name: BioImage.IO
type: collection
description: BioImage.IO RDF collections
tags: []
version: 0.1.0
authors:
  - name: BioImgae.IO Team
documentation: ./README.md
git_repo: https://github.com/bioimage-io/collection-bioimage-io
icon: >-
  https://raw.githubusercontent.com/bioimage-io/bioimage.io/main/public/static/icons/android-chrome-384x384.png
config:
  splash_title: BioImage Model Zoo
  splash_subtitle: Advanced AI models in one-click
  splash_feature_list:
    - Integrate with Fiji, Ilastik, ImJoy
    - Try model instantly with BioEngine
    - Contribute your models via Github
    - Link models to datasets and applications
  explore_button_text: Start Exploring
  background_image: static/img/zoo-background.svg
  resource_types:
    - model
    - application
    - notebook
    - dataset
  default_type: model
  url_root: >-
    https://raw.githubusercontent.com/bioimage-io/collection-bioimage-io/gh-pages
  partners:
    - id: zero
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/manifest.bioimage.io.yaml
    - id: deepimagej
      source: >-
        https://raw.githubusercontent.com/deepimagej/models/master/manifest.bioimage.io.yaml
    - id: fiji
      source: >-
        https://raw.githubusercontent.com/bioimage-io/fiji-bioimage-io/master/manifest.bioimage.io.yaml
    - id: imjoy
      source: >-
        https://raw.githubusercontent.com/imjoy-team/bioimage-io-models/master/manifest.bioimage.io.yaml
    - id: ilastik
      source: >-
        https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/manifest.bioimage.io.yaml
    - id: hpa
      source: >-
        https://raw.githubusercontent.com/CellProfiling/HPA-model-zoo/master/manifest.bioimage.io.yaml
attachments:
  application:
    - id: deepimagej/EVsTEMsegmentationFRUNet
      type: application
      name: Small extracellular vesicle instance segmentation (FRU-Net)
      description: >-
        Ready to use notebook for the segmentation of small extrcaellular
        vesicles in transmission electron microscopy (TEM) images. The notebook
        is optimized to use it in Google Colaboratory. It will download the
        original code and dataset, and make the inference connecting with
        Google's GPU.
      cite:
        - text: >-
            Gómez-de-Mariscal, E. et al., Deep-Learning-Based Segmentation of
            SmallExtracellular Vesicles in Transmission Electron Microscopy
            Images Scientific Reports, (2019)
          doi: https://doi.org/10.1038/s41598-019-49431-3
      authors:
        - name: Estibaliz Gómez-de-Mariscal
          affiliation: Universidad Carlos III de Madrid
        - name: Martin Maška
          affiliation: Masaryk University
        - name: Anna Kotrbová
          affiliation: Masaryk University
        - name: Vendula Pospíchalová
          affiliation: Masaryk University
        - name: Pavel Matula
          affiliation: Masaryk University
        - name: Arrate Muñoz-Barrutia
          affiliation: Universidad Carlos III de Madrid
      covers:
        - >-
          https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41598-019-49431-3/MediaObjects/41598_2019_49431_Fig1_HTML.png
        - >-
          https://raw.githubusercontent.com/deepimagej/models/master/fru-net_sev_segmentation/frunet_sev.jpg
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/BIIG-UC3M/FRU-Net-TEM-segmentation/blob/main/FRUnet_TEM_Exosomes_sEV.ipynb
      documentation: >-
        https://raw.githubusercontent.com/deepimagej/models/master/fru-net_sev_segmentation/README.md
      tags:
        - extracellular-vesicles
        - segmentation
        - TEM
        - notebook
        - model-inference
        - google-colab
        - workflow
        - pipeline
      source: >-
        https://raw.githubusercontent.com/BIIG-UC3M/FRU-Net-TEM-segmentation/master/FRUnet_TEM_Exosomes_sEV.ipynb
      links:
        - FRUNet2DsEVSegmentation
      config:
        partner: deepimagej
        status: passed
    - id: deepimagej/deepimagej-web
      type: application
      name: DeepImageJ
      description: >-
        DeepImageJ is a user-friendly plugin that enables the use of pre-trained
        deep learning models in ImageJ and Fiji.
      source: https://deepimagej.github.io/deepimagej/index.html
      cite:
        text: >-
          Gómez-de-Mariscal, E., García-López-de-Haro, C., Ouyang, W., Donati,
          L., Lundberg E., Unser, M., Muñoz-Barrutia, A. and Sage, D.
          DeepImageJ: A user-friendly plugin to run deep learning models in
          ImageJ, BioRxiv, 2019
        doi: https://doi.org/10.1101/799270
      authors:
        - name: DeepImageJ
          affiliation: EPFL, UC3M
      icon: >-
        https://raw.githubusercontent.com/deepimagej/models/master/logos/icon.png
      documentation: https://deepimagej.github.io/deepimagej/index.html
      git_repo: https://github.com/deepimagej/deepimagej-plugin
      passive: true
      tags:
        - deepimagej
        - software
      config:
        supported_weight_formats:
          - tensorflow_saved_model_bundle
        partner: deepimagej
        status: passed
    - id: deepimagej/smlm-deepimagej
      type: application
      name: SMLM-superresolution
      description: >-
        Single molecule localization microscopy (SMLM) processing using
        deepImageJ and ThunderSTORM in an ImageJ macro.
      covers:
        - >-
          https://raw.githubusercontent.com/deepimagej/models/master/workflows/smlm_deepstorm/cover.png
      download_url: >-
        https://raw.githubusercontent.com/deepimagej/imagej-macros/master/DeepSTORM4stacksThunderSTORM.ijm
      source: >-
        https://raw.githubusercontent.com/deepimagej/imagej-macros/master/DeepSTORM4stacksThunderSTORM.ijm
      cite:
        - text: Lucas von Chamier et al., Nature Communications 2021
          doi: https://doi.org/10.1038/s41467-021-22518-0
        - text: Gómez de Mariscal et al. bioRxiv 2019
          doi: https://doi.org/10.1101/799270
        - text: M. Ovesný, et al., Bioinformatics 2014
          doi: https://doi.org/10.1093/bioinformatics/btu202
      authors:
        - name: DeepImageJ
          affiliation: EPFL, UC3M
      icon: >-
        https://raw.githubusercontent.com/deepimagej/models/master/logos/icon.png
      documentation: >-
        https://raw.githubusercontent.com/deepimagej/models/master/workflows/smlm_deepstorm/README.md
      tags:
        - deepimagej
        - smlm
        - macro
        - deepstorm
        - thunderstorm
        - workflow
        - pipeline
        - superresolution
      config:
        partner: deepimagej
        status: passed
    - id: deepimagej/unet-pancreaticcellsegmentation
      type: application
      name: 2D U-Net for binary segmentation
      description: >-
        Easy example to define a 2D U-Net for segmentation with Keras and import
        it into DeepImageJ format
      cite:
        - text: >-
            Falk, T., Mai, D., Bensch, R. et al. U-Net: deep learning for cell
            counting, detection, and morphometry. Nat Methods 16, 67–70 (2019).
          doi: https://doi.org/10.1038/s41592-018-0261-2
      authors:
        - name: Ignacio Arganda-Carreras
          affiliation: EPFL, UC3M
        - name: DeepImageJ
          affiliation: EPFL, UC3M
      covers:
        - >-
          https://raw.githubusercontent.com/deepimagej/models/master/u-net_pancreatic_segmentation/notebook_intro.png
        - >-
          https://raw.githubusercontent.com/deepimagej/models/master/u-net_pancreatic_segmentation/usecase.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/deepimagej/models/blob/master/u-net_pancreatic_segmentation/U_Net_PhC_C2DL_PSC_segmentation.ipynb
      documentation: https://github.com/miura/NEUBIAS_AnalystSchool2020/tree/master/Ignacio
      tags:
        - unet
        - segmentation
        - deepimagej
        - notebook
        - training
        - cell-segmentation
      source: >-
        https://raw.githubusercontent.com/deepimagej/models/master/u-net_pancreatic_segmentation/U_Net_PhC_C2DL_PSC_segmentation.ipynb
      links:
        - UNet2DPancreaticSegmentation
      config:
        partner: deepimagej
        status: passed
    - id: fiji/Fiji
      name: Fiji
      description: >-
        Fiji is an image processing package — a "batteries-included"
        distribution of ImageJ, bundling many plugins which facilitate
        scientific image analysis.
      source: https://fiji.sc/
      cite:
        text: >-
          Schindelin, J., Arganda-Carreras, I., Frise, E. et al. Fiji: an
          open-source platform for biological-image analysis. Nat Methods 9,
          676–682 (2012).
        doi: https://doi.org/10.1038/nmeth.2019
      authors:
        - Fiji community
      icon: >-
        https://raw.githubusercontent.com/bioimage-io/fiji-bioimage-io/master/Fiji-icon.png
      documentation: https://fiji.sc/
      git_repo: https://github.com/fiji/fiji,
      passive: true
      tags:
        - fiji
        - software
      type: application
      config:
        partner: fiji
        status: passed
    - id: zero/Notebook_Augmentor_ZeroCostDL4Mic
      name: Augmentor - ZeroCostDL4Mic
      description: >-
        Augmentor is a data augmentation library. Data augmentation can improve
        training progress by amplifying differences in the dataset. This can be
        useful if the available dataset is small since, in this case, it is
        possible that a network could quickly learn every example in the dataset
        (overfitting), without augmentation. Augmentation can be especially
        valuable when training dataset need to be manually labelled. Note -
        visit the ZeroCostDL4Mic wiki to check the original publications this
        network is based on and make sure you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/augmentor_notebook.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Tools/Augmentor_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - Augmentor
        - Data Augmentation
        - ZeroCostDL4Mic
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Tools/Augmentor_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_CARE_2D_ZeroCostDL4Mic
      name: CARE (2D) - ZeroCostDL4Mic
      description: >-
        CARE is a neural network capable of image restoration from corrupted
        bio-images, first published in 2018 by Weigert et al. in Nature Methods.
        The network allows image denoising and resolution improvement in 2D and
        3D images, in a supervised training manner. The function of the network
        is essentially determined by the set of images provided in the training
        dataset. For instance, if noisy images are provided as input and high
        signal-to-noise ratio images are provided as targets, the network will
        perform denoising. Note - visit the ZeroCostDL4Mic wiki to check the
        original publications this network is based on and make sure you cite
        these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Lucas von Chamier and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/CARE2D_notebook.png
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/CARE2D_notebook_2.png
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/CARE2D_notebook_3.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/CARE_2D_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - CARE
        - denoising
        - ZeroCostDL4Mic
        - 2D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/CARE_2D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_CARE_2D_ZeroCostDL4Mic
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_CARE_3D_ZeroCostDL4Mic
      name: CARE (3D) - ZeroCostDL4Mic
      description: >-
        CARE is a neural network capable of image restoration from corrupted
        bio-images, first published in 2018 by Weigert et al. in Nature Methods.
        The network allows image denoising and resolution improvement in 2D and
        3D images, in a supervised training manner. The function of the network
        is essentially determined by the set of images provided in the training
        dataset. For instance, if noisy images are provided as input and high
        signal-to-noise ratio images are provided as targets, the network will
        perform denoising. Note - visit the ZeroCostDL4Mic wiki to check the
        original publications this network is based on and make sure you cite
        these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Lucas von Chamier and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/3D_CARE_notebook.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/CARE_3D_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - CARE
        - denoising
        - ZeroCostDL4Mic
        - 3D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/CARE_3D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_CARE_3D_ZeroCostDL4Mic
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_Cellpose_2D_ZeroCostDL4Mic
      name: Cellpose (2D and 3D) - ZeroCostDL4Mic
      description: Cellpose is a generalist algorithm for cellular segmentation.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/cellpose_notebook.png
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/cellpose_notebook_2.png
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/cellpose_notebook_3.png
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/cellpose_notebook_4.png
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/cellpose_notebook_5.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/Cellpose_2D_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - Cellpose
        - Segmentation
        - ZeroCostDL4Mic
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/Cellpose_2D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_StarDist_2D_ZeroCostDL4Mic_2D
        - Dataset_StarDist_Fluo_ZeroCostDL4Mic
        - Dataset_StarDist_brightfield_ZeroCostDL4Mic
        - Dataset_StarDist_brightfield2_ZeroCostDL4Mic
        - Dataset_StarDist_fluo2_ZeroCostDL4Mic
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_CycleGAN_2D_ZeroCostDL4Mic
      name: CycleGAN (2D) - ZeroCostDL4Mic
      description: >-
        CycleGAN is a method that can capture the characteristics of one image
        domain and figure out how these characteristics could be translated into
        another image domain, all in the absence of any paired training examples
        (ie transform a horse into zebra or apples into oranges). While CycleGAN
        can potentially be used for any type of image-to-image translation, we
        illustrate that it can be used to predict what a fluorescent label would
        look like when imaged using another imaging modalities. Note - visit the
        ZeroCostDL4Mic wiki to check the original publications this network is
        based on and make sure you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/cycleGAN_notebook.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/CycleGAN_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - CycleGAN
        - ZeroCostDL4Mic
        - 2D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/CycleGAN_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_CycleGAN_ZeroCostDL4Mic
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_DFCAN_ZeroCostDL4Mic
      name: DFCAN - ZeroCostDL4Mic
      description: >-
        Deep Fourier channel attention network (DFCAN) is a network created to
        transform low-resolution (LR) images to super-resolved (SR) images,
        published by Qiao, Chang and Li, Di and Guo, Yuting and Liu, Chong and
        Jiang, Tao and Dai, Qionghai and Li, Dong. The training is done using
        LR-SR image pairs, taking the LR images as input and obtaining an output
        as close to SR as posible.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
        - text: >-
            Qiao C, Li D, Guo Y, Liu C, Jiang T, Dai Q, Li D. Evaluation and
            development of deep neural networks for image super-resolution in
            optical microscopy. Nat Methods. 2021 Feb;18(2):194-202. doi:
            10.1038/s41592-020-01048-5. Epub 2021 Jan 21. PMID: 33479522. 
          doi: https://doi.org/10.1038/s41592-020-01048-5
      authors:
        - Ainhoa Serrano, Ignacio Arganda-Carreras and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/DFCAN_notebook.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/DFCAN_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - DFCAN
        - Super Resolution
        - ZeroCostDL4Mic
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/DFCAN_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_DRMIME_ZeroCostDL4Mic
      name: DRMIME - ZeroCostDL4Mic
      description: >-
        DRMIME is an network that can be used to register microscopy images
        (affine and perspective registration).
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/DrMIME_notebook.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/DRMIME_2D_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - DRMIME
        - image registration
        - ZeroCostDL4Mic
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/DRMIME_2D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_DecoNoising_2D_ZeroCostDL4Mic
      name: DecoNoising (2D) - ZeroCostDL4Mic
      description: >-
        DecoNoising 2D is deep-learning method that can be used to denoise 2D
        microscopy images. By running this notebook, you can train your own
        network and denoise your images. Note - visit the ZeroCostDL4Mic wiki to
        check the original publications this network is based on and make sure
        you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/DecoNoising_notebook.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/DecoNoising_2D_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - DecoNoising
        - denoising
        - ZeroCostDL4Mic
        - 2D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/DecoNoising_2D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_Noise2Void_2D_ZeroCostDL4Mic
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_Deep-STORM_2D_ZeroCostDL4Mic
      name: Deep-STORM (2D) - ZeroCostDL4Mic
      description: >-
        Deep-STORM is a neural network capable of image reconstruction from
        high-density single-molecule localization microscopy (SMLM), first
        published in 2018 by Nehme et al. in Optica. This network allows image
        reconstruction of 2D super-resolution images, in a supervised training
        manner. The network is trained using simulated high-density SMLM data
        for which the ground-truth is available. These simulations are obtained
        from random distribution of single molecules in a field-of-view and
        therefore do not imprint structural priors during training. The network
        output a super-resolution image with increased pixel density (typically
        upsampling factor of 8 in each dimension). Note - visit the
        ZeroCostDL4Mic wiki to check the original publications this network is
        based on and make sure you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Romain Laine and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/DeepSTORM_notebook.png
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/DeepSTORM_notebook_2.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Deep-STORM_2D_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - Deep-STORM
        - labelling
        - ZeroCostDL4Mic
        - 2D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Deep-STORM_2D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_Deep-STORM_ZeroCostDL4Mic
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_Deep-STORM_2D_ZeroCostDL4Mic_DeepImageJ
      name: Deep-STORM (2D) - ZeroCostDL4Mic - DeepImageJ
      description: >-
        Deep-STORM is a neural network capable of image reconstruction from
        high-density single-molecule localization microscopy (SMLM), first
        published in 2018 by Nehme et al. in Optica. This network allows image
        reconstruction of 2D super-resolution images, in a supervised training
        manner. The network is trained using simulated high-density SMLM data
        for which the ground-truth is available. These simulations are obtained
        from random distribution of single molecules in a field-of-view and
        therefore do not imprint structural priors during training. The network
        output a super-resolution image with increased pixel density (typically
        upsampling factor of 8 in each dimension). Note - visit the
        ZeroCostDL4Mic wiki to check the original publications this network is
        based on and make sure you cite these. Networks trained in this notebook
        can be used in Fiji via deepImageJ and ThunderSTORM plugin.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - >-
          Estibaliz Gómez de Mariscal and the deepImageJ and the ZeroCostDL4Mic
          teams
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/DeepSTORM_notebook.png
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/DeepSTORM_notebook_2.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/BioImage.io%20notebooks/Deep-STORM_2D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - Deep-STORM
        - DeepImageJ
        - ZeroCostDL4Mic
        - 2D
        - deepImageJ
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/BioImage.io%20notebooks/Deep-STORM_2D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_Deep-STORM_ZeroCostDL4Mic
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_DenoiSeg_2D_ZeroCostDL4Mic
      name: DenoiSeg (2D) - ZeroCostDL4Mic
      description: >-
        DenoiSeg 2D is deep-learning method that can be used to jointly denoise
        and segment 2D microscopy images. The benefits of using DenoiSeg
        (compared to other Deep Learning-based segmentation methods) are more
        prononced when only a few annotated images are available. However, the
        denoising part requires many images to perform well. All the noisy
        images don't need to be labeled to train DenoiSeg. Note - visit the
        ZeroCostDL4Mic wiki to check the original publications this network is
        based on and make sure you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/Denoiseg_notebook.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/DenoiSeg_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - CycleGAN
        - ZeroCostDL4Mic
        - 2D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/DenoiSeg_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_Detectron2_ZeroCostDL4Mic
      name: Detectron2 - ZeroCostDL4Mic
      description: >-
        Detectron2 is an object detection network developed by Facebook AI
        Research, which identifies objects in images and draws bounding boxes
        around them.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/yolo_notebook.png
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/yolo_notebook_2.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/Detectron2_2D_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - Detectron2
        - object detection
        - ZeroCostDL4Mic
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/Detectron2_2D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_YOLOv2_ZeroCostDL4Mic
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_EmbedSeg_2D_ZeroCostDL4Mic
      name: EmbedSeg (2D) - ZeroCostDL4Mic
      description: >-
        EmbedSeg 2D is a deep-learning method that can be used to segment object
        from bioimages and was first published by Lalit et al. in 2021, on
        arXiv.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Amin Rezaei, Guillaume Jacquemet and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/2D_Stardist_notebook.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/EmbedSeg_2D_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - EmbedSeg
        - Segmentation
        - ZeroCostDL4Mic
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/EmbedSeg_2D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_StarDist_2D_ZeroCostDL4Mic_2D
        - Dataset_StarDist_Fluo_ZeroCostDL4Mic
        - Dataset_StarDist_brightfield_ZeroCostDL4Mic
        - Dataset_StarDist_brightfield2_ZeroCostDL4Mic
        - Dataset_StarDist_fluo2_ZeroCostDL4Mic
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_Interactive_Segmentation_Kaibu_2D_ZeroCostDL4Mic
      name: Interactive Segmentation - Kaibu (2D) - ZeroCostDL4Mic
      description: Interactive Segmentation using Kaibu and Cellpose.
      cite:
        - text: >-
            Ouyang W, Le T, Xu H and Lundberg E. Interactive biomedical
            segmentation tool powered by deep learning and ImJoy [version 1;
            peer review: 1 approved, 1 approved with reservations].
            F1000Research 2021, 10:142
            (https://doi.org/10.12688/f1000research.50798.1)
          doi: https://doi.org/10.12688/f1000research.50798.1
      authors:
        - Romain Laine, Wei Ouyang and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/cellpose_notebook.png
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/cellpose_notebook_2.png
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/cellpose_notebook_3.png
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/cellpose_notebook_4.png
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/cellpose_notebook_5.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/ZeroCostDL4Mic_Interactive_annotations_Cellpose.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - Cellpose
        - Segmentation
        - ZeroCostDL4Mic
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/ZeroCostDL4Mic_Interactive_annotations_Cellpose.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_MaskRCNN_ZeroCostDL4Mic
      name: MaskRCNN - ZeroCostDL4Mic
      description: >-
        MaskRCNN is a is an object detection and segmentation network, which
        identifies objects in images and draws bounding boxes around them.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Lucas von Chamier and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/maskRCNN_notebook.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/MaskRCNN_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - MaskRCNN
        - object detection
        - ZeroCostDL4Mic
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/MaskRCNN_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_Noise2Void_2D_ZeroCostDL4Mic
      name: Noise2Void (2D) - ZeroCostDL4Mic
      description: >-
        Noise2Void 2D is deep-learning method that can be used to denoise 2D
        microscopy images. By running this notebook, you can train your own
        network and denoise your images. Note - visit the ZeroCostDL4Mic wiki to
        check the original publications this network is based on and make sure
        you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Romain Laine and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/N2V_2D_notebook.png
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/N2V2D_notebook_3.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Noise2Void_2D_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - Noise2Void
        - denoising
        - ZeroCostDL4Mic
        - 2D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Noise2Void_2D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_Noise2Void_2D_ZeroCostDL4Mic
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_Noise2Void_3D_ZeroCostDL4Mic
      name: Noise2VOID (3D) - ZeroCostDL4Mic
      description: >-
        Noise2VOID 3D is deep-learning method that can be used to denoise 3D
        microscopy images. By running this notebook, you can train your own
        network and denoise your images. Note - visit the ZeroCostDL4Mic wiki to
        check the original publications this network is based on and make sure
        you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Romain Laine and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/N2V_3D_notebook.png
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/N2V_3D_notebook_2.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Noise2Void_3D_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - Noise2Void
        - denoising
        - ZeroCostDL4Mic
        - 3D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Noise2Void_3D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_Noise2Void_3D_ZeroCostDL4Mic
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_Quality_Control_ZeroCostDL4Mic
      name: Quality Control - ZeroCostDL4Mic
      description: >-
        This notebooks enable to perform error mapping and quality metrics
        estimation.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/QC_notebook.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Tools/Quality_Control_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - Quality Control
        - ZeroCostDL4Mic
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Tools/Quality_Control_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_RCAN_3D_ZeroCostDL4Mic
      name: RCAN (3D) - ZeroCostDL4Mic
      description: >-
        RCAN is a neural network capable of image restoration from corrupted
        bio-images. The network allows image denoising and resolution
        improvement in 3D images, in a supervised training manner. The function
        of the network is essentially determined by the set of images provided
        in the training dataset. For instance, if noisy images are provided as
        input and high signal-to-noise ratio images are provided as targets, the
        network will perform denoising. Note - visit the ZeroCostDL4Mic wiki to
        check the original publications this network is based on and make sure
        you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/3D_CARE_notebook.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/3D-RCAN_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - CARE
        - denoising
        - ZeroCostDL4Mic
        - 3D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/3D-RCAN_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_CARE_3D_ZeroCostDL4Mic
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_RetinaNet_ZeroCostDL4Mic
      name: RetinaNet - ZeroCostDL4Mic
      description: >-
        RetinaNet is a is an object detection network, which identifies objects
        in images and draws bounding boxes around them.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Erlantz Calvo, Ignacio Arganda-Carreras and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/yolo_notebook.png
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/yolo_notebook_2.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/RetinaNet_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - RetinaNet
        - object detection
        - ZeroCostDL4Mic
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/RetinaNet_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_YOLOv2_ZeroCostDL4Mic
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_SplineDist_2D_ZeroCostDL4Mic
      name: SplineDist (2D) - ZeroCostDL4Mic
      description: >-
        SplineDist is a neural network inspired by StarDist, capable of
        performing image instance segmentation. Unlike StarDist, SplineDist uses
        cubic splines to describe the contour of each object and therefore can
        potentially segment objects of any shapes. This version is only for 2D
        dataset. Note - visit the ZeroCostDL4Mic wiki to check the original
        publications this network is based on and make sure you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Romain F. Laine and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/SplineDist_overlay_cropped.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/SplineDist_2D_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - SplineDist
        - segmentation
        - ZeroCostDL4Mic
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/SplineDist_2D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_StarDist_2D_ZeroCostDL4Mic_2D
        - Dataset_StarDist_Fluo_ZeroCostDL4Mic
        - Dataset_StarDist_brightfield_ZeroCostDL4Mic
        - Dataset_StarDist_brightfield2_ZeroCostDL4Mic
        - Dataset_StarDist_fluo2_ZeroCostDL4Mic
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_StarDist_2D_ZeroCostDL4Mic
      name: StarDist (2D) - ZeroCostDL4Mic
      description: >-
        StarDist is a deep-learning method that can be used to segment cell
        nuclei in 2D (xy) single images or in stacks (xyz). Note - visit the
        ZeroCostDL4Mic wiki to check the original publications this network is
        based on and make sure you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/2D_Stardist_notebook.png
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/StarDist_trainingTcells_trackmate.png
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/StarDist_trainingflo_trackmate.png
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/StarDist_trainingfluo_trackmate.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/StarDist_2D_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - StarDist
        - segmentation
        - ZeroCostDL4Mic
        - 2D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/StarDist_2D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_StarDist_2D_ZeroCostDL4Mic_2D
        - Dataset_StarDist_Fluo_ZeroCostDL4Mic
        - Dataset_StarDist_brightfield_ZeroCostDL4Mic
        - Dataset_StarDist_brightfield2_ZeroCostDL4Mic
        - Dataset_StarDist_fluo2_ZeroCostDL4Mic
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_StarDist_2D_ZeroCostDL4Mic_DeepImageJ
      name: StarDist (2D) - ZeroCostDL4Mic - DeepImageJ
      description: >-
        StarDist is a deep-learning method that can be used to segment cell
        nuclei in 2D (xy) images. Note - visit the ZeroCostDL4Mic wiki to check
        the original publications this network is based on and make sure you
        cite these. Networks trained in this notebook can be used in Fiji via
        deepImageJ and StarDist plugins for ImageJ.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - >-
          Estibaliz Gómez de Mariscal and the deepImageJ and the ZeroCostDL4Mic
          teams
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/2D_Stardist_notebook.png
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/StarDist_trainingTcells_trackmate.png
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/StarDist_trainingflo_trackmate.png
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/StarDist_trainingfluo_trackmate.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/BioImage.io%20notebooks/StarDist_2D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - StarDist
        - segmentation
        - ZeroCostDL4Mic
        - 2D
        - deepimagej
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/BioImage.io%20notebooks/StarDist_2D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_StarDist_3D_ZeroCostDL4Mic
      name: StarDist (3D) - ZeroCostDL4Mic
      description: >-
        StarDist is a deep-learning method that can be used to segment cell
        nuclei in 3D (xyz) images. Note - visit the ZeroCostDL4Mic wiki to check
        the original publications this network is based on and make sure you
        cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/StarDist_3D.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/StarDist_3D_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - StarDist
        - segmentation
        - ZeroCostDL4Mic
        - 3D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/StarDist_3D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_U-Net_2D_ZeroCostDL4Mic
      name: U-Net (2D) - ZeroCostDL4Mic
      description: >-
        U-Net is an encoder-decoder architecture originally used for image
        segmentation. The first half of the U-Net architecture is a downsampling
        convolutional neural network which acts as a feature extractor from
        input images. The other half upsamples these results and restores an
        image by combining results from downsampling with the upsampled images.
        Note - visit the ZeroCostDL4Mic wiki to check the original publications
        this network is based on and make sure you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Romain Laine and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/2D_Unet_notebook.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/U-Net_2D_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - U-Net
        - segmentation
        - ZeroCostDL4Mic
        - 2D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/U-Net_2D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_U-Net_2D_ZeroCostDL4Mic_DeepImageJ
      name: U-Net (2D) - ZeroCostDL4Mic - DeepImageJ
      description: >-
        U-Net is an encoder-decoder architecture originally used for image
        segmentation. The first half of the U-Net architecture is a downsampling
        convolutional neural network which acts as a feature extractor from
        input images. The other half upsamples these results and restores an
        image by combining results from downsampling with the upsampled images.
        Note - visit the ZeroCostDL4Mic wiki to check the original publications
        this network is based on and make sure you cite these. Networks trained
        in this notebook can be used in Fiji via deepImageJ.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - >-
          Estibaliz Gómez de Mariscal and the deepImageJ and the ZeroCostDL4Mic
          teams
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/2D_Unet_notebook.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/BioImage.io%20notebooks/U-Net_2D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - U-Net
        - segmentation
        - ZeroCostDL4Mic
        - 2D
        - deepimagej
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/BioImage.io%20notebooks/U-Net_2D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_U-Net_2D_multilabel_ZeroCostDL4Mic
      name: U-Net (2D) multilabel segmentation - ZeroCostDL4Mic
      description: >-
        U-Net is an encoder-decoder architecture originally used for image
        segmentation. The first half of the U-Net architecture is a downsampling
        convolutional neural network which acts as a feature extractor from
        input images. The other half upsamples these results and restores an
        image by combining results from downsampling with the upsampled images.
        Note - visit the ZeroCostDL4Mic wiki to check the original publications
        this network is based on and make sure you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Estibaliz Gómez de Mariscal and the ZeroCostDL4Mic teams
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/U-Net_2D_Multilabel_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - u-net
        - segmentation
        - semantic-segmentation
        - multilabel
        - ZeroCostDL4Mic
        - 2D
      source: >-
        https://github.com/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/U-Net_2D_Multilabel_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_U-Net_3D_ZeroCostDL4Mic
      name: U-Net (3D) - ZeroCostDL4Mic
      description: >-
        The 3D U-Net was first introduced by Çiçek et al for learning dense
        volumetric segmentations from sparsely annotated ground-truth data
        building upon the original U-Net architecture by Ronneberger et al. Note
        - visit the ZeroCostDL4Mic wiki to check the original publications this
        network is based on and make sure you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Daniel Krentzel and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/3D_Unet_notebook.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/U-Net_3D_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - U-Net
        - segmentation
        - ZeroCostDL4Mic
        - 3D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/U-Net_3D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_U-Net_3D_ZeroCostDL4Mic_DeepImageJ
      name: U-Net (3D) - ZeroCostDL4Mic - DeepImageJ
      description: >-
        The 3D U-Net was first introduced by Çiçek et al for learning dense
        volumetric segmentations from sparsely annotated ground-truth data
        building upon the original U-Net architecture by Ronneberger et al. Note
        - visit the ZeroCostDL4Mic wiki to check the original publications this
        network is based on and make sure you cite these. Networks trained in
        this notebook can be used in Fiji via deepImageJ.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - >-
          Estibaliz Gómez de Mariscal and the deepImageJ and the ZeroCostDL4Mic
          teams
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/3D_Unet_notebook.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/BioImage.io%20notebooks/U-Net_3D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - U-Net
        - segmentation
        - ZeroCostDL4Mic
        - 3D
        - deepimagej
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/BioImage.io%20notebooks/U-Net_3D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_YOLOv2_ZeroCostDL4Mic
      name: YOLOv2 - ZeroCostDL4Mic
      description: >-
        YOLOv2 is an object detection network developed by Redmon & Farhadi,
        which identifies objects in images and draws bounding boxes around them.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Lucas von Chamier and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/yolo_notebook.png
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/yolo_notebook_2.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/YOLOv2_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - YOLOv2
        - object detection
        - ZeroCostDL4Mic
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/YOLOv2_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_YOLOv2_ZeroCostDL4Mic
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_fnet_2D_ZeroCostDL4Mic
      name: Label-free Prediction - fnet - (2D) ZeroCostDL4Mic
      description: >-
        Label-free Prediction (fnet) is a neural network used to infer the
        features of cellular structures from brightfield or EM images without
        coloured labels. The network is trained using paired training images
        from the same field of view, imaged in a label-free (e.g. brightfield)
        and labelled condition (e.g. fluorescent protein). When trained, this
        allows the user to identify certain structures from brightfield images
        alone. The performance of fnet may depend significantly on the structure
        at hand. Note - visit the ZeroCostDL4Mic wiki to check the original
        publications this network is based on and make sure you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Lucas von Chamier and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/fnet_notebook.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/fnet_2D_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - fnet
        - labelling
        - ZeroCostDL4Mic
        - 2D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/fnet_2D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_fnet_3D_ZeroCostDL4Mic
      name: Label-free Prediction - fnet - (3D) ZeroCostDL4Mic
      description: >-
        Label-free Prediction (fnet) is a neural network used to infer the
        features of cellular structures from brightfield or EM images without
        coloured labels. The network is trained using paired training images
        from the same field of view, imaged in a label-free (e.g. brightfield)
        and labelled condition (e.g. fluorescent protein). When trained, this
        allows the user to identify certain structures from brightfield images
        alone. The performance of fnet may depend significantly on the structure
        at hand. Note - visit the ZeroCostDL4Mic wiki to check the original
        publications this network is based on and make sure you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Lucas von Chamier and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/fnet_notebook.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/fnet_3D_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - fnet
        - labelling
        - ZeroCostDL4Mic
        - 3D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/fnet_3D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_fnet_3D_ZeroCostDL4Mic
      type: application
      config:
        partner: zero
        status: passed
    - id: zero/Notebook_pix2pix_2D_ZeroCostDL4Mic
      name: pix2pix (2D) - ZeroCostDL4Mic
      description: >-
        pix2pix is a deep-learning method that can be used to translate one type
        of images into another. While pix2pix can potentially be used for any
        type of image-to-image translation, we demonstrate that it can be used
        to predict a fluorescent image from another fluorescent image. Note -
        visit the ZeroCostDL4Mic wiki to check the original publications this
        network is based on and make sure you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/pix2pix_notebook_2.png
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/pix2pix_notebook.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/pix2pix_ZeroCostDL4Mic.ipynb
      documentation: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/README.md
      tags:
        - colab
        - notebook
        - pix2pix
        - ZeroCostDL4Mic
        - 2D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/pix2pix_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_pix2pix_ZeroCostDL4Mic
      type: application
      config:
        partner: zero
        status: passed
  dataset:
    - id: deepimagej/MoNuSeg_digital_pathology_miccai2018
      name: Multi-Organ Nucleus Segmentation Challenge - MICCAI 2018
      description: >-
        Labelled images for instance segmentation of cell nuclei in digital
        pathology datasets (MoNuSeg 2018 Challenge).
      cite:
        - text: Neeraj Kumar et al. Transactions on medical imaging 2020
          doi: https://doi.org/10.1109/TMI.2019.2947628
      authors:
        - name: DeepImageJ
          affiliation: EPFL, UC3M
      documentation: https://monuseg.grand-challenge.org/
      tags:
        - StarDist
        - segmentation
        - pathology
        - H&E
        - histology
        - 2D
        - nuclei segmentation
        - digital pathology
      source: https://monuseg.grand-challenge.org/Data/
      covers:
        - >-
          https://raw.githubusercontent.com/deepimagej/models/master/datasets/MoNuSeg1.jpg
        - >-
          https://raw.githubusercontent.com/deepimagej/models/master/datasets/MoNuSeg2.jpg
        - >-
          https://raw.githubusercontent.com/deepimagej/models/master/datasets/MoNuSeg3.jpg
      type: dataset
      config:
        partner: deepimagej
        status: passed
    - id: imjoy/LuCa-7color
      name: LuCa-7color
      description: >-
        Sample PerkinElmer Vectra QPTIFF files (c) PerkinElmer
        (http://www.perkinelmer.com)
      authors:
        - Perkin Elmer
      tags:
        - OME-TIFF
      license: CC-BY 4.0
      download_url: >-
        https://downloads.openmicroscopy.org/images/Vectra-QPTIFF/perkinelmer/PKI_scans/LuCa-7color_Scan1.qptiff
      source: https://viv-demo.storage.googleapis.com/LuCa-7color_Scan1/data.zarr/0
      covers:
        - >-
          https://raw.githubusercontent.com/imjoy-team/bioimage-io-models/master/asset/LuCa-7color_Scan1.png
      links:
        - vizarr
      type: dataset
      config:
        partner: imjoy
        status: passed
    - id: zero/Dataset_CARE_2D_ZeroCostDL4Mic
      name: CARE (2D) example training and test dataset - ZeroCostDL4Mic
      description: Fluorescence microscopy (Lifeact-RFP)
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet
      documentation: https://doi.org/10.5281/zenodo.3713330
      tags:
        - CARE
        - denoising
        - ZeroCostDL4Mic
        - 2D
      source: https://doi.org/10.5281/zenodo.3713330
      covers:
        - >-
          https://github.com/HenriquesLab/ZeroCostDL4Mic/raw/master/Wiki_files/CARE_wiki.png
      type: dataset
      config:
        partner: zero
        status: passed
    - id: zero/Dataset_CARE_3D_ZeroCostDL4Mic
      name: CARE (3D) example training and test dataset - ZeroCostDL4Mic
      description: Fluorescence microscopy (Lifeact-RFP)
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet
      documentation: https://doi.org/10.5281/zenodo.3713337
      tags:
        - CARE
        - denoising
        - ZeroCostDL4Mic
        - 3D
      source: https://doi.org/10.5281/zenodo.3713337
      covers:
        - >-
          https://github.com/HenriquesLab/ZeroCostDL4Mic/raw/master/Wiki_files/CARE_wiki.png
      type: dataset
      config:
        partner: zero
        status: passed
    - id: zero/Dataset_CycleGAN_ZeroCostDL4Mic
      name: CycleGAN example training and test dataset - ZeroCostDL4Mic
      description: >-
        Unpaired microscopy images (fluorescence) of microtubules (Spinning-disk
        and SRRF reconstructed images)
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet
      documentation: https://doi.org/10.5281/zenodo.3941884
      tags:
        - CycleGAN
        - ZeroCostDL4Mic
      source: https://doi.org/10.5281/zenodo.3941884
      covers:
        - >-
          https://github.com/HenriquesLab/ZeroCostDL4Mic/raw/master/BioimageModelZoo/Images/CycleGAN_dataset.png
      type: dataset
      config:
        partner: zero
        status: passed
    - id: zero/Dataset_Deep-STORM_ZeroCostDL4Mic
      name: Deep-STORM training and example dataset - ZeroCostDL4Mic
      description: >-
        Time-series of simulated, randomly distributed single-molecule
        localization (SMLM) data (Training dataset). Experimental time-series
        dSTORM acquisition of Glial cells stained with phalloidin for actin
        (Example dataset).
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Christophe Leterrier
        - Romain F. Laine
      documentation: https://doi.org/10.5281/zenodo.3959089
      tags:
        - SMLM
        - Deep-STORM
        - ZeroCostDL4Mic
        - 2D
      source: https://doi.org/10.5281/zenodo.3959089
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/DeepSTORM_dataset.png
      type: dataset
      config:
        partner: zero
        status: passed
    - id: zero/Dataset_Noise2Void_2D_ZeroCostDL4Mic
      name: Noise2Void (2D) example training and test dataset - ZeroCostDL4Mic
      description: Fluorescence microscopy (paxillin-GFP)
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Aki Stubb
        - Guillaume Jacquemet
        - Johanna Ivaska
      documentation: https://doi.org/10.5281/zenodo.3713315
      tags:
        - Noise2Void
        - denoising
        - ZeroCostDL4Mic
        - 2D
      source: https://doi.org/10.5281/zenodo.3713315
      covers:
        - >-
          https://github.com/HenriquesLab/ZeroCostDL4Mic/raw/master/Wiki_files/N2V_wiki.png
      type: dataset
      config:
        partner: zero
        status: passed
    - id: zero/Dataset_Noise2Void_3D_ZeroCostDL4Mic
      name: Noise2Void (3D) example training and test dataset - ZeroCostDL4Mic
      description: Fluorescence microscopy (Lifeact-RFP)
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacqueme
      documentation: https://doi.org/10.5281/zenodo.3713326
      tags:
        - Noise2Void
        - denoising
        - ZeroCostDL4Mic
        - 3D
      source: https://doi.org/10.5281/zenodo.3713326
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/N2V_3D_dataset.png
      type: dataset
      config:
        partner: zero
        status: passed
    - id: zero/Dataset_Noisy_Nuclei_ZeroCostDL4Mic
      name: Noisy nuclei dataset.
      description: >-
        This dataset contains a denoising training and test dataset for deep
        learning applications. The training dataset comprises 20 paired matching
        noisy and high signal-to-noise images. The test dataset contains five
        paired matching noisy and high signal-to-noise images. Images are
        Fluorescence microscopy (SiR-DNA) images acquired using a spinning disk
        confocal microscope with a 20x 0.8 NA objective.
      cite:
        - text: >-
            Laine RF, Arganda-Carreras I, Henriques R, Jacquemet G. Avoiding a
            replication crisis in deep-learning-based bioimage analysis. Nat
            Methods. 2021 Oct;18(10):1136-1144. doi: 10.1038/s41592-021-01284-3.
            PMID: 34608322; PMCID: PMC7611896. 
          doi: https://doi.org/10.1038/s41592-021-01284-3
      authors:
        - Guillaume Jacquemet
      documentation: https://zenodo.org/record/5750174
      tags:
        - denoising
        - CARE
        - Noise2Void
        - DecoNoising
        - ZeroCostDL4Mic
      source: https://zenodo.org/record/5750174
      download_url: https://zenodo.org/record/5750174
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/NoisyNuclei_dataset.png
      type: dataset
      config:
        partner: zero
        status: passed
    - id: zero/Dataset_StarDist_2D_ZeroCostDL4Mic_2D
      name: StarDist (2D) example training and test dataset - ZeroCostDL4Mic
      description: >-
        Fluorescence microscopy (SiR-DNA) and masks obtained via manual
        segmentation
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Johanna Jukkala
        - Guillaume Jacquemet
      documentation: https://doi.org/10.5281/zenodo.3715492
      tags:
        - StarDist
        - segmentation
        - ZeroCostDL4Mic
        - 2D
      source: https://doi.org/10.5281/zenodo.3715492
      covers:
        - >-
          https://github.com/HenriquesLab/ZeroCostDL4Mic/raw/master/Wiki_files/Stardist_nuclei_masks.png
      type: dataset
      config:
        partner: zero
        status: passed
    - id: zero/Dataset_StarDist_Fluo_ZeroCostDL4Mic
      name: Combining StarDist and TrackMate example 1 - Breast cancer cell dataset
      description: >-
        Fluorescence microscopy of Nuclei (SiR-DNA) and masks obtained via
        manual segmentation
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
        - text: >-
            Elnaz Fazeli, Nathan H. Roy, Gautier Follain, Romain F. Laine, Lucas
            von Chamier, Pekka E. Hänninen, John E. Eriksson, Jean-Yves Tinevez,
            Guillaume Jacquemet. Automated cell tracking using StarDist and
            TrackMate. bioRxiv, 2020. DOI:
            https://doi.org/10.1101/2020.09.22.306233
          doi: https://doi.org/10.1101/2020.09.22.306233
      authors:
        - Guillaume Jacquemet
      documentation: https://zenodo.org/record/4034976
      tags:
        - StarDist
        - ZeroCostDL4Mic
      source: https://zenodo.org/record/4034976
      download_url: https://zenodo.org/record/4034976
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/StarDist_trainingfluo_trackmate.png
      type: dataset
      config:
        partner: zero
        status: passed
    - id: zero/Dataset_StarDist_brightfield2_ZeroCostDL4Mic
      name: Combining StarDist and TrackMate example 3 - Flow chamber dataset
      description: Paired brightfield images of cancer cells and corresponding masks
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
        - text: >-
            Elnaz Fazeli, Nathan H. Roy, Gautier Follain, Romain F. Laine, Lucas
            von Chamier, Pekka E. Hänninen, John E. Eriksson, Jean-Yves Tinevez,
            Guillaume Jacquemet. Automated cell tracking using StarDist and
            TrackMate. bioRxiv, 2020. DOI:
            https://doi.org/10.1101/2020.09.22.306233
          doi: https://doi.org/10.1101/2020.09.22.306233
      authors:
        - Gautier Follain
        - Guillaume Jacquemet
      documentation: https://zenodo.org/record/4034939
      tags:
        - StarDist
        - ZeroCostDL4Mic
      source: https://zenodo.org/record/4034939
      download_url: https://zenodo.org/record/4034939
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/StarDist_trainingflo_trackmate.png
      type: dataset
      config:
        partner: zero
        status: passed
    - id: zero/Dataset_StarDist_brightfield_ZeroCostDL4Mic
      name: Combining StarDist and TrackMate example 2 - T cell dataset
      description: Paired brightfield images of migrating T cells and corresponding masks
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
        - text: >-
            Elnaz Fazeli, Nathan H. Roy, Gautier Follain, Romain F. Laine, Lucas
            von Chamier, Pekka E. Hänninen, John E. Eriksson, Jean-Yves Tinevez,
            Guillaume Jacquemet. Automated cell tracking using StarDist and
            TrackMate. bioRxiv, 2020. DOI:
            https://doi.org/10.1101/2020.09.22.306233
          doi: https://doi.org/10.1101/2020.09.22.306233
      authors:
        - Nathan H. Roy
        - Guillaume Jacquemet
      documentation: https://zenodo.org/record/4034929
      tags:
        - StarDist
        - ZeroCostDL4Mic
      source: https://zenodo.org/record/4034929
      download_url: https://zenodo.org/record/4034929
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/StarDist_trainingTcells_trackmate.png
      type: dataset
      config:
        partner: zero
        status: passed
    - id: zero/Dataset_StarDist_fluo2_ZeroCostDL4Mic
      name: training dataset for automated tracking of MDA-MB-231 and BT20 cells
      description: >-
        Fluorescence microscopy of Nuclei (SiR-DNA) and masks obtained via
        manual segmentation
      cite:
        - text: >-
            Moreno-Layseca P, Jäntti NZ, Godbole R, Sommer C, Jacquemet G,
            Al-Akhrass H, Conway JRW, Kronqvist P, Kallionpää RE,
            Oliveira-Ferrer L, Cervero P, Linder S, Aepfelbacher M, Zauber H,
            Rae J, Parton RG, Disanza A, Scita G, Mayor S, Selbach M, Veltel S,
            Ivaska J. Cargo-specific recruitment in clathrin- and
            dynamin-independent endocytosis. Nat Cell Biol. 2021
            Oct;23(10):1073-1084. doi: 10.1038/s41556-021-00767-x. Epub 2021 Oct
            6. PMID: 34616024.
          doi: https://doi.org/10.1038/s41556-021-00767-x
      authors:
        - Hussein Al-Akhrass
        - Johanna Ivaska
        - Guillaume Jacquemet
      documentation: https://zenodo.org/record/4811213
      tags:
        - StarDist
        - ZeroCostDL4Mic
      source: https://zenodo.org/record/4811213
      download_url: https://zenodo.org/record/4811213
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/Moreno_dataset_stardist.png
      type: dataset
      config:
        partner: zero
        status: passed
    - id: zero/Dataset_YOLOv2_ZeroCostDL4Mic
      name: YoloV2 example training and test dataset - ZeroCostDL4Mic
      description: >-
        2D grayscale .png images with corresponding bounding box annotations in
        .xml  PASCAL Voc format.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet
        - Lucas von Chamier
      documentation: https://doi.org/10.5281/zenodo.3941908
      tags:
        - YOLOv2
        - ZeroCostDL4Mic
      source: https://doi.org/10.5281/zenodo.3941908
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/yolo_dataset.png
      type: dataset
      config:
        partner: zero
        status: passed
    - id: zero/Dataset_fnet_3D_ZeroCostDL4Mic
      name: >-
        Label-free prediction (fnet) example training and test dataset -
        ZeroCostDL4Mic
      description: Confocal microscopy data (TOM20 labeled with Alexa Fluor 594)
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Christoph Spahn
      documentation: https://doi.org/10.5281/zenodo.3748967
      tags:
        - fnet
        - labelling
        - ZeroCostDL4Mic
        - 3D
      source: https://doi.org/10.5281/zenodo.3748967
      covers:
        - >-
          https://github.com/HenriquesLab/ZeroCostDL4Mic/raw/master/Wiki_files/Fnet_exemplary_data_mitochondria.png
      type: dataset
      config:
        partner: zero
        status: passed
    - id: zero/Dataset_pix2pix_ZeroCostDL4Mic
      name: pix2pix example training and test dataset - ZeroCostDL4Mic
      description: Paired microscopy images (fluorescence) of lifeact-RFP and sir-DNA
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet
      documentation: https://doi.org/10.5281/zenodo.3941889
      tags:
        - pix2pix
        - ZeroCostDL4Mic
      source: https://doi.org/10.5281/zenodo.3941889
      covers:
        - >-
          https://github.com/HenriquesLab/ZeroCostDL4Mic/raw/master/BioimageModelZoo/Images/pix2pix_dataset.png
      type: dataset
      config:
        partner: zero
        status: passed

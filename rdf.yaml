name: BioImage.IO
type: collection
description: BioImage.IO RDF collections
tags: []
version: 0.1.0
authors:
  - name: BioImgae.IO Team
documentation: ./README.md
git_repo: https://github.com/bioimage-io/collection-bioimage-io
icon: >-
  https://raw.githubusercontent.com/bioimage-io/bioimage.io/main/public/static/icons/android-chrome-384x384.png
attachments:
  dataset:
    - id: Dataset_StarDist_2D_ZeroCostDL4Mic_2D
      name: StarDist (2D) example training and test dataset - ZeroCostDL4Mic
      description: >-
        Fluorescence microscopy (SiR-DNA) and masks obtained via manual
        segmentation
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Johanna Jukkala
        - Guillaume Jacquemet
      documentation: https://doi.org/10.5281/zenodo.3715492
      tags:
        - StarDist
        - segmentation
        - ZeroCostDL4Mic
        - 2D
      source: https://doi.org/10.5281/zenodo.3715492
      covers:
        - >-
          https://github.com/HenriquesLab/ZeroCostDL4Mic/raw/master/Wiki_files/Stardist_nuclei_masks.png
      type: dataset
      status: passed
    - id: Dataset_Noise2Void_2D_ZeroCostDL4Mic
      name: Noise2Void (2D) example training and test dataset - ZeroCostDL4Mic
      description: Fluorescence microscopy (paxillin-GFP)
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Aki Stubb
        - Guillaume Jacquemet
        - Johanna Ivaska
      documentation: https://doi.org/10.5281/zenodo.3713315
      tags:
        - Noise2Void
        - denoising
        - ZeroCostDL4Mic
        - 2D
      source: https://doi.org/10.5281/zenodo.3713315
      covers:
        - >-
          https://github.com/HenriquesLab/ZeroCostDL4Mic/raw/master/Wiki_files/N2V_wiki.png
      type: dataset
      status: passed
    - id: Dataset_Noise2Void_3D_ZeroCostDL4Mic
      name: Noise2Void (3D) example training and test dataset - ZeroCostDL4Mic
      description: Fluorescence microscopy (Lifeact-RFP)
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacqueme
      documentation: https://doi.org/10.5281/zenodo.3713326
      tags:
        - Noise2Void
        - denoising
        - ZeroCostDL4Mic
        - 3D
      source: https://doi.org/10.5281/zenodo.3713326
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/N2V_3D_dataset.png
      type: dataset
      status: passed
    - id: Dataset_CARE_2D_ZeroCostDL4Mic
      name: CARE (2D) example training and test dataset - ZeroCostDL4Mic
      description: Fluorescence microscopy (Lifeact-RFP)
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacqueme
      documentation: https://doi.org/10.5281/zenodo.3713330
      tags:
        - CARE
        - denoising
        - ZeroCostDL4Mic
        - 2D
      source: https://doi.org/10.5281/zenodo.3713330
      covers:
        - >-
          https://github.com/HenriquesLab/ZeroCostDL4Mic/raw/master/Wiki_files/CARE_wiki.png
      type: dataset
      status: passed
    - id: Dataset_CARE_3D_ZeroCostDL4Mic
      name: CARE (3D) example training and test dataset - ZeroCostDL4Mic
      description: Fluorescence microscopy (Lifeact-RFP)
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacqueme
      documentation: https://doi.org/10.5281/zenodo.3713337
      tags:
        - CARE
        - denoising
        - ZeroCostDL4Mic
        - 3D
      source: https://doi.org/10.5281/zenodo.3713337
      covers:
        - >-
          https://github.com/HenriquesLab/ZeroCostDL4Mic/raw/master/Wiki_files/CARE_wiki.png
      type: dataset
      status: passed
    - id: Dataset_fnet_3D_ZeroCostDL4Mic
      name: >-
        Label-free prediction (fnet) example training and test dataset -
        ZeroCostDL4Mic
      description: Confocal microscopy data (TOM20 labeled with Alexa Fluor 594)
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Christoph Spahn
      documentation: https://doi.org/10.5281/zenodo.3748967
      tags:
        - fnet
        - labelling
        - ZeroCostDL4Mic
        - 3D
      source: https://doi.org/10.5281/zenodo.3748967
      covers:
        - >-
          https://github.com/HenriquesLab/ZeroCostDL4Mic/raw/master/Wiki_files/Fnet_exemplary_data_mitochondria.png
      type: dataset
      status: passed
    - id: Dataset_Deep-STORM_ZeroCostDL4Mic
      name: Deep-STORM training and example dataset - ZeroCostDL4Mic
      description: >-
        Time-series of simulated, randomly distributed single-molecule
        localization (SMLM) data (Training dataset). Experimental time-series
        dSTORM acquisition of Glial cells stained with phalloidin for actin
        (Example dataset).
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Christophe Leterrier
        - Romain F. Laine
      documentation: https://doi.org/10.5281/zenodo.3959089
      tags:
        - SMLM
        - Deep-STORM
        - ZeroCostDL4Mic
        - 2D
      source: https://doi.org/10.5281/zenodo.3959089
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/DeepSTORM_dataset.png
      type: dataset
      status: passed
    - id: Dataset_CycleGAN_ZeroCostDL4Mic
      name: CycleGAN example training and test dataset - ZeroCostDL4Mic
      description: >-
        Unpaired microscopy images (fluorescence) of microtubules (Spinning-disk
        and SRRF reconstructed images)
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet
      documentation: https://doi.org/10.5281/zenodo.3941884
      tags:
        - CycleGAN
        - ZeroCostDL4Mic
      source: https://doi.org/10.5281/zenodo.3941884
      covers:
        - >-
          https://github.com/HenriquesLab/ZeroCostDL4Mic/raw/master/BioimageModelZoo/Images/CycleGAN_dataset.png
      type: dataset
      status: passed
    - id: Dataset_pix2pix_ZeroCostDL4Mic
      name: pix2pix example training and test dataset - ZeroCostDL4Mic
      description: Paired microscopy images (fluorescence) of lifeact-RFP and sir-DNA
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet
      documentation: https://doi.org/10.5281/zenodo.3941889
      tags:
        - pix2pix
        - ZeroCostDL4Mic
      source: https://doi.org/10.5281/zenodo.3941889
      covers:
        - >-
          https://github.com/HenriquesLab/ZeroCostDL4Mic/raw/master/BioimageModelZoo/Images/pix2pix_dataset.png
      type: dataset
      status: passed
    - id: Dataset_YOLOv2_ZeroCostDL4Mic
      name: YoloV2 example training and test dataset - ZeroCostDL4Mic
      description: >-
        2D grayscale .png images with corresponding bounding box annotations in
        .xml  PASCAL Voc format.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet
        - Lucas von Chamier
      documentation: https://doi.org/10.5281/zenodo.3941908
      tags:
        - YOLOv2
        - ZeroCostDL4Mic
      source: https://doi.org/10.5281/zenodo.3941908
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/yolo_dataset.png
      type: dataset
      status: passed
    - id: Dataset_StarDist_Fluo_ZeroCostDL4Mic
      name: Combining StarDist and TrackMate example 1 - Breast cancer cell dataset
      description: >-
        Fluorescence microscopy of Nuclei (SiR-DNA) and masks obtained via
        manual segmentation
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
        - text: >-
            Elnaz Fazeli, Nathan H. Roy, Gautier Follain, Romain F. Laine, Lucas
            von Chamier, Pekka E. Hänninen, John E. Eriksson, Jean-Yves Tinevez,
            Guillaume Jacquemet. Automated cell tracking using StarDist and
            TrackMate. bioRxiv, 2020. DOI:
            https://doi.org/10.1101/2020.09.22.306233
          doi: https://doi.org/10.1101/2020.09.22.306233
      authors:
        - Guillaume Jacquemet
      documentation: https://doi.org/10.5281/zenodo.3941884
      tags:
        - StarDist
        - ZeroCostDL4Mic
      source: https://zenodo.org/record/4034976
      download_url: https://zenodo.org/record/4034976
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/StarDist_trainingfluo_trackmate.png
      type: dataset
      status: passed
    - id: Dataset_StarDist_brightfield_ZeroCostDL4Mic
      name: Combining StarDist and TrackMate example 2 - T cell dataset
      description: Paired brightfield images of migrating T cells and corresponding masks
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
        - text: >-
            Elnaz Fazeli, Nathan H. Roy, Gautier Follain, Romain F. Laine, Lucas
            von Chamier, Pekka E. Hänninen, John E. Eriksson, Jean-Yves Tinevez,
            Guillaume Jacquemet. Automated cell tracking using StarDist and
            TrackMate. bioRxiv, 2020. DOI:
            https://doi.org/10.1101/2020.09.22.306233
          doi: https://doi.org/10.1101/2020.09.22.306233
      authors:
        - Nathan H. Roy
        - Guillaume Jacquemet
      documentation: https://doi.org/10.5281/zenodo.3941884
      tags:
        - StarDist
        - ZeroCostDL4Mic
      source: https://zenodo.org/record/4034929
      download_url: https://zenodo.org/record/4034929
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/StarDist_trainingTcells_trackmate.png
      type: dataset
      status: passed
    - id: Dataset_StarDist_brightfield2_ZeroCostDL4Mic
      name: Combining StarDist and TrackMate example 3 - Flow chamber dataset
      description: Paired brightfield images of cancer cells and corresponding masks
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
        - text: >-
            Elnaz Fazeli, Nathan H. Roy, Gautier Follain, Romain F. Laine, Lucas
            von Chamier, Pekka E. Hänninen, John E. Eriksson, Jean-Yves Tinevez,
            Guillaume Jacquemet. Automated cell tracking using StarDist and
            TrackMate. bioRxiv, 2020. DOI:
            https://doi.org/10.1101/2020.09.22.306233
          doi: https://doi.org/10.1101/2020.09.22.306233
      authors:
        - Gautier Follain
        - Guillaume Jacquemet
      documentation: https://doi.org/10.5281/zenodo.3941884
      tags:
        - StarDist
        - ZeroCostDL4Mic
      source: https://zenodo.org/record/4034939
      download_url: https://zenodo.org/record/4034939
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/StarDist_trainingflo_trackmate.png
      type: dataset
      status: passed
  application:
    - id: Notebook_U-Net_2D_ZeroCostDL4Mic
      name: U-Net (2D) - ZeroCostDL4Mic
      description: >-
        U-Net is an encoder-decoder architecture originally used for image
        segmentation. The first half of the U-Net architecture is a downsampling
        convolutional neural network which acts as a feature extractor from
        input images. The other half upsamples these results and restores an
        image by combining results from downsampling with the upsampled images.
        Note - visit the ZeroCostDL4Mic wiki to check the original publications
        this network is based on and make sure you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Romain Laine and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/U-Net_2D_ZeroCostDL4Mic.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - U-Net
        - segmentation
        - ZeroCostDL4Mic
        - 2D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/U-Net_2D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      status: passed
    - id: Notebook_U-Net_3D_ZeroCostDL4Mic
      name: U-Net (3D) - ZeroCostDL4Mic
      description: >-
        The 3D U-Net was first introduced by Çiçek et al for learning dense
        volumetric segmentations from sparsely annotated ground-truth data
        building upon the original U-Net architecture by Ronneberger et al. Note
        - visit the ZeroCostDL4Mic wiki to check the original publications this
        network is based on and make sure you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Daniel Krentzel and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/U-Net_3D_ZeroCostDL4Mic.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - U-Net
        - segmentation
        - ZeroCostDL4Mic
        - 3D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/U-Net_3D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      status: passed
    - id: Notebook_StarDist_2D_ZeroCostDL4Mic
      name: StarDist (2D) - ZeroCostDL4Mic
      description: >-
        StarDist is a deep-learning method that can be used to segment cell
        nuclei in 2D (xy) single images or in stacks (xyz). Note - visit the
        ZeroCostDL4Mic wiki to check the original publications this network is
        based on and make sure you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/StarDist_2D_ZeroCostDL4Mic.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - StarDist
        - segmentation
        - ZeroCostDL4Mic
        - 2D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/StarDist_2D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_StarDist_2D_ZeroCostDL4Mic_2D
        - Dataset_StarDist_Fluo_ZeroCostDL4Mic
        - Dataset_StarDist_brightfield_ZeroCostDL4Mic
        - Dataset_StarDist_brightfield2_ZeroCostDL4Mic
      type: application
      status: passed
    - id: Notebook_StarDist_3D_ZeroCostDL4Mic
      name: StarDist (3D) - ZeroCostDL4Mic
      description: >-
        StarDist is a deep-learning method that can be used to segment cell
        nuclei in 3D (xyz) images. Note - visit the ZeroCostDL4Mic wiki to check
        the original publications this network is based on and make sure you
        cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/StarDist_3D_ZeroCostDL4Mic.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - StarDist
        - segmentation
        - ZeroCostDL4Mic
        - 3D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/StarDist_3D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      status: passed
    - id: Notebook_Noise2Void_2D_ZeroCostDL4Mic
      name: Noise2Void (2D) - ZeroCostDL4Mic
      description: >-
        Noise2Void 2D is deep-learning method that can be used to denoise 2D
        microscopy images. By running this notebook, you can train your own
        network and denoise your images. Note - visit the ZeroCostDL4Mic wiki to
        check the original publications this network is based on and make sure
        you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Romain Laine and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Noise2Void_2D_ZeroCostDL4Mic.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - Noise2VOID
        - denoising
        - ZeroCostDL4Mic
        - 2D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Noise2Void_2D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_Noise2Void_2D_ZeroCostDL4Mic
      type: application
      status: passed
    - id: Notebook_Noise2Void_3D_ZeroCostDL4Mic
      name: Noise2VOID (3D) - ZeroCostDL4Mic
      description: >-
        Noise2VOID 3D is deep-learning method that can be used to denoise 3D
        microscopy images. By running this notebook, you can train your own
        network and denoise your images. Note - visit the ZeroCostDL4Mic wiki to
        check the original publications this network is based on and make sure
        you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Romain Laine and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Noise2Void_3D_ZeroCostDL4Mic.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - Noise2Void
        - denoising
        - ZeroCostDL4Mic
        - 3D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Noise2Void_3D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_Noise2Void_3D_ZeroCostDL4Mic
      type: application
      status: passed
    - id: Notebook_CARE_2D_ZeroCostDL4Mic
      name: CARE (2D) - ZeroCostDL4Mic
      description: >-
        CARE is a neural network capable of image restoration from corrupted
        bio-images, first published in 2018 by Weigert et al. in Nature Methods.
        The network allows image denoising and resolution improvement in 2D and
        3D images, in a supervised training manner. The function of the network
        is essentially determined by the set of images provided in the training
        dataset. For instance, if noisy images are provided as input and high
        signal-to-noise ratio images are provided as targets, the network will
        perform denoising. Note - visit the ZeroCostDL4Mic wiki to check the
        original publications this network is based on and make sure you cite
        these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Lucas von Chamier and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/CARE_2D_ZeroCostDL4Mic.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - CARE
        - denoising
        - ZeroCostDL4Mic
        - 2D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/CARE_2D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_CARE_2D_ZeroCostDL4Mic
      type: application
      status: passed
    - id: Notebook_CARE_3D_ZeroCostDL4Mic
      name: CARE (3D) - ZeroCostDL4Mic
      description: >-
        CARE is a neural network capable of image restoration from corrupted
        bio-images, first published in 2018 by Weigert et al. in Nature Methods.
        The network allows image denoising and resolution improvement in 2D and
        3D images, in a supervised training manner. The function of the network
        is essentially determined by the set of images provided in the training
        dataset. For instance, if noisy images are provided as input and high
        signal-to-noise ratio images are provided as targets, the network will
        perform denoising. Note - visit the ZeroCostDL4Mic wiki to check the
        original publications this network is based on and make sure you cite
        these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Lucas von Chamier and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/CARE_3D_ZeroCostDL4Mic.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - CARE
        - denoising
        - ZeroCostDL4Mic
        - 3D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/CARE_3D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_CARE_3D_ZeroCostDL4Mic
      type: application
      status: passed
    - id: Notebook_fnet_3D_ZeroCostDL4Mic
      name: Label-free Prediction - fnet - (3D) ZeroCostDL4Mic
      description: >-
        Label-free Prediction (fnet) is a neural network used to infer the
        features of cellular structures from brightfield or EM images without
        coloured labels. The network is trained using paired training images
        from the same field of view, imaged in a label-free (e.g. brightfield)
        and labelled condition (e.g. fluorescent protein). When trained, this
        allows the user to identify certain structures from brightfield images
        alone. The performance of fnet may depend significantly on the structure
        at hand. Note - visit the ZeroCostDL4Mic wiki to check the original
        publications this network is based on and make sure you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Lucas von Chamier and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/fnet_3D_ZeroCostDL4Mic.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - fnet
        - labelling
        - ZeroCostDL4Mic
        - 3D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/fnet_3D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_fnet_3D_ZeroCostDL4Mic
      type: application
      status: passed
    - id: Notebook_fnet_2D_ZeroCostDL4Mic
      name: Label-free Prediction - fnet - (2D) ZeroCostDL4Mic
      description: >-
        Label-free Prediction (fnet) is a neural network used to infer the
        features of cellular structures from brightfield or EM images without
        coloured labels. The network is trained using paired training images
        from the same field of view, imaged in a label-free (e.g. brightfield)
        and labelled condition (e.g. fluorescent protein). When trained, this
        allows the user to identify certain structures from brightfield images
        alone. The performance of fnet may depend significantly on the structure
        at hand. Note - visit the ZeroCostDL4Mic wiki to check the original
        publications this network is based on and make sure you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Lucas von Chamier and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/fnet_2D_ZeroCostDL4Mic.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - fnet
        - labelling
        - ZeroCostDL4Mic
        - 2D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/fnet_2D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      status: passed
    - id: Notebook_Deep-STORM_2D_ZeroCostDL4Mic
      name: Deep-STORM (2D) - ZeroCostDL4Mic
      description: >-
        Deep-STORM is a neural network capable of image reconstruction from
        high-density single-molecule localization microscopy (SMLM), first
        published in 2018 by Nehme et al. in Optica. This network allows image
        reconstruction of 2D super-resolution images, in a supervised training
        manner. The network is trained using simulated high-density SMLM data
        for which the ground-truth is available. These simulations are obtained
        from random distribution of single molecules in a field-of-view and
        therefore do not imprint structural priors during training. The network
        output a super-resolution image with increased pixel density (typically
        upsampling factor of 8 in each dimension). Note - visit the
        ZeroCostDL4Mic wiki to check the original publications this network is
        based on and make sure you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Romain Laine and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Deep-STORM_2D_ZeroCostDL4Mic.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - Deep-STORM
        - labelling
        - ZeroCostDL4Mic
        - 2D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Deep-STORM_2D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_Deep-STORM_ZeroCostDL4Mic
      type: application
      status: passed
    - id: Notebook_pix2pix_2D_ZeroCostDL4Mic
      name: pix2pix (2D) - ZeroCostDL4Mic
      description: >-
        pix2pix is a deep-learning method that can be used to translate one type
        of images into another. While pix2pix can potentially be used for any
        type of image-to-image translation, we demonstrate that it can be used
        to predict a fluorescent image from another fluorescent image. Note -
        visit the ZeroCostDL4Mic wiki to check the original publications this
        network is based on and make sure you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/pix2pix_ZeroCostDL4Mic.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - pix2pix
        - ZeroCostDL4Mic
        - 2D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/pix2pix_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_pix2pix_ZeroCostDL4Mic
      type: application
      status: passed
    - id: Notebook_CycleGAN_2D_ZeroCostDL4Mic
      name: CycleGAN (2D) - ZeroCostDL4Mic
      description: >-
        CycleGAN is a method that can capture the characteristics of one image
        domain and figure out how these characteristics could be translated into
        another image domain, all in the absence of any paired training examples
        (ie transform a horse into zebra or apples into oranges). While CycleGAN
        can potentially be used for any type of image-to-image translation, we
        illustrate that it can be used to predict what a fluorescent label would
        look like when imaged using another imaging modalities. Note - visit the
        ZeroCostDL4Mic wiki to check the original publications this network is
        based on and make sure you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/CycleGAN_ZeroCostDL4Mic.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - CycleGAN
        - ZeroCostDL4Mic
        - 2D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/CycleGAN_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_CycleGAN_ZeroCostDL4Mic
      type: application
      status: passed
    - id: Notebook_Augmentor_ZeroCostDL4Mic
      name: Augmentor - ZeroCostDL4Mic
      description: >-
        Augmentor is a data augmentation library. Data augmentation can improve
        training progress by amplifying differences in the dataset. This can be
        useful if the available dataset is small since, in this case, it is
        possible that a network could quickly learn every example in the dataset
        (overfitting), without augmentation. Augmentation can be especially
        valuable when training dataset need to be manually labelled. Note -
        visit the ZeroCostDL4Mic wiki to check the original publications this
        network is based on and make sure you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Tools/Augmentor_ZeroCostDL4Mic.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - Augmentor
        - Data Augmentation
        - ZeroCostDL4Mic
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Tools/Augmentor_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      status: passed
    - id: Notebook_DenoiSeg_2D_ZeroCostDL4Mic
      name: DenoiSeg (2D) - ZeroCostDL4Mic
      description: >-
        DenoiSeg 2D is deep-learning method that can be used to jointly denoise
        and segment 2D microscopy images. The benefits of using DenoiSeg
        (compared to other Deep Learning-based segmentation methods) are more
        prononced when only a few annotated images are available. However, the
        denoising part requires many images to perform well. All the noisy
        images don't need to be labeled to train DenoiSeg. Note - visit the
        ZeroCostDL4Mic wiki to check the original publications this network is
        based on and make sure you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/DenoiSeg_ZeroCostDL4Mic.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - CycleGAN
        - ZeroCostDL4Mic
        - 2D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/DenoiSeg_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      status: passed
    - id: Notebook_Deep-STORM_2D_ZeroCostDL4Mic_DeepImageJ
      name: Deep-STORM (2D) - ZeroCostDL4Mic - DeepImageJ
      description: >-
        Deep-STORM is a neural network capable of image reconstruction from
        high-density single-molecule localization microscopy (SMLM), first
        published in 2018 by Nehme et al. in Optica. This network allows image
        reconstruction of 2D super-resolution images, in a supervised training
        manner. The network is trained using simulated high-density SMLM data
        for which the ground-truth is available. These simulations are obtained
        from random distribution of single molecules in a field-of-view and
        therefore do not imprint structural priors during training. The network
        output a super-resolution image with increased pixel density (typically
        upsampling factor of 8 in each dimension). Note - visit the
        ZeroCostDL4Mic wiki to check the original publications this network is
        based on and make sure you cite these. Networks trained in this notebook
        can be used in Fiji via deepImageJ and ThunderSTORM plugin.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - >-
          Estibaliz Gómez de Mariscal and the deepImageJ and the ZeroCostDL4Mic
          teams
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/BioImage.io%20notebooks/Deep-STORM_2D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - Deep-STORM
        - DeepImageJ
        - ZeroCostDL4Mic
        - 2D
        - deepImageJ
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/BioImage.io%20notebooks/Deep-STORM_2D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_Deep-STORM_ZeroCostDL4Mic
      type: application
      status: passed
    - id: Notebook_U-Net_3D_ZeroCostDL4Mic_DeepImageJ
      name: U-Net (3D) - ZeroCostDL4Mic - DeepImageJ
      description: >-
        The 3D U-Net was first introduced by Çiçek et al for learning dense
        volumetric segmentations from sparsely annotated ground-truth data
        building upon the original U-Net architecture by Ronneberger et al. Note
        - visit the ZeroCostDL4Mic wiki to check the original publications this
        network is based on and make sure you cite these. Networks trained in
        this notebook can be used in Fiji via deepImageJ.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - >-
          Estibaliz Gómez de Mariscal and the deepImageJ and the ZeroCostDL4Mic
          teams
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/BioImage.io%20notebooks/U-Net_3D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - U-Net
        - segmentation
        - ZeroCostDL4Mic
        - 3D
        - deepimagej
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/BioImage.io%20notebooks/U-Net_3D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      status: passed
    - id: Notebook_U-Net_2D_ZeroCostDL4Mic_DeepImageJ
      name: U-Net (2D) - ZeroCostDL4Mic - DeepImageJ
      description: >-
        U-Net is an encoder-decoder architecture originally used for image
        segmentation. The first half of the U-Net architecture is a downsampling
        convolutional neural network which acts as a feature extractor from
        input images. The other half upsamples these results and restores an
        image by combining results from downsampling with the upsampled images.
        Note - visit the ZeroCostDL4Mic wiki to check the original publications
        this network is based on and make sure you cite these. Networks trained
        in this notebook can be used in Fiji via deepImageJ.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - >-
          Estibaliz Gómez de Mariscal and the deepImageJ and the ZeroCostDL4Mic
          teams
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/BioImage.io%20notebooks/U-Net_2D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - U-Net
        - segmentation
        - ZeroCostDL4Mic
        - 2D
        - deepimagej
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/BioImage.io%20notebooks/U-Net_2D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      status: passed
    - id: Notebook_U-Net_2D_multilabel_ZeroCostDL4Mic
      name: U-Net (2D) multilabel segmentation - ZeroCostDL4Mic
      description: >-
        U-Net is an encoder-decoder architecture originally used for image
        segmentation. The first half of the U-Net architecture is a downsampling
        convolutional neural network which acts as a feature extractor from
        input images. The other half upsamples these results and restores an
        image by combining results from downsampling with the upsampled images.
        Note - visit the ZeroCostDL4Mic wiki to check the original publications
        this network is based on and make sure you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Estibaliz Gómez de Mariscal and the ZeroCostDL4Mic teams
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/U-Net_2D_Multilabel_ZeroCostDL4Mic.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - u-net
        - segmentation
        - semantic-segmentation
        - multilabel
        - ZeroCostDL4Mic
        - 2D
      source: >-
        https://github.com/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/U-Net_2D_Multilabel_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      status: passed
    - id: Notebook_StarDist_2D_ZeroCostDL4Mic_DeepImageJ
      name: StarDist (2D) - ZeroCostDL4Mic - DeepImageJ
      description: >-
        StarDist is a deep-learning method that can be used to segment cell
        nuclei in 2D (xy) images. Note - visit the ZeroCostDL4Mic wiki to check
        the original publications this network is based on and make sure you
        cite these. Networks trained in this notebook can be used in Fiji via
        deepImageJ and StarDist plugins for ImageJ.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - >-
          Estibaliz Gómez de Mariscal and the deepImageJ and the ZeroCostDL4Mic
          teams
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/BioImage.io%20notebooks/StarDist_2D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - StarDist
        - segmentation
        - ZeroCostDL4Mic
        - 2D
        - deepimagej
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/BioImage.io%20notebooks/StarDist_2D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      status: passed
    - id: Notebook_RCAN_3D_ZeroCostDL4Mic
      name: RCAN (3D) - ZeroCostDL4Mic
      description: >-
        RCAN is a neural network capable of image restoration from corrupted
        bio-images. The network allows image denoising and resolution
        improvement in 3D images, in a supervised training manner. The function
        of the network is essentially determined by the set of images provided
        in the training dataset. For instance, if noisy images are provided as
        input and high signal-to-noise ratio images are provided as targets, the
        network will perform denoising. Note - visit the ZeroCostDL4Mic wiki to
        check the original publications this network is based on and make sure
        you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/3D-RCAN_ZeroCostDL4Mic.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - CARE
        - denoising
        - ZeroCostDL4Mic
        - 3D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/3D-RCAN_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_CARE_3D_ZeroCostDL4Mic
      type: application
      status: passed
    - id: Notebook_SplineDist_2D_ZeroCostDL4Mic
      name: SplineDist (2D) - ZeroCostDL4Mic
      description: >-
        SplineDist is a neural network inspired by StarDist, capable of
        performing image instance segmentation. Unlike StarDist, SplineDist uses
        cubic splines to describe the contour of each object and therefore can
        potentially segment objects of any shapes. This version is only for 2D
        dataset. Note - visit the ZeroCostDL4Mic wiki to check the original
        publications this network is based on and make sure you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Romain F. Laine and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/SplineDist_overlay_cropped.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/SplineDist_2D_ZeroCostDL4Mic.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - SplineDist
        - segmentation
        - ZeroCostDL4Mic
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/SplineDist_2D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_StarDist_2D_ZeroCostDL4Mic_2D
        - Dataset_StarDist_Fluo_ZeroCostDL4Mic
        - Dataset_StarDist_brightfield_ZeroCostDL4Mic
        - Dataset_StarDist_brightfield2_ZeroCostDL4Mic
      type: application
      status: passed
    - id: Notebook_YOLOv2_ZeroCostDL4Mic
      name: YOLOv2 - ZeroCostDL4Mic
      description: >-
        YOLOv2 is an object detection network developed by Redmon & Farhadi,
        which identifies objects in images and draws bounding boxes around them.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Lucas von Chamier and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/YOLOv2_ZeroCostDL4Mic.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - YOLOv2
        - object detection
        - ZeroCostDL4Mic
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/YOLOv2_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_YOLOv2_ZeroCostDL4Mic
      type: application
      status: passed
    - id: Notebook_Detectron2_ZeroCostDL4Mic
      name: Detectron2 - ZeroCostDL4Mic
      description: >-
        Detectron2 is an object detection network developed by Facebook AI
        Research, which identifies objects in images and draws bounding boxes
        around them.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/Detectron2_2D_ZeroCostDL4Mic.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - Detectron2
        - object detection
        - ZeroCostDL4Mic
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/Detectron2_2D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_YOLOv2_ZeroCostDL4Mic
      type: application
      status: passed
    - id: Notebook_DRMIME_ZeroCostDL4Mic
      name: DRMIME - ZeroCostDL4Mic
      description: >-
        DRMIME is an network that can be used to register microscopy images
        (affine and perspective registration).
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/DRMIME_2D_ZeroCostDL4Mic.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - DRMIME
        - image registration
        - ZeroCostDL4Mic
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/DRMIME_2D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      status: passed
    - id: Notebook_Cellpose_2D_ZeroCostDL4Mic
      name: Cellpose (2D) - ZeroCostDL4Mic
      description: Cellpose is a generalist algorithm for cellular segmentation.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/Cellpose_2D_ZeroCostDL4Mic.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - Cellpose
        - Segmentation
        - ZeroCostDL4Mic
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/Cellpose_2D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_StarDist_2D_ZeroCostDL4Mic_2D
        - Dataset_StarDist_Fluo_ZeroCostDL4Mic
        - Dataset_StarDist_brightfield_ZeroCostDL4Mic
        - Dataset_StarDist_brightfield2_ZeroCostDL4Mic
      type: application
      status: passed
    - id: Notebook_RetinaNet_ZeroCostDL4Mic
      name: RetinaNet - ZeroCostDL4Mic
      description: >-
        RetinaNet is a is an object detection network, which identifies objects
        in images and draws bounding boxes around them.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Erlantz Calvo, Ignacio Arganda-Carreras and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/RetinaNet_ZeroCostDL4Mic.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - RetinaNet
        - object detection
        - ZeroCostDL4Mic
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/RetinaNet_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_YOLOv2_ZeroCostDL4Mic
      type: application
      status: passed
    - id: Notebook_DecoNoising_2D_ZeroCostDL4Mic
      name: DecoNoising (2D) - ZeroCostDL4Mic
      description: >-
        DecoNoising 2D is deep-learning method that can be used to denoise 2D
        microscopy images. By running this notebook, you can train your own
        network and denoise your images. Note - visit the ZeroCostDL4Mic wiki to
        check the original publications this network is based on and make sure
        you cite these.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/DecoNoising_2D_ZeroCostDL4Mic.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - DecoNoising
        - denoising
        - ZeroCostDL4Mic
        - 2D
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/DecoNoising_2D_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
        - Dataset_Noise2Void_2D_ZeroCostDL4Mic
      type: application
      status: passed
    - id: Notebook_Interactive_Segmentation_Kaibu_2D_ZeroCostDL4Mic
      name: Interactive Segmentation - Kaibu (2D) - ZeroCostDL4Mic
      description: Interactive Segmentation using Kaibu and Cellpose.
      cite:
        - text: >-
            Ouyang W, Le T, Xu H and Lundberg E. Interactive biomedical
            segmentation tool powered by deep learning and ImJoy [version 1;
            peer review: 1 approved, 1 approved with reservations].
            F1000Research 2021, 10:142
            (https://doi.org/10.12688/f1000research.50798.1)
          doi: https://doi.org/10.12688/f1000research.50798.1
      authors:
        - Romain Laine, Wei Ouyang and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/ZeroCostDL4Mic_Interactive_annotations_Cellpose.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - Cellpose
        - Segmentation
        - ZeroCostDL4Mic
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/ZeroCostDL4Mic_Interactive_annotations_Cellpose.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      status: passed
    - id: Notebook_MaskRCNN_ZeroCostDL4Mic
      name: MaskRCNN - ZeroCostDL4Mic
      description: >-
        MaskRCNN is a is an object detection and segmentation network, which
        identifies objects in images and draws bounding boxes around them.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Lucas von Chamier and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/MaskRCNN_ZeroCostDL4Mic.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - MaskRCNN
        - object detection
        - ZeroCostDL4Mic
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/MaskRCNN_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      status: passed
    - id: Notebook_Quality_Control_ZeroCostDL4Mic
      name: Quality Control - ZeroCostDL4Mic
      description: >-
        This notebooks enable to perform error mapping and quality metrics
        estimation.
      cite:
        - text: >-
            von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep
            learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276
            (2021). https://doi.org/10.1038/s41467-021-22518-0
          doi: https://doi.org/10.1038/s41467-021-22518-0
      authors:
        - Guillaume Jacquemet and the ZeroCostDL4Mic Team
      covers:
        - >-
          https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
      badges:
        - label: Open in Colab
          icon: https://colab.research.google.com/assets/colab-badge.svg
          url: >-
            https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Tools/Quality_Control_ZeroCostDL4Mic.ipynb
      documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
      tags:
        - colab
        - notebook
        - Quality Control
        - ZeroCostDL4Mic
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Tools/Quality_Control_ZeroCostDL4Mic.ipynb
      git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
      links:
        - Notebook Preview
      type: application
      status: passed
    - id: Fiji
      name: Fiji
      description: >-
        Fiji is an image processing package — a "batteries-included"
        distribution of ImageJ, bundling many plugins which facilitate
        scientific image analysis.
      source: https://fiji.sc/
      cite:
        text: >-
          Schindelin, J., Arganda-Carreras, I., Frise, E. et al. Fiji: an
          open-source platform for biological-image analysis. Nat Methods 9,
          676–682 (2012).
        doi: https://doi.org/10.1038/nmeth.2019
      authors:
        - Fiji community
      icon: >-
        https://raw.githubusercontent.com/bioimage-io/fiji-bioimage-io/master/Fiji-icon.png
      documentation: https://fiji.sc/
      git_repo: https://github.com/fiji/fiji,
      passive: true
      tags:
        - fiji
        - software
      type: application
      status: passed
config:
  splash_title: BioImage Model Zoo
  splash_subtitle: Advanced AI models in one-click
  splash_feature_list:
    - Integrate with Fiji, Ilastik, ImJoy
    - Try model instantly with BioEngine
    - Contribute your models via Github
    - Link models to datasets and applications
  explore_button_text: Start Exploring
  background_image: static/img/zoo-background.svg
  resource_types:
    - model
    - application
    - notebook
    - dataset
  default_type: model
  url_root: >-
    https://raw.githubusercontent.com/bioimage-io/collection-bioimage-io/gh-pages
  partners:
    - id: zero
      source: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/manifest.bioimage.io.yaml
      name: ZeroCostDL4Mic
      version: 1.7.1
      tags:
        - ZeroCostDL4Mic
      logo: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/ZeroCostLogo.png
      icon: >-
        https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/ZeroCostLogo.png
      splash_title: ZeroCostDL4Mic
      splash_subtitle: >-
        A Google Colab based no-cost toolbox to explore Deep-Learning in
        Microscopy
      splash_feature_list: []
      explore_button_text: Start Exploring
      background_image: static/img/zoo-background.svg
      resource_types:
        - model
        - application
        - dataset
      default_type: application
      url_root: https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master
    - id: deepimagej
      source: >-
        https://raw.githubusercontent.com/deepimagej/models/master/manifest.bioimage.io.yaml
      name: DeepImageJ
      tags:
        - deepimagej
      logo: >-
        https://raw.githubusercontent.com/deepimagej/models/master/logos/logo.png
      icon: >-
        https://raw.githubusercontent.com/deepimagej/models/master/logos/icon.png
      splash_title: deepImageJ
      splash_subtitle: A user-friendly plugin to run deep learning models in ImageJ
      splash_feature_list: null
      explore_button_text: Start Exploring
      background_image: static/img/zoo-background.svg
      resource_types:
        - model
        - notebook
        - application
      url_root: https://raw.githubusercontent.com/deepimagej/models/master
    - id: fiji
      source: >-
        https://raw.githubusercontent.com/bioimage-io/fiji-bioimage-io/master/manifest.bioimage.io.yaml
      name: Fiji
      tags:
        - fiji
      logo: https://fiji.sc/site/logo.png
      icon: https://fiji.sc/site/logo.png
      splash_title: Fiji
      splash_subtitle: Fiji is just ImageJ
      splash_feature_list: []
      explore_button_text: Start Exploring
      background_image: static/img/zoo-background.svg
      resource_types:
        - model
        - notebook
      url_root: https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master
    - id: imjoy
      source: >-
        https://raw.githubusercontent.com/imjoy-team/bioimage-io-models/master/manifest.bioimage.io.yaml
      name: ImJoy
      tags:
        - imjoy
      logo: https://imjoy.io/static/img/imjoy-icon.svg
      icon: https://imjoy.io/static/img/imjoy-icon.svg
      splash_title: ImJoy
      splash_subtitle: Deep Learning Made Easy!
      splash_feature_list:
        - Minimal and flexible plugin powered web application
        - Server-less progressive web application with offline support
        - Rich and interactive user interface powered by web technologies
      explore_button_text: Start Exploring
      background_image: static/img/zoo-background.svg
      resource_types:
        - notebook
        - application
      default_type: application
      url_root: https://raw.githubusercontent.com/imjoy-team/bioimage-io-models/master
    - id: ilastik
      source: >-
        https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/manifest.bioimage.io.yaml
      name: ilastik
      tags:
        - ilastik
      logo: >-
        https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/image/ilastik-fist-icon.png
      icon: >-
        https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/image/ilastik-fist-icon.png
      splash_title: ilastik
      splash_subtitle: the interactive learning and segmentation toolkit
      splash_feature_list: null
      explore_button_text: Start Exploring
      background_image: static/img/zoo-background.svg
      resource_types:
        - model
        - application
      default_type: model
      url_root: https://raw.githubusercontent.com/ilastik/bioimage-io-models/main
    - id: hpa
      source: >-
        https://raw.githubusercontent.com/CellProfiling/HPA-model-zoo/master/manifest.bioimage.io.yaml
      name: HPA
      tags:
        - hpa
      logo: >-
        https://raw.githubusercontent.com/bioimage-io/tfjs-bioimage-io/master/apps/hpa-logo.gif
      icon: >-
        https://raw.githubusercontent.com/bioimage-io/tfjs-bioimage-io/master/apps/hpa-logo.gif
      about_url: https://www.proteinatlas.org/
      splash_title: The Human Protein Atlas
      splash_subtitle: null
      splash_feature_list: []
      explore_button_text: Start Exploring
      background_image: static/img/zoo-background.svg
      resource_types:
        - model
        - application
      default_type: model

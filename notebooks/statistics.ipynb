{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "1. [Setup](#Setup)\n",
    "2. [Inspecting download counts](#Inspecting-download-counts)\n",
    "3. [Contributed resources](#Contributed-resources)\n",
    "4. [Average processing time of proposed contributions](#Average-processing-time-of-proposed-contributions)\n",
    "5. [Cleanup](#cleanup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import mkdtemp\n",
    "from pathlib import Path\n",
    "from shutil import rmtree\n",
    "from subprocess import run\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "def cleanup(folder):\n",
    "    print(f\"Cleaning up {folder}\")\n",
    "    try:\n",
    "        rmtree(folder)\n",
    "    except Exception as e:\n",
    "        warnings.warn(str(e))\n",
    "\n",
    "if \"temp_dir\" in locals():\n",
    "    cleanup(temp_dir)\n",
    "\n",
    "temp_dir = mkdtemp()\n",
    "\n",
    "os.chdir(temp_dir)\n",
    "run(\"git clone https://github.com/bioimage-io/collection-bioimage-io.git --branch gh-pages --single-branch\", check=True)\n",
    "os.chdir(\"collection-bioimage-io\")\n",
    "print(f\"working in {Path().absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting download counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = run('git log --pretty=format:\"%H,%aI\" download_counts.json', check=True, capture_output=True)\n",
    "log = out.stdout.decode().split()\n",
    "print(len(log), log[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime\n",
    "from typing import NewType, Dict\n",
    "\n",
    "Hash = NewType(\"Hash\", str)\n",
    "all_commits: Dict[date, Dict[datetime, Hash]] = {}\n",
    "hash: Hash\n",
    "for log_entry in log:\n",
    "    hash, iso_datetime = log_entry.split(\",\")\n",
    "    dt = datetime.fromisoformat(iso_datetime)\n",
    "    d = dt.date()\n",
    "    day = all_commits.setdefault(d, {})\n",
    "    assert dt not in day\n",
    "    day[dt] = hash\n",
    "\n",
    "commits: Dict[date, Hash] = {}\n",
    "for d, day in all_commits.items():\n",
    "    commits[d] = max(day.items())[1]\n",
    "\n",
    "len(commits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import CalledProcessError \n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "\n",
    "all_downloads: Dict[date, int] = {}\n",
    "try:\n",
    "    for d, hash in tqdm(commits.items(), total=len(commits)):\n",
    "        out = run(f\"git checkout --force {hash}\", check=True, capture_output=True)\n",
    "        with Path(\"download_counts.json\").open() as f:\n",
    "            counts = json.load(f)\n",
    "        \n",
    "        all_downloads[d] = sum(counts.values())\n",
    "except CalledProcessError:\n",
    "    print(out.stdout.decode())\n",
    "    raise\n",
    "finally:\n",
    "    run(\"git checkout --force gh-pages\", check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(all_downloads, name=\"total downloads\")\n",
    "series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"darkgrid\", context=\"talk\")\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(16, 4))\n",
    "\n",
    "(series / 1e3).plot(kind='line',ax=axs, title=series.name)\n",
    "plt.xlabel(\"date\")\n",
    "plt.ylabel(\"10Â³\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contributed resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(\"collection.json\").open() as f:\n",
    "    collection = json.load(f)\n",
    "\n",
    "col = collection[\"collection\"]\n",
    "print(\"total:\", len(col))\n",
    "per_type = {}\n",
    "for e in col:\n",
    "    t = e[\"type\"]\n",
    "    per_type[t] = per_type.get(t, 0) + 1\n",
    "\n",
    "print(\"per type:\", per_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average processing time of proposed contributions\n",
    "\n",
    "Here we analyze the time it takes to close a generated PR that proposes to update the bioimage.io collection based on a new Zenodo record (version).\n",
    "\n",
    "These PRs are created by the [@bioimageiobot](https://github.com/bioimageiobot) and tagged with the 'auto-update' label.\n",
    "They have to be closed/merged by a (human) bioimage.io maintainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import os\n",
    "import requests\n",
    "\n",
    "url = \"https://api.github.com/graphql\"\n",
    "gh_token = os.getenv(\"GITHUB_TOKEN\")\n",
    "assert gh_token is not None, \"Missing env var 'GITHUB_TOKEN'\"\n",
    "query = \"\"\"\n",
    "{\n",
    "  search(query: \"repo:bioimage-io/collection-bioimage-io is:pr author:bioimageiobot is:closed sort:created-desc\", type: ISSUE, first: 100) {\n",
    "    edges {\n",
    "      node {\n",
    "        ... on PullRequest {\n",
    "          createdAt\n",
    "          closedAt\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    pageInfo {\n",
    "      hasNextPage\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "r = requests.post(url, auth=(\"TOKEN\", gh_token), json={'query': query}).json()\n",
    "assert \"data\" in r, r\n",
    "data = r[\"data\"]\n",
    "edges = data[\"search\"][\"edges\"][::-1]  # revert descending order to asceding\n",
    "\n",
    "start = edges[0]['node']['createdAt']\n",
    "end = edges[-1]['node']['closedAt']\n",
    "print(f\"{len(edges)} PRs from {start} to {end}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import isoparse \n",
    "from numpy import busday_count, mean\n",
    "\n",
    "from holidays import country_holidays\n",
    "\n",
    "local_holidays = country_holidays(\"Germany\", subdiv=\"BW\")[start:end]\n",
    "\n",
    "_durations = {}\n",
    "for edge in edges:\n",
    "    created = isoparse(edge[\"node\"][\"createdAt\"])\n",
    "    closed = isoparse(edge[\"node\"][\"closedAt\"])\n",
    "    delta = busday_count(created.date(), closed.date(), holidays=local_holidays)\n",
    "    _durations[created] = delta\n",
    "\n",
    "dur_col = \"duration [work days in BW]\"\n",
    "durations = pd.DataFrame(_durations.items(), columns=(\"created\", dur_col))\n",
    "durations[dur_col].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(16, 4))\n",
    "durations.plot(kind=\"scatter\", x=\"created\", y=dur_col, ax=axes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{"name":"BioImage.IO","type":"collection","description":"BioImage.IO RDF collections","tags":[],"version":"0.1.0","authors":[{"name":"BioImgae.IO Team"}],"documentation":"./README.md","git_repo":"https://github.com/bioimage-io/collection-bioimage-io","icon":"https://raw.githubusercontent.com/bioimage-io/bioimage.io/main/public/static/icons/android-chrome-384x384.png","attachments":{"zenodo":[{"id":"10.5072/zenodo.921275","name":"HPA Bestfitting Densenet","type":"model","authors":[{"name":"Shubin Dai"}],"tags":["bioimage.io","bioimage.io:model","classification","densenet-121","hpa","onnx","cells","protein-localization","zenodo"],"description":"The winning model of HPA image classification 2019 by Bestfitting","stats":{"downloads":35,"unique_downloads":14,"unique_views":0,"version_downloads":40,"version_unique_downloads":14,"version_unique_views":1,"version_views":1,"version_volume":71436856,"views":0,"volume":71371587},"license":"MIT","documentation":"https://sandbox.zenodo.org/api/files/5d346d01-76ce-4cda-98b3-93b5f2bf4cde/README.md","covers":["https://sandbox.zenodo.org/api/files/5d346d01-76ce-4cda-98b3-93b5f2bf4cde/bestfitting-densenet-diagram.png"],"source":"https://sandbox.zenodo.org/api/files/5d346d01-76ce-4cda-98b3-93b5f2bf4cde/rdf.yaml","links":["imjoy/BioImageIO-Packager"],"config":{"_doi":"10.5072/zenodo.921277","_conceptdoi":"10.5072/zenodo.921275","_rdf_file":"https://sandbox.zenodo.org/api/files/5d346d01-76ce-4cda-98b3-93b5f2bf4cde/rdf.yaml"}},{"id":"10.5072/zenodo.907585","name":"Widefield Super-resolution (GAN - TxRed)","type":"model","authors":[{"affiliation":"University of California, Los Angeles, CA, USA","name":"Hongda Wang"},{"affiliation":"University of California, Los Angeles, CA, USA","name":"Yair Rivenson"},{"affiliation":"University of California, Los Angeles, CA, USA","name":"Aydogan Ozcan"}],"tags":["bioimage.io","bioimage.io:model","deepimagej","gan","fluorescence-microscopy","super-resolution","zenodo"],"description":"A trained GAN to transform diffraction-limited input images into super-resolved ones.","stats":{"downloads":466,"unique_downloads":209,"unique_views":5,"version_downloads":1018,"version_unique_downloads":543,"version_unique_views":9,"version_views":11,"version_volume":433758730,"views":7,"volume":397077617},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/67a7eae5-2290-4b61-b273-eee0fa916d90/README.md","covers":["https://sandbox.zenodo.org/api/files/67a7eae5-2290-4b61-b273-eee0fa916d90/exampleImage.png","https://sandbox.zenodo.org/api/files/67a7eae5-2290-4b61-b273-eee0fa916d90/resultImage.png"],"source":"https://sandbox.zenodo.org/api/files/67a7eae5-2290-4b61-b273-eee0fa916d90/model.yaml","links":["imjoy/BioImageIO-Packager","deepimagej/deepimagej"],"config":{"_doi":"10.5072/zenodo.913992","_conceptdoi":"10.5072/zenodo.907585","_rdf_file":"https://sandbox.zenodo.org/api/files/67a7eae5-2290-4b61-b273-eee0fa916d90/model.yaml"}},{"id":"10.5072/zenodo.908833","name":"Widefield Super-resolution (GAN - FITC)","type":"model","authors":[{"affiliation":"University of California, Los Angeles, CA, USA","name":"Hongda Wang"},{"affiliation":"University of California, Los Angeles, CA, USA","name":"Yair Rivenson"},{"affiliation":"University of California, Los Angeles, CA, USA","name":"Aydogan Ozcan"}],"tags":["bioimage.io","bioimage.io:model","deepimagej","gan","fluorescence-microscopy","super-resolution","zenodo"],"description":"A trained GAN to transform diffraction-limited input images into super-resolved ones.","stats":{"downloads":477,"unique_downloads":213,"unique_views":3,"version_downloads":933,"version_unique_downloads":480,"version_unique_views":8,"version_views":12,"version_volume":726039711,"views":3,"volume":684074996},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/8b1d0c16-db10-4645-ae11-5c4296415a2e/README.md","covers":["https://sandbox.zenodo.org/api/files/8b1d0c16-db10-4645-ae11-5c4296415a2e/exampleImage.png","https://sandbox.zenodo.org/api/files/8b1d0c16-db10-4645-ae11-5c4296415a2e/resultImage.png"],"source":"https://sandbox.zenodo.org/api/files/8b1d0c16-db10-4645-ae11-5c4296415a2e/model.yaml","links":["imjoy/BioImageIO-Packager","deepimagej/deepimagej"],"config":{"_doi":"10.5072/zenodo.914425","_conceptdoi":"10.5072/zenodo.908833","_rdf_file":"https://sandbox.zenodo.org/api/files/8b1d0c16-db10-4645-ae11-5c4296415a2e/model.yaml"}},{"id":"10.5072/zenodo.907595","name":"Widefield Super-resolution (GAN - DAPI)","type":"model","authors":[{"affiliation":"University of California, Los Angeles, CA, USA","name":"Hongda Wang"},{"affiliation":"University of California, Los Angeles, CA, USA","name":"Yair Rivenson"},{"affiliation":"University of California, Los Angeles, CA, USA","name":"Aydogan Ozcan"}],"tags":["bioimage.io","bioimage.io:model","deepimagej","gan","fluorescence-microscopy","super-resolution","zenodo"],"description":"A trained GAN to transform diffraction-limited input images into super-resolved ones.","stats":{"downloads":489,"unique_downloads":233,"unique_views":3,"version_downloads":942,"version_unique_downloads":464,"version_unique_views":10,"version_views":10,"version_volume":57690942,"views":3,"volume":25863680},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/1e074efe-d7ac-48b0-af75-1c604aad31f7/README.md","covers":["https://sandbox.zenodo.org/api/files/1e074efe-d7ac-48b0-af75-1c604aad31f7/exampleImage.png","https://sandbox.zenodo.org/api/files/1e074efe-d7ac-48b0-af75-1c604aad31f7/resultImage.png"],"source":"https://sandbox.zenodo.org/api/files/1e074efe-d7ac-48b0-af75-1c604aad31f7/model.yaml","links":["imjoy/BioImageIO-Packager","deepimagej/deepimagej"],"config":{"_doi":"10.5072/zenodo.914422","_conceptdoi":"10.5072/zenodo.907595","_rdf_file":"https://sandbox.zenodo.org/api/files/1e074efe-d7ac-48b0-af75-1c604aad31f7/model.yaml"}},{"id":"10.5072/zenodo.905080","name":"Pancreatic Cell Phase Contrast Segmentation (DeepWater - CTC submission)","type":"model","authors":[{"affiliation":"Centre for Biomedical Image Analysis, Masaryk University","name":"Filip Lux"},{"affiliation":"Centre for Biomedical Image Analysis, Masaryk University","name":"Petr Matula"}],"tags":["bioimage.io","bioimage.io:model","deepwater","deepimagej","segmentation","watershed","cell-tracking-challenge","phase-contrast","zenodo"],"description":"The method combines deep learning with watershed segmentation. For each frame, the convolutional neural network of U-Net shape detects all cells by markers and recognizes the foreground and the background of the frame. Then, the final segmentation is generated by a Marker-Controlled Watershed transformation.","stats":{"downloads":305,"unique_downloads":227,"unique_views":2,"version_downloads":859,"version_unique_downloads":650,"version_unique_views":9,"version_views":12,"version_volume":201537943,"views":2,"volume":96510025},"license":"MIT","documentation":"https://sandbox.zenodo.org/api/files/05933bba-2a1d-4b6f-935e-26528ddc450a/README.md","covers":["https://sandbox.zenodo.org/api/files/05933bba-2a1d-4b6f-935e-26528ddc450a/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/05933bba-2a1d-4b6f-935e-26528ddc450a/model.yaml","links":["deepimagej/deepimagej","imjoy/bioimageio-packager","deepimagej/unet-pancreaticcellsegmentation"],"config":{"_doi":"10.5072/zenodo.914413","_conceptdoi":"10.5072/zenodo.905080","_rdf_file":"https://sandbox.zenodo.org/api/files/05933bba-2a1d-4b6f-935e-26528ddc450a/model.yaml"}},{"id":"10.5072/zenodo.905991","name":"HeLa DIC Cell Segmentation (U-Net)","type":"model","authors":[{"affiliation":"EPFL, UC3M","name":"DeepImageJ"}],"tags":["bioimage.io","bioimage.io:model","deepimagej","hela-cells","segmentation","phase-contrast","zenodo"],"description":"DeepImageJ compatible U-Net trained to segment Hela cells in 2D phase contrast microscopy images","stats":{"downloads":358,"unique_downloads":235,"unique_views":3,"version_downloads":659,"version_unique_downloads":518,"version_unique_views":20,"version_views":25,"version_volume":6527433945,"views":4,"volume":6519769240},"license":"BSD-2-Clause","documentation":"https://sandbox.zenodo.org/api/files/7450899d-5536-42f6-afac-8a27684d7c98/README.md","covers":["https://sandbox.zenodo.org/api/files/7450899d-5536-42f6-afac-8a27684d7c98/unet_hela_seg.jpg"],"source":"https://sandbox.zenodo.org/api/files/7450899d-5536-42f6-afac-8a27684d7c98/model.yaml","links":["imjoy/BioImageIO-Packager","deepimagej/deepimagej"],"config":{"_doi":"10.5072/zenodo.913978","_conceptdoi":"10.5072/zenodo.905991","_rdf_file":"https://sandbox.zenodo.org/api/files/7450899d-5536-42f6-afac-8a27684d7c98/model.yaml"}},{"id":"10.5072/zenodo.849110","name":"3D UNet - arabidopsis - ZeroCostDL4Mic","type":"model","authors":[{"affiliation":"UC3M, EPFL","name":"DeepImageJ"},{"affiliation":"PIP python package","name":"pydeepimagej"}],"tags":["bioimage.io","bioimage.io:model","zerocostdl4mic","deepimagej","segmentation","3dunet","zenodo"],"description":"Trained 3D U-Net to segment arabidopsis ovaries boundaries in confocal microscopy 3D volumes.","stats":{"downloads":966,"unique_downloads":493,"unique_views":4,"version_downloads":6492,"version_unique_downloads":2931,"version_unique_views":50,"version_views":61,"version_volume":5874097494,"views":6,"volume":1395891775},"license":"MIT","documentation":"https://sandbox.zenodo.org/api/files/494811fc-a47e-45e9-952e-be006dfa084f/README.md","covers":["https://sandbox.zenodo.org/api/files/494811fc-a47e-45e9-952e-be006dfa084f/input.png","https://sandbox.zenodo.org/api/files/494811fc-a47e-45e9-952e-be006dfa084f/output.png"],"source":"https://sandbox.zenodo.org/api/files/494811fc-a47e-45e9-952e-be006dfa084f/model.yaml","links":["imjoy/BioImageIO-Packager","deepimagej/deepimagej","ilastik/ilastik","zero/notebook_u-net_3d_zerocostdl4mic_deepimagej"],"config":{"_doi":"10.5072/zenodo.908534","_conceptdoi":"10.5072/zenodo.849110","_rdf_file":"https://sandbox.zenodo.org/api/files/494811fc-a47e-45e9-952e-be006dfa084f/model.yaml"}},{"id":"10.5072/zenodo.906808","name":"Glial Cell SMLM (DeepSTORM - ZeroCostDL4Mic)","type":"model","authors":[{"affiliation":"UCL, Francis Crick Institute, Turku and Åbo Akademi University","name":"ZeroCostDL4Mic team"},{"affiliation":"UC3M, EPFL","name":"DeepImageJ team"}],"tags":["bioimage.io","bioimage.io:model","zerocostdl4mic","deepimagej","smlm","image-reconstruction","super-resolution","zenodo"],"description":"A trained Deep-STORM model for image reconstruction from high-density single-molecule localization microscopy (SMLM).","stats":{"downloads":989,"unique_downloads":540,"unique_views":3,"version_downloads":1033,"version_unique_downloads":570,"version_unique_views":5,"version_views":7,"version_volume":460823829,"views":4,"volume":387255609},"license":"MIT","documentation":"https://sandbox.zenodo.org/api/files/586c72d8-d5fe-42bc-b9a4-8faff6de6963/README.md","covers":["https://sandbox.zenodo.org/api/files/586c72d8-d5fe-42bc-b9a4-8faff6de6963/input.png","https://sandbox.zenodo.org/api/files/586c72d8-d5fe-42bc-b9a4-8faff6de6963/zoom.png"],"source":"https://sandbox.zenodo.org/api/files/586c72d8-d5fe-42bc-b9a4-8faff6de6963/model.yaml","links":["deepimagej/deepimagej","zero/notebook_deep-storm_2d_zerocostdl4mic_deepimagej","imjoy/bioimageio-packager","deepimagej/smlm-deepimagej"],"config":{"_doi":"10.5072/zenodo.907832","_conceptdoi":"10.5072/zenodo.906808","_rdf_file":"https://sandbox.zenodo.org/api/files/586c72d8-d5fe-42bc-b9a4-8faff6de6963/model.yaml"}},{"id":"10.5072/zenodo.906784","name":"3D U-Net - ZeroCostDL4Mic","type":"model","authors":[{"affiliation":"EPFL, UC3M","name":"DeepImageJ team"}],"tags":["bioimage.io","bioimage.io:model","deepimagej","tem","mitochondria","segmentation","3d-unet","zerocostdl4mic","deepimagej-beta","zenodo"],"description":"3D U-Net trained using ZeroCostDL4Mic notebooks to segment mitochondria in Transmission Electron Microscopy (TEM) data.","stats":{"downloads":567,"unique_downloads":497,"unique_views":0,"version_downloads":594,"version_unique_downloads":523,"version_unique_views":1,"version_views":1,"version_volume":3222979412,"views":0,"volume":3222910246},"license":"MIT","documentation":"https://sandbox.zenodo.org/api/files/52771cb2-5886-41a3-b8ee-4def7203951f/README.md","covers":["https://sandbox.zenodo.org/api/files/52771cb2-5886-41a3-b8ee-4def7203951f/exampleImage.gif"],"source":"https://sandbox.zenodo.org/api/files/52771cb2-5886-41a3-b8ee-4def7203951f/model.yaml","links":["deepimagej/deepimagej","zero/notebook_u-net_3d_zerocostdl4mic_deepimagej","imjoy/bioimageio-packager"],"config":{"_doi":"10.5072/zenodo.907831","_conceptdoi":"10.5072/zenodo.906784","_rdf_file":"https://sandbox.zenodo.org/api/files/52771cb2-5886-41a3-b8ee-4def7203951f/model.yaml"}},{"id":"10.5072/zenodo.906806","name":"Skin lesions classification","type":"model","authors":[{"affiliation":"UC3M","name":"Carlos García-López-de-Haro"}],"tags":["bioimage.io","bioimage.io:model","deepimagej-beta","deepimagej","skin-lesions","melanoma","classification","pytorch","zenodo"],"description":"CNN trained to classify the type of imaged skin lesion.","stats":{"downloads":611,"unique_downloads":545,"unique_views":2,"version_downloads":611,"version_unique_downloads":545,"version_unique_views":2,"version_views":2,"version_volume":157176969,"views":2,"volume":157176969},"license":"BSD-2-Clause","documentation":"https://sandbox.zenodo.org/api/files/5218d3ab-9b32-47ea-891e-0da59e849ad6/README.md","covers":["https://sandbox.zenodo.org/api/files/5218d3ab-9b32-47ea-891e-0da59e849ad6/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/5218d3ab-9b32-47ea-891e-0da59e849ad6/model.yaml","links":["imjoy/BioImageIO-Packager","deepimagej/deepimagej"],"config":{"_doi":"10.5072/zenodo.906807","_conceptdoi":"10.5072/zenodo.906806","_rdf_file":"https://sandbox.zenodo.org/api/files/5218d3ab-9b32-47ea-891e-0da59e849ad6/model.yaml"}},{"id":"10.5072/zenodo.906804","name":"Masson's Trichrome Virtual Staining (GAN)","type":"model","authors":[{"affiliation":"University of California","name":"Yair Rivenson"},{"affiliation":"University of California","name":"Hongda Wang"},{"affiliation":"University of California","name":"Aydogan Ozcan"}],"tags":["bioimage.io","bioimage.io:model","deepimagej","gan","virtual-staining","histology","zenodo"],"description":"A trained GAN to transform wide-field autofluorescence images of unlabelled tissue sections into images that are equivalent to the bright-field images of histologically stained versions of the same samples.","stats":{"downloads":946,"unique_downloads":529,"unique_views":0,"version_downloads":946,"version_unique_downloads":529,"version_unique_views":0,"version_views":0,"version_volume":91350476,"views":0,"volume":91350476},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/0dcd8dec-ed38-4d10-a487-025597c207b6/README.md","covers":["https://sandbox.zenodo.org/api/files/0dcd8dec-ed38-4d10-a487-025597c207b6/exampleImage.png","https://sandbox.zenodo.org/api/files/0dcd8dec-ed38-4d10-a487-025597c207b6/resultImage.png"],"source":"https://sandbox.zenodo.org/api/files/0dcd8dec-ed38-4d10-a487-025597c207b6/model.yaml","links":["imjoy/BioImageIO-Packager","deepimagej/deepimagej"],"config":{"_doi":"10.5072/zenodo.906805","_conceptdoi":"10.5072/zenodo.906804","_rdf_file":"https://sandbox.zenodo.org/api/files/0dcd8dec-ed38-4d10-a487-025597c207b6/model.yaml"}},{"id":"10.5072/zenodo.906802","name":"Jones Virtual Staining (GAN)","type":"model","authors":[{"affiliation":"University of California","name":"Yair Rivenson"},{"affiliation":"University of California","name":"Hongda Wang"},{"affiliation":"University of California","name":"Aydogan Ozcan"}],"tags":["bioimage.io","bioimage.io:model","deepimagej","gan","virtual-staining","histology","zenodo"],"description":"A trained GAN to transform wide-field autofluorescence images of unlabelled tissue sections into images that are equivalent to the bright-field images of histologically stained versions of the same samples.","stats":{"downloads":944,"unique_downloads":530,"unique_views":0,"version_downloads":944,"version_unique_downloads":530,"version_unique_views":0,"version_views":0,"version_volume":89787802,"views":0,"volume":89787802},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/bfac9db5-f773-4d1b-a0f8-754628b3f5b3/README.md","covers":["https://sandbox.zenodo.org/api/files/bfac9db5-f773-4d1b-a0f8-754628b3f5b3/exampleImage.png","https://sandbox.zenodo.org/api/files/bfac9db5-f773-4d1b-a0f8-754628b3f5b3/resultImage.png"],"source":"https://sandbox.zenodo.org/api/files/bfac9db5-f773-4d1b-a0f8-754628b3f5b3/model.yaml","links":["imjoy/BioImageIO-Packager","deepimagej/deepimagej"],"config":{"_doi":"10.5072/zenodo.906803","_conceptdoi":"10.5072/zenodo.906802","_rdf_file":"https://sandbox.zenodo.org/api/files/bfac9db5-f773-4d1b-a0f8-754628b3f5b3/model.yaml"}},{"id":"10.5072/zenodo.894458","name":"Small Extracellular Vesicle TEM Segmentation (Fully Residual U-Net)","type":"model","authors":[{"affiliation":"Universidad Carlos III de Madrid","name":"Estibaliz Gómez-de-Mariscal"},{"affiliation":"Masaryk University","name":"Martin Maška"},{"affiliation":"Masaryk University","name":"Anna Kotrbová"},{"affiliation":"Masaryk University","name":"Vendula Pospíchalová"},{"affiliation":"Masaryk University","name":"Pavel Matula"},{"affiliation":"Universidad Carlos III de Madrid","name":"Arrate Muñoz-Barrutia"}],"tags":["bioimage.io","bioimage.io:model","deepimagej","extracellular-vesicles","segmentation","tem","frunet","exosomes","electron-microscopy","2d-segmentation","zenodo"],"description":"DeepImageJ compatible fully residual U-Net trained to segment small extracellular vesicles in 2D TEM images","stats":{"downloads":647,"unique_downloads":595,"unique_views":1,"version_downloads":1233,"version_unique_downloads":778,"version_unique_views":12,"version_views":35,"version_volume":10578498936,"views":1,"volume":217985927},"license":"BSD-3-Clause","documentation":"https://sandbox.zenodo.org/api/files/15f6cc78-b503-4880-966d-6a865794c9e8/README.md","covers":["https://sandbox.zenodo.org/api/files/15f6cc78-b503-4880-966d-6a865794c9e8/frunet_sev.jpg"],"source":"https://sandbox.zenodo.org/api/files/15f6cc78-b503-4880-966d-6a865794c9e8/model.yaml","links":["deepimagej/deepimagej","imjoy/bioimageio-packager","deepimagej/evstemsegmentationfrunet","ilastik/ilastik"],"config":{"_doi":"10.5072/zenodo.906449","_conceptdoi":"10.5072/zenodo.894458","_rdf_file":"https://sandbox.zenodo.org/api/files/15f6cc78-b503-4880-966d-6a865794c9e8/model.yaml"}},{"id":"10.5072/zenodo.904904","name":"2D UNet - ZeroCostDL4Mic","type":"model","authors":[{"name":"ZeroCostDL4Mic"},{"affiliation":"EPFL, UC3M","name":"DeepImageJ"}],"tags":["bioimage.io","bioimage.io:model","zerocostdl4mic","deepimagej","segmentation","tem","unet","zenodo"],"description":"2D U-Net trained for binary segmentation using the EM images of neuronal membranes and segmentation masks from the ISBI segmentation challenge 2012.","stats":{"downloads":1248,"unique_downloads":672,"unique_views":12,"version_downloads":1248,"version_unique_downloads":672,"version_unique_views":12,"version_views":12,"version_volume":456844069,"views":12,"volume":456844069},"license":"MIT","documentation":"https://sandbox.zenodo.org/api/files/d6bdaa4f-d337-4c06-85ed-3d1430a2784b/README.md","covers":["https://sandbox.zenodo.org/api/files/d6bdaa4f-d337-4c06-85ed-3d1430a2784b/input.png","https://sandbox.zenodo.org/api/files/d6bdaa4f-d337-4c06-85ed-3d1430a2784b/output.png"],"source":"https://sandbox.zenodo.org/api/files/d6bdaa4f-d337-4c06-85ed-3d1430a2784b/model.yaml","links":["imjoy/BioImageIO-Packager","deepimagej/deepimagej","zero/notebook_u-net_2d_zerocostdl4mic_deepimagej"],"config":{"_doi":"10.5072/zenodo.904905","_conceptdoi":"10.5072/zenodo.904904","_rdf_file":"https://sandbox.zenodo.org/api/files/d6bdaa4f-d337-4c06-85ed-3d1430a2784b/model.yaml"}},{"id":"10.5072/zenodo.880528","name":"Multi-Organ Nucleus Segmentation (StarDist 2D)","type":"model","authors":[{"affiliation":"EPFL, UC3M","name":"DeepImageJ team"},{"affiliation":"Universidad Carlos III de Madrid","name":"Estibaliz Gómez de Mariscal"}],"tags":["bioimage.io","bioimage.io:model","segmentation","histopathology","histology","stardist","nucleus-segmentation","zerocostdl4mic","trainable","deepimagej","digital-pathology","zenodo"],"description":"Nucleus segmentation in digital pathology datasets using a StarDist trained model in 2D. The dataset is the one provided in the MoNuSeg 2018 Challenge.","stats":{"downloads":2967,"unique_downloads":1213,"unique_views":5,"version_downloads":5408,"version_unique_downloads":1904,"version_unique_views":19,"version_views":32,"version_volume":4048831372,"views":7,"volume":1907454611},"license":"MIT","documentation":"https://sandbox.zenodo.org/api/files/954ada81-d28f-47de-b9d3-686559c76401/README.md","covers":["https://sandbox.zenodo.org/api/files/954ada81-d28f-47de-b9d3-686559c76401/combined.jpg","https://sandbox.zenodo.org/api/files/954ada81-d28f-47de-b9d3-686559c76401/input.png","https://sandbox.zenodo.org/api/files/954ada81-d28f-47de-b9d3-686559c76401/output.png"],"source":"https://sandbox.zenodo.org/api/files/954ada81-d28f-47de-b9d3-686559c76401/model.yaml","links":["zero/notebook_stardist_2d_zerocostdl4mic_deepimagej","deepimagej/deepimagej","imjoy/bioimageio-packager","deepimagej/monuseg_digital_pathology_miccai2018"],"config":{"_doi":"10.5072/zenodo.894493","_conceptdoi":"10.5072/zenodo.880528","_rdf_file":"https://sandbox.zenodo.org/api/files/954ada81-d28f-47de-b9d3-686559c76401/model.yaml"}},{"id":"10.5072/zenodo.886788","name":"ISBI2012-2D-AffinityModel","type":"model","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:model","u-net","neuron-segmentation","segmentation","volume-em","isbi2012-challenge","boundary-prediction","zenodo"],"description":"ISBI2012-2D-AffinityModel","stats":{"downloads":1506,"unique_downloads":1382,"unique_views":18,"version_downloads":1506,"version_unique_downloads":1382,"version_unique_views":18,"version_views":24,"version_volume":638332060,"views":24,"volume":638332060},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/678d163d-baa9-4c9a-987b-a1b3f0ac1bae/documentation.md","covers":["https://sandbox.zenodo.org/api/files/678d163d-baa9-4c9a-987b-a1b3f0ac1bae/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/678d163d-baa9-4c9a-987b-a1b3f0ac1bae/rdf.yaml","links":["10.5072/zenodo.881019","ilastik/ilastik","deepimagej/deepimagej","imjoy/BioImageIO-Packager"],"config":{"_doi":"10.5072/zenodo.886789","_conceptdoi":"10.5072/zenodo.886788","_rdf_file":"https://sandbox.zenodo.org/api/files/678d163d-baa9-4c9a-987b-a1b3f0ac1bae/rdf.yaml"}},{"id":"10.5072/zenodo.849032","name":"SMLM Density Map Estimation (DEFCoN)","type":"model","authors":[{"name":"Wei"}],"tags":["bioimage.io","bioimage.io:model","deepimagej","smlm","defcon","density estimation","zenodo"],"description":"This is a test model","stats":{"downloads":1637,"unique_downloads":1539,"unique_views":9,"version_downloads":3491,"version_unique_downloads":2782,"version_unique_views":20,"version_views":25,"version_volume":47886067,"views":9,"volume":20418033},"license":"BSD-1-Clause","documentation":"https://github.com/LEB-EPFL/DEFCoN-ImageJ/wiki","covers":["https://sandbox.zenodo.org/api/files/472b09aa-f70b-48e9-b836-6ab560e3b70c/cover_image.jpg"],"source":"https://sandbox.zenodo.org/api/files/472b09aa-f70b-48e9-b836-6ab560e3b70c/model.yaml","links":["imjoy/BioImageIO-Packager","deepimagej/deepimagej"],"config":{"_doi":"10.5072/zenodo.885236","_conceptdoi":"10.5072/zenodo.849032","_rdf_file":"https://sandbox.zenodo.org/api/files/472b09aa-f70b-48e9-b836-6ab560e3b70c/model.yaml"}},{"id":"10.5072/zenodo.881018","name":"ISBI Challenge: Segmentation of neuronal structures in EM stacks","type":"dataset","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:dataset","neuron-segmentation","em-segmentation","isbi2012-challenge","zenodo"],"description":"First challenge on 2d segmentation of neuronal processes in EM images. Organised as part of the ISBI2012 conference.","stats":{"downloads":677,"unique_downloads":557,"unique_views":2,"version_downloads":682,"version_unique_downloads":560,"version_unique_views":15,"version_views":18,"version_volume":352911805,"views":2,"volume":352888913},"license":"CC-BY-4.0","documentation":"http://brainiac2.mit.edu/isbi_challenge/home","covers":["https://sandbox.zenodo.org/api/files/6f7f9164-f183-4b3c-9201-362187b2ba9f/cover0.jpg","https://sandbox.zenodo.org/api/files/6f7f9164-f183-4b3c-9201-362187b2ba9f/cover1.gif"],"source":"https://sandbox.zenodo.org/api/files/6f7f9164-f183-4b3c-9201-362187b2ba9f/rdf.yaml","links":[],"config":{"_doi":"10.5072/zenodo.883893","_conceptdoi":"10.5072/zenodo.881018","_rdf_file":"https://sandbox.zenodo.org/api/files/6f7f9164-f183-4b3c-9201-362187b2ba9f/rdf.yaml"}},{"id":"10.5072/zenodo.881848","name":"Covid-IF-Cells-BoundaryModel","type":"model","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:model","u-net","cell-segmentation","htm","high-throughput-microscopt","segmentation","cells","covid-antibody-test","covid-19","sars-cov-2","immunofluorescence","affinity-prediction","zenodo"],"description":"Covid-IF-Cells-BoundaryModel","stats":{"downloads":1782,"unique_downloads":1578,"unique_views":4,"version_downloads":2042,"version_unique_downloads":1630,"version_unique_views":5,"version_views":6,"version_volume":3967593157,"views":4,"volume":1645978691},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/886646e7-8b7c-4e7b-a4e4-05c0343d6704/documentation.md","covers":["https://sandbox.zenodo.org/api/files/886646e7-8b7c-4e7b-a4e4-05c0343d6704/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/886646e7-8b7c-4e7b-a4e4-05c0343d6704/rdf.yaml","links":["ilastik/ilastik","deepimagej/deepimagej","10.5072/zenodo.881843","imjoy/BioImageIO-Packager"],"config":{"_doi":"10.5072/zenodo.882211","_conceptdoi":"10.5072/zenodo.881848","_rdf_file":"https://sandbox.zenodo.org/api/files/886646e7-8b7c-4e7b-a4e4-05c0343d6704/rdf.yaml"}},{"id":"10.5072/zenodo.881944","name":"Platyereis-nuclei-BoundaryModel","type":"model","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:model","u-net","nuclei-segmentation","segmentation","volume-em","platynereis","nuclei","affinity-prediction","zenodo"],"description":"Platyereis-nuclei-BoundaryModel","stats":{"downloads":1656,"unique_downloads":1493,"unique_views":9,"version_downloads":1807,"version_unique_downloads":1536,"version_unique_views":11,"version_views":15,"version_volume":1460715135,"views":9,"volume":855110871},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/c36de755-742d-4e34-9ffc-211d583d0ef1/documentation.md","covers":["https://sandbox.zenodo.org/api/files/c36de755-742d-4e34-9ffc-211d583d0ef1/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/c36de755-742d-4e34-9ffc-211d583d0ef1/rdf.yaml","links":["deepimagej/deepimagej","10.5072/zenodo.881899","ilastik/ilastik"],"config":{"_doi":"10.5072/zenodo.882210","_conceptdoi":"10.5072/zenodo.881944","_rdf_file":"https://sandbox.zenodo.org/api/files/c36de755-742d-4e34-9ffc-211d583d0ef1/rdf.yaml"}},{"id":"10.5072/zenodo.881942","name":"CREMI-BoundaryModel","type":"model","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:model","u-net","neuron-segmentation","segmentation","volume-em","cremi","connectomics","affinity-prediction","zenodo"],"description":"CREMI-BoundaryModel","stats":{"downloads":1650,"unique_downloads":1466,"unique_views":1,"version_downloads":1779,"version_unique_downloads":1506,"version_unique_views":4,"version_views":9,"version_volume":4441559190,"views":3,"volume":2883038738},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/24ddb8e3-c9f0-459a-93f6-5d0a7703e6d0/documentation.md","covers":["https://sandbox.zenodo.org/api/files/24ddb8e3-c9f0-459a-93f6-5d0a7703e6d0/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/24ddb8e3-c9f0-459a-93f6-5d0a7703e6d0/rdf.yaml","links":["10.5072/zenodo.881917","ilastik/ilastik","deepimagej/deepimagej"],"config":{"_doi":"10.5072/zenodo.882209","_conceptdoi":"10.5072/zenodo.881942","_rdf_file":"https://sandbox.zenodo.org/api/files/24ddb8e3-c9f0-459a-93f6-5d0a7703e6d0/rdf.yaml"}},{"id":"10.5072/zenodo.880412","name":"EM-Mitochondria-BoundaryModel","type":"model","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:model","u-net","mitochondria-segmentation","segmentation","mito-em","mitochondria","affinity-prediction","zenodo"],"description":"EM-Mitochondria-BoundaryModel","stats":{"downloads":635,"unique_downloads":438,"unique_views":3,"version_downloads":2259,"version_unique_downloads":1569,"version_unique_views":11,"version_views":16,"version_volume":19087232527,"views":4,"volume":6846655036},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/81fa667e-293f-4f3f-aca7-b352f6546c7f/documentation.md","covers":["https://sandbox.zenodo.org/record/882067/files/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/81fa667e-293f-4f3f-aca7-b352f6546c7f/rdf.yaml","links":["ilastik/ilastik","deepimagej/deepimagej","imjoy/BioImageIO-Packager"],"config":{"_doi":"10.5072/zenodo.882193","_conceptdoi":"10.5072/zenodo.880412","_rdf_file":"https://sandbox.zenodo.org/api/files/81fa667e-293f-4f3f-aca7-b352f6546c7f/rdf.yaml"}},{"id":"10.5072/zenodo.881973","name":"Arabidopsis-ovules-BoundaryModel","type":"model","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:model","u-net","ovules-segmentation","segmentation","light-microscopy","arabidopsis","ovules","confocal-microscopy","affinity-prediction","zenodo"],"description":"Arabidopsis-ovules-BoundaryModel","stats":{"downloads":1697,"unique_downloads":1342,"unique_views":5,"version_downloads":1808,"version_unique_downloads":1360,"version_unique_views":6,"version_views":10,"version_volume":3948999885,"views":6,"volume":3118346166},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/83af3b6d-77b9-4fec-b488-402ddae756c8/documentation.md","covers":["https://sandbox.zenodo.org/api/files/83af3b6d-77b9-4fec-b488-402ddae756c8/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/83af3b6d-77b9-4fec-b488-402ddae756c8/rdf.yaml","links":["ilastik/ilastik","10.5072/zenodo.881893","deepimagej/deepimagej","imjoy/BioImageIO-Packager"],"config":{"_doi":"10.5072/zenodo.882064","_conceptdoi":"10.5072/zenodo.881973","_rdf_file":"https://sandbox.zenodo.org/api/files/83af3b6d-77b9-4fec-b488-402ddae756c8/rdf.yaml"}},{"id":"10.5072/zenodo.881940","name":"DSB-Nuclei-BoundaryModelNew","type":"model","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:model","u-net","nucleus-segmentation","segmentation","volume-em","platynereis","nuclei","affinity-prediction","zenodo"],"description":"DSB-Nuclei-BoundaryModel","stats":{"downloads":1540,"unique_downloads":1290,"unique_views":8,"version_downloads":1594,"version_unique_downloads":1302,"version_unique_views":8,"version_views":16,"version_volume":1435416713,"views":15,"volume":1199671274},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/bc7c3c89-23e5-47f4-8a0d-e95b4f73bad3/documentation.md","covers":["https://sandbox.zenodo.org/api/files/bc7c3c89-23e5-47f4-8a0d-e95b4f73bad3/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/bc7c3c89-23e5-47f4-8a0d-e95b4f73bad3/rdf.yaml","links":["10.5072/zenodo.881915","ilastik/ilastik","deepimagej/deepimagej","imjoy/BioImageIO-Packager"],"config":{"_doi":"10.5072/zenodo.881989","_conceptdoi":"10.5072/zenodo.881940","_rdf_file":"https://sandbox.zenodo.org/api/files/bc7c3c89-23e5-47f4-8a0d-e95b4f73bad3/rdf.yaml"}},{"id":"10.5072/zenodo.881916","name":"CREMI: MICCAI Challenge on Circuit Reconstruction from Electron Microscopy Images","type":"dataset","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:dataset","neuron-segmentation","em-segmentation","cremi-challenge","zenodo"],"description":"The goal of this challenge is to evaluate algorithms for automatic reconstruction of neurons and neuronal connectivity from serial section electron microscopy data.","stats":{"downloads":784,"unique_downloads":546,"unique_views":3,"version_downloads":784,"version_unique_downloads":546,"version_unique_views":3,"version_views":4,"version_volume":47586016,"views":4,"volume":47586016},"license":"CC-BY-4.0","documentation":"https://cremi.org/","covers":["https://sandbox.zenodo.org/api/files/a762cbb3-5722-49ca-bc2e-75e77e741a6a/cover0.png","https://sandbox.zenodo.org/api/files/a762cbb3-5722-49ca-bc2e-75e77e741a6a/cover1.png","https://sandbox.zenodo.org/api/files/a762cbb3-5722-49ca-bc2e-75e77e741a6a/cover2.png"],"source":"https://sandbox.zenodo.org/api/files/a762cbb3-5722-49ca-bc2e-75e77e741a6a/rdf.yaml","links":[],"config":{"_doi":"10.5072/zenodo.881917","_conceptdoi":"10.5072/zenodo.881916","_rdf_file":"https://sandbox.zenodo.org/api/files/a762cbb3-5722-49ca-bc2e-75e77e741a6a/rdf.yaml"}},{"id":"10.5072/zenodo.881914","name":"DSB Nucleus Segmentation Training Data","type":"dataset","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:dataset","nucleus-segmentation","dsb","dsb2018","zenodo"],"description":"Subset of the nucleus segmentation training data provided by the 2018 Kaggle Data Science Bowl.","stats":{"downloads":543,"unique_downloads":535,"unique_views":3,"version_downloads":543,"version_unique_downloads":535,"version_unique_views":3,"version_views":3,"version_volume":1706854,"views":3,"volume":1706854},"license":"CC-BY-4.0","documentation":"https://www.kaggle.com/c/data-science-bowl-2018","covers":["https://sandbox.zenodo.org/api/files/9335cedd-0a6f-458d-a28e-ac4a79216e2e/cover0.jpg"],"source":"https://sandbox.zenodo.org/api/files/9335cedd-0a6f-458d-a28e-ac4a79216e2e/rdf.yaml","links":[],"config":{"_doi":"10.5072/zenodo.881915","_conceptdoi":"10.5072/zenodo.881914","_rdf_file":"https://sandbox.zenodo.org/api/files/9335cedd-0a6f-458d-a28e-ac4a79216e2e/rdf.yaml"}},{"id":"10.5072/zenodo.881898","name":"Platynereis EM traning data","type":"dataset","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:dataset","em-segmentation","platynereis","platynereis dumerilii","cell-segmentation","cilia-segmentation","nucleus-segmentation","zenodo"],"description":"Training data for EM cell, nuclei and organelle segmentation in Platynereis dumerilii. Contains training data for cellular membranes, nuclei, cuticle and cilia.","stats":{"downloads":537,"unique_downloads":528,"unique_views":1,"version_downloads":537,"version_unique_downloads":528,"version_unique_views":1,"version_views":1,"version_volume":12632188,"views":1,"volume":12632188},"license":"CC-BY-4.0","documentation":"https://www.biorxiv.org/content/10.1101/2020.02.26.961037v1.abstract","covers":["https://sandbox.zenodo.org/api/files/d1278f8e-1f20-4c69-a86b-8f7dd4b89291/cover0.png"],"source":"https://sandbox.zenodo.org/api/files/d1278f8e-1f20-4c69-a86b-8f7dd4b89291/rdf.yaml","links":[],"config":{"_doi":"10.5072/zenodo.881899","_conceptdoi":"10.5072/zenodo.881898","_rdf_file":"https://sandbox.zenodo.org/api/files/d1278f8e-1f20-4c69-a86b-8f7dd4b89291/rdf.yaml"}},{"id":"10.5072/zenodo.881892","name":"Arabidopsis thaliana ovules - confocal","type":"dataset","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:dataset","confocal","lm-segmentation","arabidopsis","arabidopsis thaliana","ovules","plants","zenodo"],"description":"Ovules - confocal volumetric stacks with voxel size: (0.235x0.075x0.075 µm^3) (ZYX). Courtesy of Kay Schneitz lab, School of Life Sciences, Technical University of Munich, Germany.","stats":{"downloads":526,"unique_downloads":516,"unique_views":1,"version_downloads":526,"version_unique_downloads":516,"version_unique_views":1,"version_views":1,"version_volume":7234135,"views":1,"volume":7234135},"license":"CC-BY-4.0","documentation":"https://osf.io/uzq3w/wiki/home/","covers":["https://sandbox.zenodo.org/api/files/c396ca77-12e7-4f02-9ab3-01dbbaa32def/cover0.png"],"source":"https://sandbox.zenodo.org/api/files/c396ca77-12e7-4f02-9ab3-01dbbaa32def/rdf.yaml","links":[],"config":{"_doi":"10.5072/zenodo.881893","_conceptdoi":"10.5072/zenodo.881892","_rdf_file":"https://sandbox.zenodo.org/api/files/c396ca77-12e7-4f02-9ab3-01dbbaa32def/rdf.yaml"}},{"id":"10.5072/zenodo.881842","name":"CovidIf training data","type":"dataset","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:dataset","cell-segmentation","nucleus-segmentation","high-througput-microscopy","covid-19","sars-cov-2","zenodo"],"description":"Training data for cell, nucleus and infection classification in IF data of Covid-19 infected cells.","stats":{"downloads":721,"unique_downloads":510,"unique_views":1,"version_downloads":721,"version_unique_downloads":510,"version_unique_views":1,"version_views":1,"version_volume":6323562,"views":1,"volume":6323562},"license":"CC-BY-4.0","documentation":"https://onlinelibrary.wiley.com/doi/full/10.1002/bies.202000257","covers":["https://sandbox.zenodo.org/api/files/75b365f2-a335-43cb-892a-93e35b2d7c98/cover0.jpg","https://sandbox.zenodo.org/api/files/75b365f2-a335-43cb-892a-93e35b2d7c98/cover1.jpg","https://sandbox.zenodo.org/api/files/75b365f2-a335-43cb-892a-93e35b2d7c98/cover2.jpg"],"source":"https://sandbox.zenodo.org/api/files/75b365f2-a335-43cb-892a-93e35b2d7c98/rdf.yaml","links":[],"config":{"_doi":"10.5072/zenodo.881843","_conceptdoi":"10.5072/zenodo.881842","_rdf_file":"https://sandbox.zenodo.org/api/files/75b365f2-a335-43cb-892a-93e35b2d7c98/rdf.yaml"}},{"id":"10.5072/zenodo.880273","name":"ISBI2012-2D-BoundaryModel","type":"model","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:model","u-net","neuron-segmentation","segmentation","volume-em","isbi2012-challenge","affinity-prediction","zenodo"],"description":"ISBI2012-2D-BoundaryModel","stats":{"downloads":1589,"unique_downloads":1331,"unique_views":4,"version_downloads":2141,"version_unique_downloads":1533,"version_unique_views":17,"version_views":28,"version_volume":1385039130,"views":6,"volume":473157030},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/9567559e-501c-4106-be15-8e10fbbe2390/documentation.md","covers":["https://sandbox.zenodo.org/api/files/9567559e-501c-4106-be15-8e10fbbe2390/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/9567559e-501c-4106-be15-8e10fbbe2390/rdf.yaml","links":["10.5072/zenodo.881019","ilastik/ilastik","deepimagej/deepimagej","imjoy/BioImageIO-Packager"],"config":{"_doi":"10.5072/zenodo.881742","_conceptdoi":"10.5072/zenodo.880273","_rdf_file":"https://sandbox.zenodo.org/api/files/9567559e-501c-4106-be15-8e10fbbe2390/rdf.yaml"}},{"id":"10.5072/zenodo.881020","name":"MitoEM Challenge: Large-scale 3D Mitochondria Instance Segmentation","type":"dataset","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:dataset","mitochondria-segmentation","em-segmentation","mito-em-challenge","zenodo"],"description":"The task is the 3D mitochondria instance segmentation on two 30x30x30 um datasets, 1000x4096x4096 in voxels at 30x8x8 nm resolution.","stats":{"downloads":0,"unique_downloads":0,"unique_views":2,"version_downloads":1,"version_unique_downloads":1,"version_unique_views":4,"version_views":5,"version_volume":801,"views":2,"volume":0},"license":"CC-BY-4.0","documentation":"https://mitoem.grand-challenge.org/","covers":["https://grand-challenge-public-prod.s3.amazonaws.com/b/566/banner.x10.jpeg","https://grand-challenge-public-prod.s3.amazonaws.com/i/2020/10/27/mitoEM_teaser.png"],"source":"https://sandbox.zenodo.org/api/files/b129783b-c251-4995-a71b-2ee0cc4ada49/mito_em.yaml","links":[],"config":{"_doi":"10.5072/zenodo.881227","_conceptdoi":"10.5072/zenodo.881020","_rdf_file":"https://sandbox.zenodo.org/api/files/b129783b-c251-4995-a71b-2ee0cc4ada49/mito_em.yaml"}},{"id":"10.5072/zenodo.872944","name":"2D UNet Arabidopsis Ovules","type":"model","authors":[{"name":"Adrian Wolny"},{"name":"Lorenzo Cerrone"}],"tags":["bioimage.io","bioimage.io:model","unet2d","pytorch","arabidopsis","ovules","cell membrane","segmentation","plant tissue","plant","zenodo"],"description":"A 2D U-Net trained to predict the cell boundaries in confocal stacks of Arabidopsis ovules. Trained on z-slices of 3D confocal images.","stats":{"downloads":2788,"unique_downloads":1444,"unique_views":7,"version_downloads":4203,"version_unique_downloads":1783,"version_unique_views":14,"version_views":19,"version_volume":803807407,"views":8,"volume":512892895},"license":"MIT","documentation":"https://sandbox.zenodo.org/api/files/36604653-1541-4891-b6bd-de5963217e5f/unet2d.md","covers":["https://sandbox.zenodo.org/api/files/36604653-1541-4891-b6bd-de5963217e5f/raw.png","https://sandbox.zenodo.org/api/files/36604653-1541-4891-b6bd-de5963217e5f/pred.png"],"source":"https://sandbox.zenodo.org/api/files/36604653-1541-4891-b6bd-de5963217e5f/rdf.yaml","links":["imjoy/BioImageIO-Packager","ilastik/ilastik"],"config":{"_doi":"10.5072/zenodo.872978","_conceptdoi":"10.5072/zenodo.872944","_rdf_file":"https://sandbox.zenodo.org/api/files/36604653-1541-4891-b6bd-de5963217e5f/rdf.yaml"}},{"id":"10.5072/zenodo.872852","name":"3D UNet Arabidopsis Ovules","type":"model","authors":[{"name":"Adrian Wolny"},{"name":"Lorenzo Cerrone"}],"tags":["bioimage.io","bioimage.io:model","unet3d","pytorch","arabidopsis","ovules","cell membrane","segmentation","plant tissue","zenodo"],"description":"A 3d U-Net trained to predict the cell boundaries in confocal stacks of Arabidopsis ovules. Voxel size: (0.235, 0.150, 0.150) microns ZYX","stats":{"downloads":6655,"unique_downloads":1600,"unique_views":1,"version_downloads":6932,"version_unique_downloads":1616,"version_unique_views":1,"version_views":1,"version_volume":7622008113,"views":1,"volume":7297659906},"license":"MIT","documentation":"https://sandbox.zenodo.org/api/files/12102045-f235-4426-afff-2b801725eb15/unet3d.md","covers":["https://sandbox.zenodo.org/api/files/12102045-f235-4426-afff-2b801725eb15/ilastik_4.png","https://sandbox.zenodo.org/api/files/12102045-f235-4426-afff-2b801725eb15/ilastik_5.png","https://sandbox.zenodo.org/api/files/12102045-f235-4426-afff-2b801725eb15/ilastik_6.png","https://sandbox.zenodo.org/api/files/12102045-f235-4426-afff-2b801725eb15/ilastik_7.png","https://sandbox.zenodo.org/api/files/12102045-f235-4426-afff-2b801725eb15/ilastik_8.png"],"source":"https://sandbox.zenodo.org/api/files/12102045-f235-4426-afff-2b801725eb15/rdf.yaml","links":["imjoy/BioImageIO-Packager"],"config":{"_doi":"10.5072/zenodo.872975","_conceptdoi":"10.5072/zenodo.872852","_rdf_file":"https://sandbox.zenodo.org/api/files/12102045-f235-4426-afff-2b801725eb15/rdf.yaml"}},{"id":"10.5072/zenodo.872914","name":"CREMI-BoundaryModel","type":"model","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:model","u-net","neuron-segmentation","segmentation","volume-em","cremi","connectomics","affinity-prediction","zenodo"],"description":"CREMI-BoundaryModel","stats":{"downloads":1423,"unique_downloads":1103,"unique_views":4,"version_downloads":1466,"version_unique_downloads":1116,"version_unique_views":5,"version_views":5,"version_volume":2546348295,"views":4,"volume":2182419308},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/406bdb5a-4dad-48cc-ae9a-d61f737d7de9/documentation.md","covers":["https://sandbox.zenodo.org/api/files/406bdb5a-4dad-48cc-ae9a-d61f737d7de9/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/406bdb5a-4dad-48cc-ae9a-d61f737d7de9/rdf.yaml","links":["imjoy/BioImageIO-Packager","ilastik/ilastik"],"config":{"_doi":"10.5072/zenodo.872956","_conceptdoi":"10.5072/zenodo.872914","_rdf_file":"https://sandbox.zenodo.org/api/files/406bdb5a-4dad-48cc-ae9a-d61f737d7de9/rdf.yaml"}},{"id":"10.5072/zenodo.872854","name":"3D UNet Lateral Root Primordia Cell Boundaries","type":"model","authors":[{"name":"Adrian Wolny"},{"name":"Lorenzo Cerrone"}],"tags":["bioimage.io","bioimage.io:model","unet3d","pytorch","arabidopsis","lateral root","cell membrane","segmentation","plant tissue","zenodo"],"description":"A 3d U-Net trained to predict the cell boundaries in lightsheet stacks of Arabidopsis Lateral Root Primordia. (0.25x0.1625x0.1625) microns ZYX","stats":{"downloads":2345,"unique_downloads":1072,"unique_views":2,"version_downloads":2368,"version_unique_downloads":1076,"version_unique_views":3,"version_views":3,"version_volume":100239265,"views":2,"volume":99091979},"license":"MIT","documentation":"https://sandbox.zenodo.org/api/files/7c3fb1b0-74aa-4b98-97c4-6cf6167c20bc/unet3d.md","covers":["https://sandbox.zenodo.org/api/files/7c3fb1b0-74aa-4b98-97c4-6cf6167c20bc/raw.png","https://sandbox.zenodo.org/api/files/7c3fb1b0-74aa-4b98-97c4-6cf6167c20bc/pred.png"],"source":"https://sandbox.zenodo.org/api/files/7c3fb1b0-74aa-4b98-97c4-6cf6167c20bc/rdf.yaml","links":["imjoy/BioImageIO-Packager","ilastik/Ilastik"],"config":{"_doi":"10.5072/zenodo.872933","_conceptdoi":"10.5072/zenodo.872854","_rdf_file":"https://sandbox.zenodo.org/api/files/7c3fb1b0-74aa-4b98-97c4-6cf6167c20bc/rdf.yaml"}},{"id":"10.5072/zenodo.872924","name":"Platyereis-nuclei-BoundaryModel","type":"model","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:model","u-net","nuclei-segmentation","segmentation","volume-em","platynereis","nuclei","affinity-prediction","zenodo"],"description":"Platyereis-nuclei-BoundaryModel","stats":{"downloads":1318,"unique_downloads":1013,"unique_views":0,"version_downloads":1318,"version_unique_downloads":1013,"version_unique_views":0,"version_views":0,"version_volume":655677914,"views":0,"volume":655677914},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/f4eab9b7-81ce-4603-93e7-9ccd3731506c/documentation.md","covers":["https://sandbox.zenodo.org/api/files/f4eab9b7-81ce-4603-93e7-9ccd3731506c/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/f4eab9b7-81ce-4603-93e7-9ccd3731506c/rdf.yaml","links":["imjoy/BioImageIO-Packager","ilastik/Ilastik"],"config":{"_doi":"10.5072/zenodo.872925","_conceptdoi":"10.5072/zenodo.872924","_rdf_file":"https://sandbox.zenodo.org/api/files/f4eab9b7-81ce-4603-93e7-9ccd3731506c/rdf.yaml"}},{"id":"10.5072/zenodo.872918","name":"Platyereis-cells-BoundaryModel","type":"model","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:model","u-net","cells-segmentation","segmentation","volume-em","platynereis","cells","affinity-prediction","zenodo"],"description":"Platyereis-cells-BoundaryModel","stats":{"downloads":1295,"unique_downloads":1005,"unique_views":0,"version_downloads":1295,"version_unique_downloads":1005,"version_unique_views":0,"version_views":0,"version_volume":495426650,"views":0,"volume":495426650},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/fc05a6ea-3aea-47fb-9760-f177d7c4a7d1/documentation.md","covers":["https://sandbox.zenodo.org/api/files/fc05a6ea-3aea-47fb-9760-f177d7c4a7d1/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/fc05a6ea-3aea-47fb-9760-f177d7c4a7d1/rdf.yaml","links":["imjoy/BioImageIO-Packager","ilastik/Ilastik"],"config":{"_doi":"10.5072/zenodo.872919","_conceptdoi":"10.5072/zenodo.872918","_rdf_file":"https://sandbox.zenodo.org/api/files/fc05a6ea-3aea-47fb-9760-f177d7c4a7d1/rdf.yaml"}},{"id":"10.5072/zenodo.872916","name":"DSB-Nuclei-BoundaryModel","type":"model","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:model","u-net","nucleus-segmentation","segmentation","volume-em","platynereis","nuclei","affinity-prediction","zenodo"],"description":"DSB-Nuclei-BoundaryModel","stats":{"downloads":1213,"unique_downloads":909,"unique_views":3,"version_downloads":1213,"version_unique_downloads":909,"version_unique_views":3,"version_views":3,"version_volume":481380280,"views":3,"volume":481380280},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/c28391fb-4935-4a76-951f-f6910dae8fbd/documentation.md","covers":["https://sandbox.zenodo.org/api/files/c28391fb-4935-4a76-951f-f6910dae8fbd/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/c28391fb-4935-4a76-951f-f6910dae8fbd/rdf.yaml","links":["imjoy/BioImageIO-Packager","ilastik/Ilastik"],"config":{"_doi":"10.5072/zenodo.872917","_conceptdoi":"10.5072/zenodo.872916","_rdf_file":"https://sandbox.zenodo.org/api/files/c28391fb-4935-4a76-951f-f6910dae8fbd/rdf.yaml"}},{"id":"10.5072/zenodo.872860","name":"3D UNet Lateral Root Primordia Nuclei","type":"model","authors":[{"name":"Adrian Wolny"},{"name":"Lorenzo Cerrone"}],"tags":["bioimage.io","bioimage.io:model","unet3d","pytorch","arabidopsis","lateral root","cell nuclei","segmentation","plant tissue","zenodo"],"description":"A variant of 3D U-Net trained on light-sheet images of Arabidopsis lateral root nuclei on original resolution. Voxel size: (0.25x0.1625x0.1625 µm^3) (ZYX).","stats":{"downloads":2340,"unique_downloads":1100,"unique_views":2,"version_downloads":2340,"version_unique_downloads":1100,"version_unique_views":2,"version_views":3,"version_volume":286755064,"views":3,"volume":286755064},"license":"MIT","documentation":"https://sandbox.zenodo.org/api/files/a6e1b0c5-bcad-4b52-933e-13c36283d93a/unet3d.md","covers":["https://sandbox.zenodo.org/api/files/a6e1b0c5-bcad-4b52-933e-13c36283d93a/raw.png","https://sandbox.zenodo.org/api/files/a6e1b0c5-bcad-4b52-933e-13c36283d93a/pred.png"],"source":"https://sandbox.zenodo.org/api/files/a6e1b0c5-bcad-4b52-933e-13c36283d93a/rdf.yaml","links":["imjoy/BioImageIO-Packager","ilastik/Ilastik"],"config":{"_doi":"10.5072/zenodo.872861","_conceptdoi":"10.5072/zenodo.872860","_rdf_file":"https://sandbox.zenodo.org/api/files/a6e1b0c5-bcad-4b52-933e-13c36283d93a/rdf.yaml"}},{"id":"10.5072/zenodo.856197","name":"N2V SEM Demo","type":"model","authors":[{"name":"Deborah Schmidt"}],"tags":["bioimage.io","bioimage.io:model","denoising","unet2d","n2v","zenodo"],"description":"Uploaded via BioImage.IO website (https://bioimage.io)","stats":{"downloads":1962,"unique_downloads":1470,"unique_views":6,"version_downloads":1962,"version_unique_downloads":1470,"version_unique_views":6,"version_views":7,"version_volume":769742210,"views":7,"volume":769742210},"license":"BSD-3-Clause","documentation":"https://sandbox.zenodo.org/api/files/956c0bd6-5472-4052-a1ef-94ccf94cadc9/README.md","covers":["https://sandbox.zenodo.org/api/files/956c0bd6-5472-4052-a1ef-94ccf94cadc9/thumbnail.png"],"source":"https://sandbox.zenodo.org/api/files/956c0bd6-5472-4052-a1ef-94ccf94cadc9/model.yaml","links":["imjoy/BioImageIO-Packager"],"config":{"_doi":"10.5072/zenodo.856198","_conceptdoi":"10.5072/zenodo.856197","_rdf_file":"https://sandbox.zenodo.org/api/files/956c0bd6-5472-4052-a1ef-94ccf94cadc9/model.yaml"}}],"github":[{"id":"zero","source":"https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/manifest.bioimage.io.yaml"},{"id":"deepimagej","source":"https://raw.githubusercontent.com/deepimagej/models/master/manifest.bioimage.io.yaml"},{"id":"fiji","source":"https://raw.githubusercontent.com/bioimage-io/fiji-bioimage-io/master/manifest.bioimage.io.yaml"},{"id":"imjoy","source":"https://raw.githubusercontent.com/imjoy-team/bioimage-io-models/master/manifest.bioimage.io.yaml"},{"id":"ilastik","source":"https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/manifest.bioimage.io.yaml"},{"id":"hpa","source":"https://raw.githubusercontent.com/CellProfiling/HPA-model-zoo/master/manifest.bioimage.io.yaml"}]},"config":{"splash_title":"BioImage Model Zoo","splash_subtitle":"Advanced AI models in one-click","splash_feature_list":["Integrate with Fiji, Ilastik, ImJoy","Try model instantly with BioEngine","Contribute your models via Github","Link models to datasets and applications"],"explore_button_text":"Start Exploring","background_image":"static/img/zoo-background.svg","resource_types":["model","application","notebook","dataset"],"default_type":"model","url_root":"https://raw.githubusercontent.com/bioimage-io/collection-bioimage-io/gh-pages"}}
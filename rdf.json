{"name":"BioImage.IO","type":"collection","description":"BioImage.IO RDF collections","tags":[],"version":"0.1.0","authors":[{"name":"BioImgae.IO Team"}],"documentation":"./README.md","git_repo":"https://github.com/bioimage-io/collection-bioimage-io","icon":"https://raw.githubusercontent.com/bioimage-io/bioimage.io/main/public/static/icons/android-chrome-384x384.png","attachments":{"zenodo":[{"id":"10.5072/zenodo.921275","name":"HPA Bestfitting Densenet","type":"model","authors":[{"name":"Shubin Dai"}],"tags":["bioimage.io","bioimage.io:model","classification","densenet-121","hpa","onnx","cells","protein-localization","zenodo"],"description":"The winning model of HPA image classification 2019 by Bestfitting","stats":{"downloads":1392,"unique_downloads":1305,"unique_views":9,"version_downloads":3072,"version_unique_downloads":2816,"version_unique_views":14,"version_views":14,"version_volume":378115548,"views":9,"volume":138937287},"license":"MIT","documentation":"https://sandbox.zenodo.org/api/files/adbe7f27-328f-4705-a112-6648fcba0743/README.md","covers":["https://sandbox.zenodo.org/api/files/adbe7f27-328f-4705-a112-6648fcba0743/bestfitting-densenet-diagram.png"],"source":"https://sandbox.zenodo.org/api/files/adbe7f27-328f-4705-a112-6648fcba0743/rdf%20(36).yaml","links":["imjoy/BioImageIO-Packager"],"config":{"_doi":"10.5072/zenodo.921692","_conceptdoi":"10.5072/zenodo.921275","_rdf_file":"https://sandbox.zenodo.org/api/files/adbe7f27-328f-4705-a112-6648fcba0743/rdf%20(36).yaml"}},{"id":"10.5072/zenodo.938150","name":"3D UNet and binarization - ZeroCostDL4Mic","type":"model","authors":[{"affiliation":"UC3M, EPFL","name":"DeepImageJ"},{"affiliation":"UCL, University of Turku and Åbo Akademi University","name":"ZeroCostDL4Mic"}],"tags":["bioimage.io","bioimage.io:model","zerocostdl4mic","deepimagej","segmentation","3dunet","zenodo"],"description":"Trained 3D U-Net to segment arabidopsis ovaries boundaries in confocal microscopy 3D volumes.","stats":{"downloads":0,"unique_downloads":0,"unique_views":0,"version_downloads":0,"version_unique_downloads":0,"version_unique_views":0,"version_views":0,"version_volume":0,"views":0,"volume":0},"license":"MIT","documentation":"https://sandbox.zenodo.org/api/files/17cdd6d8-e4f5-4240-8f74-59c1228df7fe/README.md","covers":["https://sandbox.zenodo.org/api/files/17cdd6d8-e4f5-4240-8f74-59c1228df7fe/input.png","https://sandbox.zenodo.org/api/files/17cdd6d8-e4f5-4240-8f74-59c1228df7fe/output.png"],"source":"https://sandbox.zenodo.org/api/files/17cdd6d8-e4f5-4240-8f74-59c1228df7fe/model.yaml","links":["imjoy/BioImageIO-Packager","deepimagej/deepimagej","zero/notebook_u-net_3d_zerocostdl4mic_deepimagej"],"config":{"_doi":"10.5072/zenodo.938151","_conceptdoi":"10.5072/zenodo.938150","_rdf_file":"https://sandbox.zenodo.org/api/files/17cdd6d8-e4f5-4240-8f74-59c1228df7fe/model.yaml"}},{"id":"10.5072/zenodo.849110","name":"3D UNet - arabidopsis - ZeroCostDL4Mic","type":"model","authors":[{"affiliation":"UC3M, EPFL","name":"DeepImageJ"},{"affiliation":"UCL, University of Turku and Åbo Akademi University","name":"ZeroCostDL4Mic"}],"tags":["bioimage.io","bioimage.io:model","zerocostdl4mic","deepimagej","segmentation","3dunet","zenodo"],"description":"Trained 3D U-Net to segment arabidopsis ovaries boundaries in confocal microscopy 3D volumes.","stats":{"downloads":15751,"unique_downloads":2510,"unique_views":1,"version_downloads":25859,"version_unique_downloads":7058,"version_unique_views":74,"version_views":95,"version_volume":183660519229,"views":1,"volume":174139382401},"license":"MIT","documentation":"https://sandbox.zenodo.org/api/files/b7b70fb7-b859-479b-a30e-3d5ad4463929/README.md","covers":["https://sandbox.zenodo.org/api/files/b7b70fb7-b859-479b-a30e-3d5ad4463929/input.png","https://sandbox.zenodo.org/api/files/b7b70fb7-b859-479b-a30e-3d5ad4463929/output.png"],"source":"https://sandbox.zenodo.org/api/files/b7b70fb7-b859-479b-a30e-3d5ad4463929/model.yaml","links":["imjoy/BioImageIO-Packager","deepimagej/deepimagej","zero/notebook_u-net_3d_zerocostdl4mic_deepimagej"],"config":{"_doi":"10.5072/zenodo.938099","_conceptdoi":"10.5072/zenodo.849110","_rdf_file":"https://sandbox.zenodo.org/api/files/b7b70fb7-b859-479b-a30e-3d5ad4463929/model.yaml"}},{"id":"10.5072/zenodo.881944","name":"Platyereis-nuclei-BoundaryModel","type":"model","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:model","u-net","nuclei-segmentation","segmentation","volume-em","platynereis","nuclei","affinity-prediction","zenodo"],"description":"Platyereis-nuclei-BoundaryModel","stats":{"downloads":13630,"unique_downloads":2920,"unique_views":3,"version_downloads":16051,"version_unique_downloads":4970,"version_unique_views":15,"version_views":30,"version_volume":212738108595,"views":4,"volume":209960100469},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/c4b92a9e-19cf-4fd0-878a-c0954c49986f/documentation.md","covers":["https://sandbox.zenodo.org/api/files/c4b92a9e-19cf-4fd0-878a-c0954c49986f/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/c4b92a9e-19cf-4fd0-878a-c0954c49986f/rdf.yaml","links":["deepimagej/deepimagej","10.5072/zenodo.881899","ilastik/ilastik","imjoy/BioImageIO-Packager"],"config":{"_doi":"10.5072/zenodo.934251","_conceptdoi":"10.5072/zenodo.881944","_rdf_file":"https://sandbox.zenodo.org/api/files/c4b92a9e-19cf-4fd0-878a-c0954c49986f/rdf.yaml"}},{"id":"10.5072/zenodo.881940","name":"DSB-Nuclei-BoundaryModel","type":"model","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:model","u-net","nucleus-segmentation","segmentation","volume-em","platynereis","nuclei","affinity-prediction","zenodo"],"description":"DSB-Nuclei-BoundaryModel","stats":{"downloads":14071,"unique_downloads":2896,"unique_views":5,"version_downloads":16291,"version_unique_downloads":4699,"version_unique_views":18,"version_views":33,"version_volume":229081861097,"views":8,"volume":226817891998},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/782ae236-8146-44fe-b2ac-a16314dcd7e2/documentation.md","covers":["https://sandbox.zenodo.org/api/files/782ae236-8146-44fe-b2ac-a16314dcd7e2/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/782ae236-8146-44fe-b2ac-a16314dcd7e2/rdf.yaml","links":["10.5072/zenodo.881915","ilastik/ilastik","deepimagej/deepimagej","imjoy/BioImageIO-Packager"],"config":{"_doi":"10.5072/zenodo.934248","_conceptdoi":"10.5072/zenodo.881940","_rdf_file":"https://sandbox.zenodo.org/api/files/782ae236-8146-44fe-b2ac-a16314dcd7e2/rdf.yaml"}},{"id":"10.5072/zenodo.927181","name":"Flow chamber cell segmentation","type":"model","authors":[{"affiliation":"Turku Bioscience Centre, University of Turku and Abo Akademi University","name":"Guillaume Jacquemet"},{"affiliation":"Universidad Carlos III de Madrid","name":"Estibaliz Gómez de Mariscal"}],"tags":["bioimage.io","bioimage.io:model","deepimagej","zerocostdl4mic","segmentation","flowchamber","brightfield","instance-segmentation","stardist","cells","zenodo"],"description":"Trained StarDist model to segment of cancer cells in paired brightfield images.","stats":{"downloads":4193,"unique_downloads":3682,"unique_views":9,"version_downloads":4354,"version_unique_downloads":3777,"version_unique_views":12,"version_views":12,"version_volume":1069405097,"views":9,"volume":901317902},"license":"MIT","documentation":null,"covers":["https://sandbox.zenodo.org/api/files/e236cb69-aa12-4017-a356-12cec1b3c379/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/e236cb69-aa12-4017-a356-12cec1b3c379/model.yaml","links":["imjoy/BioImageIO-Packager","deepimagej/deepimagej","zero/notebook_stardist_2d_zerocostdl4mic_deepimagej","zero/dataset_stardist_brightfield2_zerocostdl4mic"],"config":{"_doi":"10.5072/zenodo.927913","_conceptdoi":"10.5072/zenodo.927181","_rdf_file":"https://sandbox.zenodo.org/api/files/e236cb69-aa12-4017-a356-12cec1b3c379/model.yaml"}},{"id":"10.5072/zenodo.927158","name":"T cell nuceli segmentation - brightfield","type":"model","authors":[{"affiliation":"Turku Bioscience Centre, University of Turku and Åbo Akademi University","name":"Guillaume Jacquemet"}],"tags":["bioimage.io","bioimage.io:model","deepimagej","tcell","zerocostdl4mic","segmentation","brightfield","stardist","instancesegmentation","zenodo"],"description":"StarDist 2D model to segment migrating T-cells in paired brightfield microscopy images.","stats":{"downloads":4524,"unique_downloads":3587,"unique_views":16,"version_downloads":4549,"version_unique_downloads":3591,"version_unique_views":17,"version_views":17,"version_volume":1539193294,"views":16,"volume":1500389235},"license":"MIT","documentation":null,"covers":["https://sandbox.zenodo.org/api/files/16dce8f1-37e5-44fc-b1e8-da4c4c6a3dfc/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/16dce8f1-37e5-44fc-b1e8-da4c4c6a3dfc/model.yaml","links":["imjoy/bioimageio-packager","deepimagej/deepimagej","zero/notebook_stardist_2d_zerocostdl4mic_deepimagej","zero/dataset_stardist_brightfield_zerocostdl4mic"],"config":{"_doi":"10.5072/zenodo.927420","_conceptdoi":"10.5072/zenodo.927158","_rdf_file":"https://sandbox.zenodo.org/api/files/16dce8f1-37e5-44fc-b1e8-da4c4c6a3dfc/model.yaml"}},{"id":"10.5072/zenodo.927364","name":"Nuclei (SiR-DNA) segmentation","type":"model","authors":[{"affiliation":"Turku Bioscience Centre, University of Turku and Åbo Akademi University","name":"Guillaume Jacquemet"}],"tags":["bioimage.io","bioimage.io:model","deepimagej","segmentation","stardist","zerocostdl4mic","breastcancer","fluorescence","nuclei","instance-segmentation","zenodo"],"description":"Trained StarDist model for breast cancer cell nuclei (SiR-DNA) segmentation in fluorescence microscopy images.","stats":{"downloads":4591,"unique_downloads":3733,"unique_views":17,"version_downloads":4607,"version_unique_downloads":3738,"version_unique_views":18,"version_views":22,"version_volume":1542629852,"views":21,"volume":1523777704},"license":"MIT","documentation":null,"covers":["https://sandbox.zenodo.org/api/files/f1fff282-e246-4402-a3a1-052a2c411ab2/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/f1fff282-e246-4402-a3a1-052a2c411ab2/model.yaml","links":["imjoy/bioimageio-packager","deepimagej/deepimagej","zero/notebook_stardist_2d_zerocostdl4mic_deepimagej","zero/dataset_stardist_fluo_zerocostdl4mic"],"config":{"_doi":"10.5072/zenodo.927416","_conceptdoi":"10.5072/zenodo.927364","_rdf_file":"https://sandbox.zenodo.org/api/files/f1fff282-e246-4402-a3a1-052a2c411ab2/model.yaml"}},{"id":"10.5072/zenodo.907585","name":"Widefield Super-resolution (GAN - TxRed)","type":"model","authors":[{"affiliation":"University of California, Los Angeles, CA, USA","name":"Hongda Wang"},{"affiliation":"University of California, Los Angeles, CA, USA","name":"Yair Rivenson"},{"affiliation":"University of California, Los Angeles, CA, USA","name":"Aydogan Ozcan"}],"tags":["bioimage.io","bioimage.io:model","deepimagej","gan","fluorescence-microscopy","super-resolution","zenodo"],"description":"A trained GAN to transform diffraction-limited input images into super-resolved ones.","stats":{"downloads":7865,"unique_downloads":4073,"unique_views":13,"version_downloads":8417,"version_unique_downloads":4407,"version_unique_views":17,"version_views":20,"version_volume":4804663810,"views":16,"volume":4767982697},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/67a7eae5-2290-4b61-b273-eee0fa916d90/README.md","covers":["https://sandbox.zenodo.org/api/files/67a7eae5-2290-4b61-b273-eee0fa916d90/exampleImage.png","https://sandbox.zenodo.org/api/files/67a7eae5-2290-4b61-b273-eee0fa916d90/resultImage.png"],"source":"https://sandbox.zenodo.org/api/files/67a7eae5-2290-4b61-b273-eee0fa916d90/model.yaml","links":["imjoy/BioImageIO-Packager","deepimagej/deepimagej"],"config":{"_doi":"10.5072/zenodo.913992","_conceptdoi":"10.5072/zenodo.907585","_rdf_file":"https://sandbox.zenodo.org/api/files/67a7eae5-2290-4b61-b273-eee0fa916d90/model.yaml"}},{"id":"10.5072/zenodo.908833","name":"Widefield Super-resolution (GAN - FITC)","type":"model","authors":[{"affiliation":"University of California, Los Angeles, CA, USA","name":"Hongda Wang"},{"affiliation":"University of California, Los Angeles, CA, USA","name":"Yair Rivenson"},{"affiliation":"University of California, Los Angeles, CA, USA","name":"Aydogan Ozcan"}],"tags":["bioimage.io","bioimage.io:model","deepimagej","gan","fluorescence-microscopy","super-resolution","zenodo"],"description":"A trained GAN to transform diffraction-limited input images into super-resolved ones.","stats":{"downloads":7400,"unique_downloads":3877,"unique_views":15,"version_downloads":7856,"version_unique_downloads":4144,"version_unique_views":20,"version_views":28,"version_volume":5145522565,"views":19,"volume":5103557850},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/8b1d0c16-db10-4645-ae11-5c4296415a2e/README.md","covers":["https://sandbox.zenodo.org/api/files/8b1d0c16-db10-4645-ae11-5c4296415a2e/exampleImage.png","https://sandbox.zenodo.org/api/files/8b1d0c16-db10-4645-ae11-5c4296415a2e/resultImage.png"],"source":"https://sandbox.zenodo.org/api/files/8b1d0c16-db10-4645-ae11-5c4296415a2e/model.yaml","links":["imjoy/BioImageIO-Packager","deepimagej/deepimagej"],"config":{"_doi":"10.5072/zenodo.914425","_conceptdoi":"10.5072/zenodo.908833","_rdf_file":"https://sandbox.zenodo.org/api/files/8b1d0c16-db10-4645-ae11-5c4296415a2e/model.yaml"}},{"id":"10.5072/zenodo.907595","name":"Widefield Super-resolution (GAN - DAPI)","type":"model","authors":[{"affiliation":"University of California, Los Angeles, CA, USA","name":"Hongda Wang"},{"affiliation":"University of California, Los Angeles, CA, USA","name":"Yair Rivenson"},{"affiliation":"University of California, Los Angeles, CA, USA","name":"Aydogan Ozcan"}],"tags":["bioimage.io","bioimage.io:model","deepimagej","gan","fluorescence-microscopy","super-resolution","zenodo"],"description":"A trained GAN to transform diffraction-limited input images into super-resolved ones.","stats":{"downloads":7010,"unique_downloads":3823,"unique_views":11,"version_downloads":7463,"version_unique_downloads":4054,"version_unique_views":19,"version_views":19,"version_volume":959637911,"views":11,"volume":927810649},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/1e074efe-d7ac-48b0-af75-1c604aad31f7/README.md","covers":["https://sandbox.zenodo.org/api/files/1e074efe-d7ac-48b0-af75-1c604aad31f7/exampleImage.png","https://sandbox.zenodo.org/api/files/1e074efe-d7ac-48b0-af75-1c604aad31f7/resultImage.png"],"source":"https://sandbox.zenodo.org/api/files/1e074efe-d7ac-48b0-af75-1c604aad31f7/model.yaml","links":["imjoy/BioImageIO-Packager","deepimagej/deepimagej"],"config":{"_doi":"10.5072/zenodo.914422","_conceptdoi":"10.5072/zenodo.907595","_rdf_file":"https://sandbox.zenodo.org/api/files/1e074efe-d7ac-48b0-af75-1c604aad31f7/model.yaml"}},{"id":"10.5072/zenodo.905080","name":"Pancreatic Cell Phase Contrast Segmentation (DeepWater - CTC submission)","type":"model","authors":[{"affiliation":"Centre for Biomedical Image Analysis, Masaryk University","name":"Filip Lux"},{"affiliation":"Centre for Biomedical Image Analysis, Masaryk University","name":"Petr Matula"}],"tags":["bioimage.io","bioimage.io:model","deepwater","deepimagej","segmentation","watershed","cell-tracking-challenge","phase-contrast","zenodo"],"description":"The method combines deep learning with watershed segmentation. For each frame, the convolutional neural network of U-Net shape detects all cells by markers and recognizes the foreground and the background of the frame. Then, the final segmentation is generated by a Marker-Controlled Watershed transformation.","stats":{"downloads":4870,"unique_downloads":3912,"unique_views":20,"version_downloads":5424,"version_unique_downloads":4335,"version_unique_views":29,"version_views":37,"version_volume":1984164526,"views":24,"volume":1879136608},"license":"MIT","documentation":"https://sandbox.zenodo.org/api/files/05933bba-2a1d-4b6f-935e-26528ddc450a/README.md","covers":["https://sandbox.zenodo.org/api/files/05933bba-2a1d-4b6f-935e-26528ddc450a/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/05933bba-2a1d-4b6f-935e-26528ddc450a/model.yaml","links":["deepimagej/deepimagej","imjoy/bioimageio-packager","deepimagej/unet-pancreaticcellsegmentation"],"config":{"_doi":"10.5072/zenodo.914413","_conceptdoi":"10.5072/zenodo.905080","_rdf_file":"https://sandbox.zenodo.org/api/files/05933bba-2a1d-4b6f-935e-26528ddc450a/model.yaml"}},{"id":"10.5072/zenodo.905991","name":"HeLa DIC Cell Segmentation (U-Net)","type":"model","authors":[{"affiliation":"EPFL, UC3M","name":"DeepImageJ"}],"tags":["bioimage.io","bioimage.io:model","deepimagej","hela-cells","segmentation","phase-contrast","zenodo"],"description":"DeepImageJ compatible U-Net trained to segment Hela cells in 2D phase contrast microscopy images","stats":{"downloads":4920,"unique_downloads":3703,"unique_views":17,"version_downloads":5221,"version_unique_downloads":3986,"version_unique_views":34,"version_views":42,"version_volume":74511865087,"views":19,"volume":74504200382},"license":"BSD-2-Clause","documentation":"https://sandbox.zenodo.org/api/files/7450899d-5536-42f6-afac-8a27684d7c98/README.md","covers":["https://sandbox.zenodo.org/api/files/7450899d-5536-42f6-afac-8a27684d7c98/unet_hela_seg.jpg"],"source":"https://sandbox.zenodo.org/api/files/7450899d-5536-42f6-afac-8a27684d7c98/model.yaml","links":["imjoy/BioImageIO-Packager","deepimagej/deepimagej"],"config":{"_doi":"10.5072/zenodo.913978","_conceptdoi":"10.5072/zenodo.905991","_rdf_file":"https://sandbox.zenodo.org/api/files/7450899d-5536-42f6-afac-8a27684d7c98/model.yaml"}},{"id":"10.5072/zenodo.906808","name":"Glial Cell SMLM (DeepSTORM - ZeroCostDL4Mic)","type":"model","authors":[{"affiliation":"UCL, Francis Crick Institute, Turku and Åbo Akademi University","name":"ZeroCostDL4Mic team"},{"affiliation":"UC3M, EPFL","name":"DeepImageJ team"}],"tags":["bioimage.io","bioimage.io:model","zerocostdl4mic","deepimagej","smlm","image-reconstruction","super-resolution","zenodo"],"description":"A trained Deep-STORM model for image reconstruction from high-density single-molecule localization microscopy (SMLM).","stats":{"downloads":7450,"unique_downloads":4129,"unique_views":14,"version_downloads":7494,"version_unique_downloads":4159,"version_unique_views":16,"version_views":18,"version_volume":1353448014,"views":15,"volume":1279879794},"license":"MIT","documentation":"https://sandbox.zenodo.org/api/files/586c72d8-d5fe-42bc-b9a4-8faff6de6963/README.md","covers":["https://sandbox.zenodo.org/api/files/586c72d8-d5fe-42bc-b9a4-8faff6de6963/input.png","https://sandbox.zenodo.org/api/files/586c72d8-d5fe-42bc-b9a4-8faff6de6963/zoom.png"],"source":"https://sandbox.zenodo.org/api/files/586c72d8-d5fe-42bc-b9a4-8faff6de6963/model.yaml","links":["deepimagej/deepimagej","zero/notebook_deep-storm_2d_zerocostdl4mic_deepimagej","imjoy/bioimageio-packager","deepimagej/smlm-deepimagej"],"config":{"_doi":"10.5072/zenodo.907832","_conceptdoi":"10.5072/zenodo.906808","_rdf_file":"https://sandbox.zenodo.org/api/files/586c72d8-d5fe-42bc-b9a4-8faff6de6963/model.yaml"}},{"id":"10.5072/zenodo.906784","name":"3D U-Net - ZeroCostDL4Mic","type":"model","authors":[{"affiliation":"EPFL, UC3M","name":"DeepImageJ team"}],"tags":["bioimage.io","bioimage.io:model","deepimagej","tem","mitochondria","segmentation","3d-unet","zerocostdl4mic","deepimagej-beta","zenodo"],"description":"3D U-Net trained using ZeroCostDL4Mic notebooks to segment mitochondria in Transmission Electron Microscopy (TEM) data.","stats":{"downloads":4587,"unique_downloads":4070,"unique_views":11,"version_downloads":4614,"version_unique_downloads":4096,"version_unique_views":12,"version_views":12,"version_volume":28026005829,"views":11,"volume":28025936663},"license":"MIT","documentation":"https://sandbox.zenodo.org/api/files/52771cb2-5886-41a3-b8ee-4def7203951f/README.md","covers":["https://sandbox.zenodo.org/api/files/52771cb2-5886-41a3-b8ee-4def7203951f/exampleImage.gif"],"source":"https://sandbox.zenodo.org/api/files/52771cb2-5886-41a3-b8ee-4def7203951f/model.yaml","links":["deepimagej/deepimagej","zero/notebook_u-net_3d_zerocostdl4mic_deepimagej","imjoy/bioimageio-packager"],"config":{"_doi":"10.5072/zenodo.907831","_conceptdoi":"10.5072/zenodo.906784","_rdf_file":"https://sandbox.zenodo.org/api/files/52771cb2-5886-41a3-b8ee-4def7203951f/model.yaml"}},{"id":"10.5072/zenodo.906806","name":"Skin lesions classification","type":"model","authors":[{"affiliation":"UC3M","name":"Carlos García-López-de-Haro"}],"tags":["bioimage.io","bioimage.io:model","deepimagej-beta","deepimagej","skin-lesions","melanoma","classification","pytorch","zenodo"],"description":"CNN trained to classify the type of imaged skin lesion.","stats":{"downloads":4368,"unique_downloads":3999,"unique_views":4,"version_downloads":4368,"version_unique_downloads":3999,"version_unique_views":4,"version_views":4,"version_volume":597355920,"views":4,"volume":597355920},"license":"BSD-2-Clause","documentation":"https://sandbox.zenodo.org/api/files/5218d3ab-9b32-47ea-891e-0da59e849ad6/README.md","covers":["https://sandbox.zenodo.org/api/files/5218d3ab-9b32-47ea-891e-0da59e849ad6/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/5218d3ab-9b32-47ea-891e-0da59e849ad6/model.yaml","links":["imjoy/BioImageIO-Packager","deepimagej/deepimagej"],"config":{"_doi":"10.5072/zenodo.906807","_conceptdoi":"10.5072/zenodo.906806","_rdf_file":"https://sandbox.zenodo.org/api/files/5218d3ab-9b32-47ea-891e-0da59e849ad6/model.yaml"}},{"id":"10.5072/zenodo.906804","name":"Masson's Trichrome Virtual Staining (GAN)","type":"model","authors":[{"affiliation":"University of California","name":"Yair Rivenson"},{"affiliation":"University of California","name":"Hongda Wang"},{"affiliation":"University of California","name":"Aydogan Ozcan"}],"tags":["bioimage.io","bioimage.io:model","deepimagej","gan","virtual-staining","histology","zenodo"],"description":"A trained GAN to transform wide-field autofluorescence images of unlabelled tissue sections into images that are equivalent to the bright-field images of histologically stained versions of the same samples.","stats":{"downloads":5861,"unique_downloads":3393,"unique_views":1,"version_downloads":5861,"version_unique_downloads":3393,"version_unique_views":1,"version_views":1,"version_volume":1393361011,"views":1,"volume":1393361011},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/0dcd8dec-ed38-4d10-a487-025597c207b6/README.md","covers":["https://sandbox.zenodo.org/api/files/0dcd8dec-ed38-4d10-a487-025597c207b6/exampleImage.png","https://sandbox.zenodo.org/api/files/0dcd8dec-ed38-4d10-a487-025597c207b6/resultImage.png"],"source":"https://sandbox.zenodo.org/api/files/0dcd8dec-ed38-4d10-a487-025597c207b6/model.yaml","links":["imjoy/BioImageIO-Packager","deepimagej/deepimagej"],"config":{"_doi":"10.5072/zenodo.906805","_conceptdoi":"10.5072/zenodo.906804","_rdf_file":"https://sandbox.zenodo.org/api/files/0dcd8dec-ed38-4d10-a487-025597c207b6/model.yaml"}},{"id":"10.5072/zenodo.906802","name":"Jones Virtual Staining (GAN)","type":"model","authors":[{"affiliation":"University of California","name":"Yair Rivenson"},{"affiliation":"University of California","name":"Hongda Wang"},{"affiliation":"University of California","name":"Aydogan Ozcan"}],"tags":["bioimage.io","bioimage.io:model","deepimagej","gan","virtual-staining","histology","zenodo"],"description":"A trained GAN to transform wide-field autofluorescence images of unlabelled tissue sections into images that are equivalent to the bright-field images of histologically stained versions of the same samples.","stats":{"downloads":5264,"unique_downloads":3052,"unique_views":8,"version_downloads":5264,"version_unique_downloads":3052,"version_unique_views":8,"version_views":8,"version_volume":2242426051,"views":8,"volume":2242426051},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/bfac9db5-f773-4d1b-a0f8-754628b3f5b3/README.md","covers":["https://sandbox.zenodo.org/api/files/bfac9db5-f773-4d1b-a0f8-754628b3f5b3/exampleImage.png","https://sandbox.zenodo.org/api/files/bfac9db5-f773-4d1b-a0f8-754628b3f5b3/resultImage.png"],"source":"https://sandbox.zenodo.org/api/files/bfac9db5-f773-4d1b-a0f8-754628b3f5b3/model.yaml","links":["imjoy/BioImageIO-Packager","deepimagej/deepimagej"],"config":{"_doi":"10.5072/zenodo.906803","_conceptdoi":"10.5072/zenodo.906802","_rdf_file":"https://sandbox.zenodo.org/api/files/bfac9db5-f773-4d1b-a0f8-754628b3f5b3/model.yaml"}},{"id":"10.5072/zenodo.894458","name":"Small Extracellular Vesicle TEM Segmentation (Fully Residual U-Net)","type":"model","authors":[{"affiliation":"Universidad Carlos III de Madrid","name":"Estibaliz Gómez-de-Mariscal"},{"affiliation":"Masaryk University","name":"Martin Maška"},{"affiliation":"Masaryk University","name":"Anna Kotrbová"},{"affiliation":"Masaryk University","name":"Vendula Pospíchalová"},{"affiliation":"Masaryk University","name":"Pavel Matula"},{"affiliation":"Universidad Carlos III de Madrid","name":"Arrate Muñoz-Barrutia"}],"tags":["bioimage.io","bioimage.io:model","deepimagej","extracellular-vesicles","segmentation","tem","frunet","exosomes","electron-microscopy","2d-segmentation","zenodo"],"description":"DeepImageJ compatible fully residual U-Net trained to segment small extracellular vesicles in 2D TEM images","stats":{"downloads":3717,"unique_downloads":3270,"unique_views":8,"version_downloads":4307,"version_unique_downloads":3454,"version_unique_views":19,"version_views":42,"version_volume":15098627538,"views":8,"volume":4450104513},"license":"BSD-3-Clause","documentation":"https://sandbox.zenodo.org/api/files/15f6cc78-b503-4880-966d-6a865794c9e8/README.md","covers":["https://sandbox.zenodo.org/api/files/15f6cc78-b503-4880-966d-6a865794c9e8/frunet_sev.jpg"],"source":"https://sandbox.zenodo.org/api/files/15f6cc78-b503-4880-966d-6a865794c9e8/model.yaml","links":["deepimagej/deepimagej","imjoy/bioimageio-packager","deepimagej/evstemsegmentationfrunet","ilastik/ilastik"],"config":{"_doi":"10.5072/zenodo.906449","_conceptdoi":"10.5072/zenodo.894458","_rdf_file":"https://sandbox.zenodo.org/api/files/15f6cc78-b503-4880-966d-6a865794c9e8/model.yaml"}},{"id":"10.5072/zenodo.904904","name":"2D UNet - ZeroCostDL4Mic","type":"model","authors":[{"name":"ZeroCostDL4Mic"},{"affiliation":"EPFL, UC3M","name":"DeepImageJ"}],"tags":["bioimage.io","bioimage.io:model","zerocostdl4mic","deepimagej","segmentation","tem","unet","zenodo"],"description":"2D U-Net trained for binary segmentation using the EM images of neuronal membranes and segmentation masks from the ISBI segmentation challenge 2012.","stats":{"downloads":4953,"unique_downloads":2775,"unique_views":21,"version_downloads":4953,"version_unique_downloads":2775,"version_unique_views":21,"version_views":25,"version_volume":3901326225,"views":25,"volume":3901326225},"license":"MIT","documentation":"https://sandbox.zenodo.org/api/files/d6bdaa4f-d337-4c06-85ed-3d1430a2784b/README.md","covers":["https://sandbox.zenodo.org/api/files/d6bdaa4f-d337-4c06-85ed-3d1430a2784b/input.png","https://sandbox.zenodo.org/api/files/d6bdaa4f-d337-4c06-85ed-3d1430a2784b/output.png"],"source":"https://sandbox.zenodo.org/api/files/d6bdaa4f-d337-4c06-85ed-3d1430a2784b/model.yaml","links":["imjoy/BioImageIO-Packager","deepimagej/deepimagej","zero/notebook_u-net_2d_zerocostdl4mic_deepimagej"],"config":{"_doi":"10.5072/zenodo.904905","_conceptdoi":"10.5072/zenodo.904904","_rdf_file":"https://sandbox.zenodo.org/api/files/d6bdaa4f-d337-4c06-85ed-3d1430a2784b/model.yaml"}},{"id":"10.5072/zenodo.880528","name":"Multi-Organ Nucleus Segmentation (StarDist 2D)","type":"model","authors":[{"affiliation":"EPFL, UC3M","name":"DeepImageJ team"},{"affiliation":"Universidad Carlos III de Madrid","name":"Estibaliz Gómez de Mariscal"}],"tags":["bioimage.io","bioimage.io:model","segmentation","histopathology","histology","stardist","nucleus-segmentation","zerocostdl4mic","trainable","deepimagej","digital-pathology","zenodo"],"description":"Nucleus segmentation in digital pathology datasets using a StarDist trained model in 2D. The dataset is the one provided in the MoNuSeg 2018 Challenge.","stats":{"downloads":7719,"unique_downloads":3272,"unique_views":13,"version_downloads":10177,"version_unique_downloads":3970,"version_unique_views":28,"version_views":42,"version_volume":7197759853,"views":16,"volume":5056331344},"license":"MIT","documentation":"https://sandbox.zenodo.org/api/files/954ada81-d28f-47de-b9d3-686559c76401/README.md","covers":["https://sandbox.zenodo.org/api/files/954ada81-d28f-47de-b9d3-686559c76401/combined.jpg","https://sandbox.zenodo.org/api/files/954ada81-d28f-47de-b9d3-686559c76401/input.png","https://sandbox.zenodo.org/api/files/954ada81-d28f-47de-b9d3-686559c76401/output.png"],"source":"https://sandbox.zenodo.org/api/files/954ada81-d28f-47de-b9d3-686559c76401/model.yaml","links":["zero/notebook_stardist_2d_zerocostdl4mic_deepimagej","deepimagej/deepimagej","imjoy/bioimageio-packager","deepimagej/monuseg_digital_pathology_miccai2018"],"config":{"_doi":"10.5072/zenodo.894493","_conceptdoi":"10.5072/zenodo.880528","_rdf_file":"https://sandbox.zenodo.org/api/files/954ada81-d28f-47de-b9d3-686559c76401/model.yaml"}},{"id":"10.5072/zenodo.886788","name":"ISBI2012-2D-AffinityModel","type":"model","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:model","u-net","neuron-segmentation","segmentation","volume-em","isbi2012-challenge","boundary-prediction","zenodo"],"description":"ISBI2012-2D-AffinityModel","stats":{"downloads":15643,"unique_downloads":3864,"unique_views":27,"version_downloads":15643,"version_unique_downloads":3864,"version_unique_views":27,"version_views":39,"version_volume":102720525868,"views":39,"volume":102720525868},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/678d163d-baa9-4c9a-987b-a1b3f0ac1bae/documentation.md","covers":["https://sandbox.zenodo.org/api/files/678d163d-baa9-4c9a-987b-a1b3f0ac1bae/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/678d163d-baa9-4c9a-987b-a1b3f0ac1bae/rdf.yaml","links":["10.5072/zenodo.881019","ilastik/ilastik","deepimagej/deepimagej","imjoy/BioImageIO-Packager"],"config":{"_doi":"10.5072/zenodo.886789","_conceptdoi":"10.5072/zenodo.886788","_rdf_file":"https://sandbox.zenodo.org/api/files/678d163d-baa9-4c9a-987b-a1b3f0ac1bae/rdf.yaml"}},{"id":"10.5072/zenodo.849032","name":"SMLM Density Map Estimation (DEFCoN)","type":"model","authors":[{"name":"Wei"}],"tags":["bioimage.io","bioimage.io:model","deepimagej","smlm","defcon","density estimation","zenodo"],"description":"This is a test model","stats":{"downloads":3655,"unique_downloads":3453,"unique_views":14,"version_downloads":5510,"version_unique_downloads":4697,"version_unique_views":26,"version_views":32,"version_volume":75213794,"views":15,"volume":47745729},"license":"BSD-1-Clause","documentation":"https://github.com/LEB-EPFL/DEFCoN-ImageJ/wiki","covers":["https://sandbox.zenodo.org/api/files/472b09aa-f70b-48e9-b836-6ab560e3b70c/cover_image.jpg"],"source":"https://sandbox.zenodo.org/api/files/472b09aa-f70b-48e9-b836-6ab560e3b70c/model.yaml","links":["imjoy/BioImageIO-Packager","deepimagej/deepimagej"],"config":{"_doi":"10.5072/zenodo.885236","_conceptdoi":"10.5072/zenodo.849032","_rdf_file":"https://sandbox.zenodo.org/api/files/472b09aa-f70b-48e9-b836-6ab560e3b70c/model.yaml"}},{"id":"10.5072/zenodo.881018","name":"ISBI Challenge: Segmentation of neuronal structures in EM stacks","type":"dataset","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:dataset","neuron-segmentation","em-segmentation","isbi2012-challenge","zenodo"],"description":"First challenge on 2d segmentation of neuronal processes in EM images. Organised as part of the ISBI2012 conference.","stats":{"downloads":2189,"unique_downloads":1809,"unique_views":3,"version_downloads":2194,"version_unique_downloads":1812,"version_unique_views":18,"version_views":21,"version_volume":1084728211,"views":3,"volume":1084705319},"license":"CC-BY-4.0","documentation":"http://brainiac2.mit.edu/isbi_challenge/home","covers":["https://sandbox.zenodo.org/api/files/6f7f9164-f183-4b3c-9201-362187b2ba9f/cover0.jpg","https://sandbox.zenodo.org/api/files/6f7f9164-f183-4b3c-9201-362187b2ba9f/cover1.gif"],"source":"https://sandbox.zenodo.org/api/files/6f7f9164-f183-4b3c-9201-362187b2ba9f/rdf.yaml","links":[],"config":{"_doi":"10.5072/zenodo.883893","_conceptdoi":"10.5072/zenodo.881018","_rdf_file":"https://sandbox.zenodo.org/api/files/6f7f9164-f183-4b3c-9201-362187b2ba9f/rdf.yaml"}},{"id":"10.5072/zenodo.881848","name":"Covid-IF-Cells-BoundaryModel","type":"model","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:model","u-net","cell-segmentation","htm","high-throughput-microscopt","segmentation","cells","covid-antibody-test","covid-19","sars-cov-2","immunofluorescence","affinity-prediction","zenodo"],"description":"Covid-IF-Cells-BoundaryModel","stats":{"downloads":4029,"unique_downloads":3686,"unique_views":6,"version_downloads":4289,"version_unique_downloads":3738,"version_unique_views":7,"version_views":8,"version_volume":5269206975,"views":6,"volume":2947592509},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/886646e7-8b7c-4e7b-a4e4-05c0343d6704/documentation.md","covers":["https://sandbox.zenodo.org/api/files/886646e7-8b7c-4e7b-a4e4-05c0343d6704/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/886646e7-8b7c-4e7b-a4e4-05c0343d6704/rdf.yaml","links":["ilastik/ilastik","deepimagej/deepimagej","10.5072/zenodo.881843","imjoy/BioImageIO-Packager"],"config":{"_doi":"10.5072/zenodo.882211","_conceptdoi":"10.5072/zenodo.881848","_rdf_file":"https://sandbox.zenodo.org/api/files/886646e7-8b7c-4e7b-a4e4-05c0343d6704/rdf.yaml"}},{"id":"10.5072/zenodo.881942","name":"CREMI-BoundaryModel","type":"model","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:model","u-net","neuron-segmentation","segmentation","volume-em","cremi","connectomics","affinity-prediction","zenodo"],"description":"CREMI-BoundaryModel","stats":{"downloads":4005,"unique_downloads":3615,"unique_views":5,"version_downloads":4134,"version_unique_downloads":3655,"version_unique_views":8,"version_views":13,"version_volume":9896416296,"views":7,"volume":8337895844},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/24ddb8e3-c9f0-459a-93f6-5d0a7703e6d0/documentation.md","covers":["https://sandbox.zenodo.org/api/files/24ddb8e3-c9f0-459a-93f6-5d0a7703e6d0/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/24ddb8e3-c9f0-459a-93f6-5d0a7703e6d0/rdf.yaml","links":["10.5072/zenodo.881917","ilastik/ilastik","deepimagej/deepimagej"],"config":{"_doi":"10.5072/zenodo.882209","_conceptdoi":"10.5072/zenodo.881942","_rdf_file":"https://sandbox.zenodo.org/api/files/24ddb8e3-c9f0-459a-93f6-5d0a7703e6d0/rdf.yaml"}},{"id":"10.5072/zenodo.880412","name":"EM-Mitochondria-BoundaryModel","type":"model","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:model","u-net","mitochondria-segmentation","segmentation","mito-em","mitochondria","affinity-prediction","zenodo"],"description":"EM-Mitochondria-BoundaryModel","stats":{"downloads":11704,"unique_downloads":1387,"unique_views":4,"version_downloads":14432,"version_unique_downloads":3576,"version_unique_views":12,"version_views":17,"version_volume":662323678289,"views":5,"volume":650048858030},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/81fa667e-293f-4f3f-aca7-b352f6546c7f/documentation.md","covers":["https://sandbox.zenodo.org/record/882067/files/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/81fa667e-293f-4f3f-aca7-b352f6546c7f/rdf.yaml","links":["ilastik/ilastik","deepimagej/deepimagej","imjoy/BioImageIO-Packager"],"config":{"_doi":"10.5072/zenodo.882193","_conceptdoi":"10.5072/zenodo.880412","_rdf_file":"https://sandbox.zenodo.org/api/files/81fa667e-293f-4f3f-aca7-b352f6546c7f/rdf.yaml"}},{"id":"10.5072/zenodo.881973","name":"Arabidopsis-ovules-BoundaryModel","type":"model","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:model","u-net","ovules-segmentation","segmentation","light-microscopy","arabidopsis","ovules","confocal-microscopy","affinity-prediction","zenodo"],"description":"Arabidopsis-ovules-BoundaryModel","stats":{"downloads":4233,"unique_downloads":3466,"unique_views":11,"version_downloads":4345,"version_unique_downloads":3485,"version_unique_views":12,"version_views":18,"version_volume":8378374370,"views":14,"volume":7547708961},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/83af3b6d-77b9-4fec-b488-402ddae756c8/documentation.md","covers":["https://sandbox.zenodo.org/api/files/83af3b6d-77b9-4fec-b488-402ddae756c8/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/83af3b6d-77b9-4fec-b488-402ddae756c8/rdf.yaml","links":["ilastik/ilastik","10.5072/zenodo.881893","deepimagej/deepimagej","imjoy/BioImageIO-Packager"],"config":{"_doi":"10.5072/zenodo.882064","_conceptdoi":"10.5072/zenodo.881973","_rdf_file":"https://sandbox.zenodo.org/api/files/83af3b6d-77b9-4fec-b488-402ddae756c8/rdf.yaml"}},{"id":"10.5072/zenodo.881916","name":"CREMI: MICCAI Challenge on Circuit Reconstruction from Electron Microscopy Images","type":"dataset","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:dataset","neuron-segmentation","em-segmentation","cremi-challenge","zenodo"],"description":"The goal of this challenge is to evaluate algorithms for automatic reconstruction of neurons and neuronal connectivity from serial section electron microscopy data.","stats":{"downloads":2422,"unique_downloads":1769,"unique_views":3,"version_downloads":2422,"version_unique_downloads":1769,"version_unique_views":3,"version_views":4,"version_volume":131679772,"views":4,"volume":131679772},"license":"CC-BY-4.0","documentation":"https://cremi.org/","covers":["https://sandbox.zenodo.org/api/files/a762cbb3-5722-49ca-bc2e-75e77e741a6a/cover0.png","https://sandbox.zenodo.org/api/files/a762cbb3-5722-49ca-bc2e-75e77e741a6a/cover1.png","https://sandbox.zenodo.org/api/files/a762cbb3-5722-49ca-bc2e-75e77e741a6a/cover2.png"],"source":"https://sandbox.zenodo.org/api/files/a762cbb3-5722-49ca-bc2e-75e77e741a6a/rdf.yaml","links":[],"config":{"_doi":"10.5072/zenodo.881917","_conceptdoi":"10.5072/zenodo.881916","_rdf_file":"https://sandbox.zenodo.org/api/files/a762cbb3-5722-49ca-bc2e-75e77e741a6a/rdf.yaml"}},{"id":"10.5072/zenodo.881914","name":"DSB Nucleus Segmentation Training Data","type":"dataset","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:dataset","nucleus-segmentation","dsb","dsb2018","zenodo"],"description":"Subset of the nucleus segmentation training data provided by the 2018 Kaggle Data Science Bowl.","stats":{"downloads":1756,"unique_downloads":1736,"unique_views":3,"version_downloads":1756,"version_unique_downloads":1736,"version_unique_views":3,"version_views":3,"version_volume":4952846,"views":3,"volume":4952846},"license":"CC-BY-4.0","documentation":"https://www.kaggle.com/c/data-science-bowl-2018","covers":["https://sandbox.zenodo.org/api/files/9335cedd-0a6f-458d-a28e-ac4a79216e2e/cover0.jpg"],"source":"https://sandbox.zenodo.org/api/files/9335cedd-0a6f-458d-a28e-ac4a79216e2e/rdf.yaml","links":[],"config":{"_doi":"10.5072/zenodo.881915","_conceptdoi":"10.5072/zenodo.881914","_rdf_file":"https://sandbox.zenodo.org/api/files/9335cedd-0a6f-458d-a28e-ac4a79216e2e/rdf.yaml"}},{"id":"10.5072/zenodo.881898","name":"Platynereis EM traning data","type":"dataset","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:dataset","em-segmentation","platynereis","platynereis dumerilii","cell-segmentation","cilia-segmentation","nucleus-segmentation","zenodo"],"description":"Training data for EM cell, nuclei and organelle segmentation in Platynereis dumerilii. Contains training data for cellular membranes, nuclei, cuticle and cilia.","stats":{"downloads":1717,"unique_downloads":1695,"unique_views":1,"version_downloads":1717,"version_unique_downloads":1695,"version_unique_views":1,"version_views":1,"version_volume":36227357,"views":1,"volume":36227357},"license":"CC-BY-4.0","documentation":"https://www.biorxiv.org/content/10.1101/2020.02.26.961037v1.abstract","covers":["https://sandbox.zenodo.org/api/files/d1278f8e-1f20-4c69-a86b-8f7dd4b89291/cover0.png"],"source":"https://sandbox.zenodo.org/api/files/d1278f8e-1f20-4c69-a86b-8f7dd4b89291/rdf.yaml","links":[],"config":{"_doi":"10.5072/zenodo.881899","_conceptdoi":"10.5072/zenodo.881898","_rdf_file":"https://sandbox.zenodo.org/api/files/d1278f8e-1f20-4c69-a86b-8f7dd4b89291/rdf.yaml"}},{"id":"10.5072/zenodo.881892","name":"Arabidopsis thaliana ovules - confocal","type":"dataset","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:dataset","confocal","lm-segmentation","arabidopsis","arabidopsis thaliana","ovules","plants","zenodo"],"description":"Ovules - confocal volumetric stacks with voxel size: (0.235x0.075x0.075 µm^3) (ZYX). Courtesy of Kay Schneitz lab, School of Life Sciences, Technical University of Munich, Germany.","stats":{"downloads":1692,"unique_downloads":1671,"unique_views":1,"version_downloads":1692,"version_unique_downloads":1671,"version_unique_views":1,"version_views":1,"version_volume":21719416,"views":1,"volume":21719416},"license":"CC-BY-4.0","documentation":"https://osf.io/uzq3w/wiki/home/","covers":["https://sandbox.zenodo.org/api/files/c396ca77-12e7-4f02-9ab3-01dbbaa32def/cover0.png"],"source":"https://sandbox.zenodo.org/api/files/c396ca77-12e7-4f02-9ab3-01dbbaa32def/rdf.yaml","links":[],"config":{"_doi":"10.5072/zenodo.881893","_conceptdoi":"10.5072/zenodo.881892","_rdf_file":"https://sandbox.zenodo.org/api/files/c396ca77-12e7-4f02-9ab3-01dbbaa32def/rdf.yaml"}},{"id":"10.5072/zenodo.881842","name":"CovidIf training data","type":"dataset","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:dataset","cell-segmentation","nucleus-segmentation","high-througput-microscopy","covid-19","sars-cov-2","zenodo"],"description":"Training data for cell, nucleus and infection classification in IF data of Covid-19 infected cells.","stats":{"downloads":2339,"unique_downloads":1718,"unique_views":2,"version_downloads":2339,"version_unique_downloads":1718,"version_unique_views":2,"version_views":2,"version_volume":18900317,"views":2,"volume":18900317},"license":"CC-BY-4.0","documentation":"https://onlinelibrary.wiley.com/doi/full/10.1002/bies.202000257","covers":["https://sandbox.zenodo.org/api/files/75b365f2-a335-43cb-892a-93e35b2d7c98/cover0.jpg","https://sandbox.zenodo.org/api/files/75b365f2-a335-43cb-892a-93e35b2d7c98/cover1.jpg","https://sandbox.zenodo.org/api/files/75b365f2-a335-43cb-892a-93e35b2d7c98/cover2.jpg"],"source":"https://sandbox.zenodo.org/api/files/75b365f2-a335-43cb-892a-93e35b2d7c98/rdf.yaml","links":[],"config":{"_doi":"10.5072/zenodo.881843","_conceptdoi":"10.5072/zenodo.881842","_rdf_file":"https://sandbox.zenodo.org/api/files/75b365f2-a335-43cb-892a-93e35b2d7c98/rdf.yaml"}},{"id":"10.5072/zenodo.880273","name":"ISBI2012-2D-BoundaryModel","type":"model","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:model","u-net","neuron-segmentation","segmentation","volume-em","isbi2012-challenge","affinity-prediction","zenodo"],"description":"ISBI2012-2D-BoundaryModel","stats":{"downloads":14080,"unique_downloads":3416,"unique_views":11,"version_downloads":14632,"version_unique_downloads":3618,"version_unique_views":24,"version_views":35,"version_volume":59503179871,"views":13,"volume":58591297771},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/9567559e-501c-4106-be15-8e10fbbe2390/documentation.md","covers":["https://sandbox.zenodo.org/api/files/9567559e-501c-4106-be15-8e10fbbe2390/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/9567559e-501c-4106-be15-8e10fbbe2390/rdf.yaml","links":["10.5072/zenodo.881019","ilastik/ilastik","deepimagej/deepimagej","imjoy/BioImageIO-Packager"],"config":{"_doi":"10.5072/zenodo.881742","_conceptdoi":"10.5072/zenodo.880273","_rdf_file":"https://sandbox.zenodo.org/api/files/9567559e-501c-4106-be15-8e10fbbe2390/rdf.yaml"}},{"id":"10.5072/zenodo.881020","name":"MitoEM Challenge: Large-scale 3D Mitochondria Instance Segmentation","type":"dataset","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:dataset","mitochondria-segmentation","em-segmentation","mito-em-challenge","zenodo"],"description":"The task is the 3D mitochondria instance segmentation on two 30x30x30 um datasets, 1000x4096x4096 in voxels at 30x8x8 nm resolution.","stats":{"downloads":0,"unique_downloads":0,"unique_views":6,"version_downloads":1,"version_unique_downloads":1,"version_unique_views":8,"version_views":9,"version_volume":801,"views":6,"volume":0},"license":"CC-BY-4.0","documentation":"https://mitoem.grand-challenge.org/","covers":["https://grand-challenge-public-prod.s3.amazonaws.com/b/566/banner.x10.jpeg","https://grand-challenge-public-prod.s3.amazonaws.com/i/2020/10/27/mitoEM_teaser.png"],"source":"https://sandbox.zenodo.org/api/files/b129783b-c251-4995-a71b-2ee0cc4ada49/mito_em.yaml","links":[],"config":{"_doi":"10.5072/zenodo.881227","_conceptdoi":"10.5072/zenodo.881020","_rdf_file":"https://sandbox.zenodo.org/api/files/b129783b-c251-4995-a71b-2ee0cc4ada49/mito_em.yaml"}},{"id":"10.5072/zenodo.872944","name":"2D UNet Arabidopsis Ovules","type":"model","authors":[{"name":"Adrian Wolny"},{"name":"Lorenzo Cerrone"}],"tags":["bioimage.io","bioimage.io:model","unet2d","pytorch","arabidopsis","ovules","cell membrane","segmentation","plant tissue","plant","zenodo"],"description":"A 2D U-Net trained to predict the cell boundaries in confocal stacks of Arabidopsis ovules. Trained on z-slices of 3D confocal images.","stats":{"downloads":11975,"unique_downloads":3285,"unique_views":7,"version_downloads":13390,"version_unique_downloads":3624,"version_unique_views":14,"version_views":19,"version_volume":2600026449,"views":8,"volume":2309111937},"license":"MIT","documentation":"https://sandbox.zenodo.org/api/files/36604653-1541-4891-b6bd-de5963217e5f/unet2d.md","covers":["https://sandbox.zenodo.org/api/files/36604653-1541-4891-b6bd-de5963217e5f/raw.png","https://sandbox.zenodo.org/api/files/36604653-1541-4891-b6bd-de5963217e5f/pred.png"],"source":"https://sandbox.zenodo.org/api/files/36604653-1541-4891-b6bd-de5963217e5f/rdf.yaml","links":["imjoy/BioImageIO-Packager","ilastik/ilastik"],"config":{"_doi":"10.5072/zenodo.872978","_conceptdoi":"10.5072/zenodo.872944","_rdf_file":"https://sandbox.zenodo.org/api/files/36604653-1541-4891-b6bd-de5963217e5f/rdf.yaml"}},{"id":"10.5072/zenodo.872852","name":"3D UNet Arabidopsis Ovules","type":"model","authors":[{"name":"Adrian Wolny"},{"name":"Lorenzo Cerrone"}],"tags":["bioimage.io","bioimage.io:model","unet3d","pytorch","arabidopsis","ovules","cell membrane","segmentation","plant tissue","zenodo"],"description":"A 3d U-Net trained to predict the cell boundaries in confocal stacks of Arabidopsis ovules. Voxel size: (0.235, 0.150, 0.150) microns ZYX","stats":{"downloads":19878,"unique_downloads":3374,"unique_views":6,"version_downloads":20155,"version_unique_downloads":3390,"version_unique_views":6,"version_views":8,"version_volume":24299696904,"views":8,"volume":23975348697},"license":"MIT","documentation":"https://sandbox.zenodo.org/api/files/12102045-f235-4426-afff-2b801725eb15/unet3d.md","covers":["https://sandbox.zenodo.org/api/files/12102045-f235-4426-afff-2b801725eb15/ilastik_4.png","https://sandbox.zenodo.org/api/files/12102045-f235-4426-afff-2b801725eb15/ilastik_5.png","https://sandbox.zenodo.org/api/files/12102045-f235-4426-afff-2b801725eb15/ilastik_6.png","https://sandbox.zenodo.org/api/files/12102045-f235-4426-afff-2b801725eb15/ilastik_7.png","https://sandbox.zenodo.org/api/files/12102045-f235-4426-afff-2b801725eb15/ilastik_8.png"],"source":"https://sandbox.zenodo.org/api/files/12102045-f235-4426-afff-2b801725eb15/rdf.yaml","links":["imjoy/BioImageIO-Packager"],"config":{"_doi":"10.5072/zenodo.872975","_conceptdoi":"10.5072/zenodo.872852","_rdf_file":"https://sandbox.zenodo.org/api/files/12102045-f235-4426-afff-2b801725eb15/rdf.yaml"}},{"id":"10.5072/zenodo.872914","name":"CREMI-BoundaryModel","type":"model","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:model","u-net","neuron-segmentation","segmentation","volume-em","cremi","connectomics","affinity-prediction","zenodo"],"description":"CREMI-BoundaryModel","stats":{"downloads":9946,"unique_downloads":3088,"unique_views":4,"version_downloads":9989,"version_unique_downloads":3101,"version_unique_views":5,"version_views":5,"version_volume":337109699550,"views":4,"volume":336745770563},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/406bdb5a-4dad-48cc-ae9a-d61f737d7de9/documentation.md","covers":["https://sandbox.zenodo.org/api/files/406bdb5a-4dad-48cc-ae9a-d61f737d7de9/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/406bdb5a-4dad-48cc-ae9a-d61f737d7de9/rdf.yaml","links":["imjoy/BioImageIO-Packager","ilastik/ilastik"],"config":{"_doi":"10.5072/zenodo.872956","_conceptdoi":"10.5072/zenodo.872914","_rdf_file":"https://sandbox.zenodo.org/api/files/406bdb5a-4dad-48cc-ae9a-d61f737d7de9/rdf.yaml"}},{"id":"10.5072/zenodo.872854","name":"3D UNet Lateral Root Primordia Cell Boundaries","type":"model","authors":[{"name":"Adrian Wolny"},{"name":"Lorenzo Cerrone"}],"tags":["bioimage.io","bioimage.io:model","unet3d","pytorch","arabidopsis","lateral root","cell membrane","segmentation","plant tissue","zenodo"],"description":"A 3d U-Net trained to predict the cell boundaries in lightsheet stacks of Arabidopsis Lateral Root Primordia. (0.25x0.1625x0.1625) microns ZYX","stats":{"downloads":8100,"unique_downloads":2993,"unique_views":2,"version_downloads":8123,"version_unique_downloads":2997,"version_unique_views":5,"version_views":5,"version_volume":297806808,"views":2,"volume":296659522},"license":"MIT","documentation":"https://sandbox.zenodo.org/api/files/7c3fb1b0-74aa-4b98-97c4-6cf6167c20bc/unet3d.md","covers":["https://sandbox.zenodo.org/api/files/7c3fb1b0-74aa-4b98-97c4-6cf6167c20bc/raw.png","https://sandbox.zenodo.org/api/files/7c3fb1b0-74aa-4b98-97c4-6cf6167c20bc/pred.png"],"source":"https://sandbox.zenodo.org/api/files/7c3fb1b0-74aa-4b98-97c4-6cf6167c20bc/rdf.yaml","links":["imjoy/BioImageIO-Packager","ilastik/Ilastik"],"config":{"_doi":"10.5072/zenodo.872933","_conceptdoi":"10.5072/zenodo.872854","_rdf_file":"https://sandbox.zenodo.org/api/files/7c3fb1b0-74aa-4b98-97c4-6cf6167c20bc/rdf.yaml"}},{"id":"10.5072/zenodo.872924","name":"Platyereis-nuclei-BoundaryModel","type":"model","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:model","u-net","nuclei-segmentation","segmentation","volume-em","platynereis","nuclei","affinity-prediction","zenodo"],"description":"Platyereis-nuclei-BoundaryModel","stats":{"downloads":4871,"unique_downloads":2696,"unique_views":0,"version_downloads":4871,"version_unique_downloads":2696,"version_unique_views":0,"version_views":0,"version_volume":1190810426,"views":0,"volume":1190810426},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/f4eab9b7-81ce-4603-93e7-9ccd3731506c/documentation.md","covers":["https://sandbox.zenodo.org/api/files/f4eab9b7-81ce-4603-93e7-9ccd3731506c/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/f4eab9b7-81ce-4603-93e7-9ccd3731506c/rdf.yaml","links":["imjoy/BioImageIO-Packager","ilastik/Ilastik"],"config":{"_doi":"10.5072/zenodo.872925","_conceptdoi":"10.5072/zenodo.872924","_rdf_file":"https://sandbox.zenodo.org/api/files/f4eab9b7-81ce-4603-93e7-9ccd3731506c/rdf.yaml"}},{"id":"10.5072/zenodo.872918","name":"Platyereis-cells-BoundaryModel","type":"model","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:model","u-net","cells-segmentation","segmentation","volume-em","platynereis","cells","affinity-prediction","zenodo"],"description":"Platyereis-cells-BoundaryModel","stats":{"downloads":4802,"unique_downloads":2602,"unique_views":0,"version_downloads":4802,"version_unique_downloads":2602,"version_unique_views":0,"version_views":0,"version_volume":840781051,"views":0,"volume":840781051},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/fc05a6ea-3aea-47fb-9760-f177d7c4a7d1/documentation.md","covers":["https://sandbox.zenodo.org/api/files/fc05a6ea-3aea-47fb-9760-f177d7c4a7d1/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/fc05a6ea-3aea-47fb-9760-f177d7c4a7d1/rdf.yaml","links":["imjoy/BioImageIO-Packager","ilastik/Ilastik"],"config":{"_doi":"10.5072/zenodo.872919","_conceptdoi":"10.5072/zenodo.872918","_rdf_file":"https://sandbox.zenodo.org/api/files/fc05a6ea-3aea-47fb-9760-f177d7c4a7d1/rdf.yaml"}},{"id":"10.5072/zenodo.872916","name":"DSB-Nuclei-BoundaryModel","type":"model","authors":[{"name":"Constantin Pape"}],"tags":["bioimage.io","bioimage.io:model","u-net","nucleus-segmentation","segmentation","volume-em","platynereis","nuclei","affinity-prediction","zenodo"],"description":"DSB-Nuclei-BoundaryModel","stats":{"downloads":4920,"unique_downloads":2673,"unique_views":3,"version_downloads":4920,"version_unique_downloads":2673,"version_unique_views":3,"version_views":3,"version_volume":1095713828,"views":3,"volume":1095713828},"license":"CC-BY-4.0","documentation":"https://sandbox.zenodo.org/api/files/c28391fb-4935-4a76-951f-f6910dae8fbd/documentation.md","covers":["https://sandbox.zenodo.org/api/files/c28391fb-4935-4a76-951f-f6910dae8fbd/cover.jpg"],"source":"https://sandbox.zenodo.org/api/files/c28391fb-4935-4a76-951f-f6910dae8fbd/rdf.yaml","links":["imjoy/BioImageIO-Packager","ilastik/Ilastik"],"config":{"_doi":"10.5072/zenodo.872917","_conceptdoi":"10.5072/zenodo.872916","_rdf_file":"https://sandbox.zenodo.org/api/files/c28391fb-4935-4a76-951f-f6910dae8fbd/rdf.yaml"}},{"id":"10.5072/zenodo.872860","name":"3D UNet Lateral Root Primordia Nuclei","type":"model","authors":[{"name":"Adrian Wolny"},{"name":"Lorenzo Cerrone"}],"tags":["bioimage.io","bioimage.io:model","unet3d","pytorch","arabidopsis","lateral root","cell nuclei","segmentation","plant tissue","zenodo"],"description":"A variant of 3D U-Net trained on light-sheet images of Arabidopsis lateral root nuclei on original resolution. Voxel size: (0.25x0.1625x0.1625 µm^3) (ZYX).","stats":{"downloads":7264,"unique_downloads":2677,"unique_views":3,"version_downloads":7264,"version_unique_downloads":2677,"version_unique_views":3,"version_views":4,"version_volume":753020946,"views":4,"volume":753020946},"license":"MIT","documentation":"https://sandbox.zenodo.org/api/files/a6e1b0c5-bcad-4b52-933e-13c36283d93a/unet3d.md","covers":["https://sandbox.zenodo.org/api/files/a6e1b0c5-bcad-4b52-933e-13c36283d93a/raw.png","https://sandbox.zenodo.org/api/files/a6e1b0c5-bcad-4b52-933e-13c36283d93a/pred.png"],"source":"https://sandbox.zenodo.org/api/files/a6e1b0c5-bcad-4b52-933e-13c36283d93a/rdf.yaml","links":["imjoy/BioImageIO-Packager","ilastik/Ilastik"],"config":{"_doi":"10.5072/zenodo.872861","_conceptdoi":"10.5072/zenodo.872860","_rdf_file":"https://sandbox.zenodo.org/api/files/a6e1b0c5-bcad-4b52-933e-13c36283d93a/rdf.yaml"}},{"id":"10.5072/zenodo.856197","name":"N2V SEM Demo","type":"model","authors":[{"name":"Deborah Schmidt"}],"tags":["bioimage.io","bioimage.io:model","denoising","unet2d","n2v","zenodo"],"description":"Uploaded via BioImage.IO website (https://bioimage.io)","stats":{"downloads":3448,"unique_downloads":2875,"unique_views":6,"version_downloads":3448,"version_unique_downloads":2875,"version_unique_views":6,"version_views":7,"version_volume":1049901448,"views":7,"volume":1049901448},"license":"BSD-3-Clause","documentation":"https://sandbox.zenodo.org/api/files/956c0bd6-5472-4052-a1ef-94ccf94cadc9/README.md","covers":["https://sandbox.zenodo.org/api/files/956c0bd6-5472-4052-a1ef-94ccf94cadc9/thumbnail.png"],"source":"https://sandbox.zenodo.org/api/files/956c0bd6-5472-4052-a1ef-94ccf94cadc9/model.yaml","links":["imjoy/BioImageIO-Packager"],"config":{"_doi":"10.5072/zenodo.856198","_conceptdoi":"10.5072/zenodo.856197","_rdf_file":"https://sandbox.zenodo.org/api/files/956c0bd6-5472-4052-a1ef-94ccf94cadc9/model.yaml"}}],"github":[{"id":"zero","source":"https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/manifest.bioimage.io.yaml"},{"id":"deepimagej","source":"https://raw.githubusercontent.com/deepimagej/models/master/manifest.bioimage.io.yaml"},{"id":"fiji","source":"https://raw.githubusercontent.com/bioimage-io/fiji-bioimage-io/master/manifest.bioimage.io.yaml"},{"id":"imjoy","source":"https://raw.githubusercontent.com/imjoy-team/bioimage-io-models/master/manifest.bioimage.io.yaml"},{"id":"ilastik","source":"https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/manifest.bioimage.io.yaml"},{"id":"hpa","source":"https://raw.githubusercontent.com/CellProfiling/HPA-model-zoo/master/manifest.bioimage.io.yaml"}]},"config":{"splash_title":"BioImage Model Zoo","splash_subtitle":"Advanced AI models in one-click","splash_feature_list":["Integrate with Fiji, Ilastik, ImJoy","Try model instantly with BioEngine","Contribute your models via Github","Link models to datasets and applications"],"explore_button_text":"Start Exploring","background_image":"static/img/zoo-background.svg","resource_types":["model","application","notebook","dataset"],"default_type":"model","url_root":"https://raw.githubusercontent.com/bioimage-io/collection-bioimage-io/gh-pages"}}